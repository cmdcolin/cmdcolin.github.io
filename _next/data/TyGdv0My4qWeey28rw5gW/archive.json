{"pageProps":{"allPosts":[{"title":"Memoizing async functions so that you don't cache errors","date":"2022-02-26","slug":"2022-02-26-memoize-async","mdxSource":{"compiledSource":"var p=Object.defineProperty,d=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var i=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var l=(e,t,a)=>t in e?p(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,o=(e,t)=>{for(var a in t||(t={}))i.call(t,a)&&l(e,a,t[a]);if(n)for(var a of n(t))s.call(t,a)&&l(e,a,t[a]);return e},c=(e,t)=>d(e,m(t));var h=(e,t)=>{var a={};for(var r in e)i.call(e,r)&&t.indexOf(r)<0&&(a[r]=e[r]);if(e!=null&&n)for(var r of n(e))t.indexOf(r)<0&&s.call(e,r)&&(a[r]=e[r]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var r=a,{components:e}=r,t=h(r,[\"components\"]);return mdx(MDXLayout,c(o(o({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"There are two hard problems in computer science: \",mdx(\"a\",o({parentName:\"p\"},{href:\"https://martinfowler.com/bliki/TwoHardThings.html\"}),`Cache invalidation and naming\nthings`),`. In this post we'll\nshow how to invalidate the cache when a promise throws an error.`),mdx(\"p\",null,`Memoizing an async function in javascript can be somewhat confusing.\nEspecially, one important consideration is caching when an error occurs. You\ncould cache the error'd promise, but the following example will show how to not\ncache the error, but still throw an exception. Since the error is not cached,\nyou can re-try the async function call after an error, and you won't get an old\ncached error state`),mdx(\"p\",null,\"Example async function: fetch from the pokemon API\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-javascript\"}),`async function getPokemon() {\n  const id = Math.floor(Math.random() * 150)\n  const url = 'https://pokeapi.co/api/v2/pokemon/' + id\n  const ret = await fetch(url)\n  if (!ret.ok) {\n    throw new Error(\n      \\`Failed to fetch \\${url} HTTP \\${ret.status} \\${ret.statusText}\\`,\n    )\n  }\n  return ret.json()\n}\n`)),mdx(\"p\",null,\"Here is a technique that can be used to memoize this function\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-javascript\"}),`function getPokemonMemoized() {\n  if (!this.res) {\n    this.res = getPokemon().catch(e => {\n      this.res = undefined\n      throw e\n    })\n  }\n  return this.res\n}\n`)),mdx(\"p\",null,`The promise is held in this.res, and the important part of this function is\nthat when I get an error, I clear this.res and re-throw the error. The caller\nof the function, on error, will receive the error message, but caching will not\ntake place, allowing retries to take place later on.`),mdx(\"p\",null,\"See \",mdx(\"a\",o({parentName:\"p\"},{href:\"https://cmdcolin.github.io/pokemon.html\"}),\"https://cmdcolin.github.io/pokemon.html\"),\" for demo\"),mdx(\"h2\",null,\"Footnote 1: Error handling\"),mdx(\"p\",null,`This demo also demonstrates some basic fetch error handling, and uses\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"statusText\"),\" \",mdx(\"a\",o({parentName:\"p\"},{href:\"https://developer.mozilla.org/en-US/docs/Web/API/Response/statusText\"}),`which happens to not exist in\nHTTP/2`),`.\nIf you want a semblence of status message text in HTTP/2 you can try to use\nawait ret.json() or await ret.text() inside the catch clause, but note that it\ncould cause yet another error to be thrown`),mdx(\"h2\",null,\"Footnote 2: Global cache\"),mdx(\"p\",null,`You could also keep a cache in a global variable, or as a property on a class,\nor other methods. I have also found it useful to have a specific function for\nclearing the cache, so you can get a clean slate each time a test runs in unit\ntesting or similar`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-javascript\"}),`let res\nasync function getPokemonMemoized() {\n  if (!res) {\n    res = getPokemon().catch(e => {\n      res = undefined\n      throw e\n    })\n  }\n  return res\n}\nfunction clearCache() {\n  res = undefined\n}\n`)),mdx(\"h2\",null,\"Footnote 3 - Aborting\"),mdx(\"p\",null,`If you want to handle aborting, it is a bit trickier. Aborting in javascript is\nhandled by\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://developer.mozilla.org/en-US/docs/Web/API/AbortController/AbortController\"}),\"AbortController\"),`.\nThis is an object that gives you an\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal\"}),\"AbortSignal\"),`\nthat can be passed to fetch calls and the like to stop a big download from\nhappening.`),mdx(\"p\",null,`In our above example, if we passed an abort signal to the first call to fetch,\nand then aborted it, it would abort the fetch, `,mdx(\"a\",o({parentName:\"p\"},{href:\"https://developer.mozilla.org/en-US/docs/Web/API/AbortController/abort\"}),`which throws a DOMException\ncalled\n\"AbortError\"`),`.\nYou can detect that it is an AbortError like this, and may choose not to\ndisplay or re-throw the abort exception`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-javascript\"}),`function isAbortException(e) {\n  return e instanceof Error && exception.name === 'AbortError'\n}\n`)),mdx(\"p\",null,`Now, what if 5 functions call getPokemonMemoized(), all passing different abort\nsignals. What if the first one aborts? Then all the rest will get aborted also.\nBut what if we only want to abort the cached call if literally all of them\naborted? Then we may have to synthesize an abortcontroller inside our function`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-javascript\"}),`let res\nlet abortcontroller\nlet listeners = 0\nasync function getPokemonMemoized(signal) {\n  if (!res) {\n    abortcontroller = new AbortController()\n\n    // synthesize a new signal instead of using the passed in signal\n    res = getPokemon(abortcontroller.signal).catch(e => {\n      res = undefined\n      throw e\n    })\n  }\n  if (signal) {\n    listeners++\n    // add listener to the passed in signal\n    signal.addEventListener('abort', () => {\n      listeners--\n      if (listeners === 0) {\n        abortcontroller.abort()\n      }\n    })\n  }\n  return res\n}\n`)),mdx(\"p\",null,`A library my team created,\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://github.com/GMOD/abortable-promise-cache\"}),\"abortable-promise-cache\"),`,\ntries to help with this scenario with a cleaner abstraction.`),mdx(\"h2\",null,\"Footnote 4\"),mdx(\"p\",null,`I have been playing through Pokemon Yellow and find it really amusing hence the\npokemon theme`),mdx(\"p\",null,`Fun stuff: The cutting room floor wiki with unused moves, sounds, and sprites\nin Pokemon Yellow `,mdx(\"a\",o({parentName:\"p\"},{href:\"https://tcrf.net/Pok%C3%A9mon_Yellow\"}),\"https://tcrf.net/Pok%C3%A9mon_Yellow\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Ukraine","date":"2022-02-24","slug":"2022-02-24-ukraine","mdxSource":{"compiledSource":"var u=Object.defineProperty,h=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var t=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var p=(o,n,e)=>n in o?u(o,n,{enumerable:!0,configurable:!0,writable:!0,value:e}):o[n]=e,i=(o,n)=>{for(var e in n||(n={}))r.call(n,e)&&p(o,e,n[e]);if(t)for(var e of t(n))s.call(n,e)&&p(o,e,n[e]);return o},d=(o,n)=>h(o,c(n));var m=(o,n)=>{var e={};for(var a in o)r.call(o,a)&&n.indexOf(a)<0&&(e[a]=o[a]);if(o!=null&&t)for(var a of t(o))n.indexOf(a)<0&&s.call(o,a)&&(e[a]=o[a]);return e};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(e){var a=e,{components:o}=a,n=m(a,[\"components\"]);return mdx(MDXLayout,d(i(i({},layoutProps),n),{components:o,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"As Russia is actively invading Ukraine my heart goes out to them.\"),mdx(\"p\",null,`Even if I had no personal connection with Ukraine, I would find this abhorrent,\nbut I do have personal connections to Ukraine in various ways that makes me\nthink of them more fondly`),mdx(\"p\",null,`My first, and so far only, consulting job was with a company in Ukraine, around 2012. I helped them configure JBrowse, and prepared an official looking word\ndocument with recommendations and hours (a total of like...2 hours) and they\nwere very nice.`),mdx(\"p\",null,\"Stand strong Ukraine\"),mdx(\"img\",{src:\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Lesser_Coat_of_Arms_of_Ukraine.svg/172px-Lesser_Coat_of_Arms_of_Ukraine.svg.png\"}))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Back when I was a noise musician...","date":"2022-02-15","slug":"2022-02-15-noise","mdxSource":{"compiledSource":"var h=Object.defineProperty,u=Object.defineProperties;var l=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,i=Object.prototype.propertyIsEnumerable;var r=(o,t,e)=>t in o?h(o,t,{enumerable:!0,configurable:!0,writable:!0,value:e}):o[t]=e,p=(o,t)=>{for(var e in t||(t={}))s.call(t,e)&&r(o,e,t[e]);if(n)for(var e of n(t))i.call(t,e)&&r(o,e,t[e]);return o},c=(o,t)=>u(o,l(t));var m=(o,t)=>{var e={};for(var a in o)s.call(o,a)&&t.indexOf(a)<0&&(e[a]=o[a]);if(o!=null&&n)for(var a of n(o))t.indexOf(a)<0&&i.call(o,a)&&(e[a]=o[a]);return e};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(e){var a=e,{components:o}=a,t=m(a,[\"components\"]);return mdx(MDXLayout,c(p(p({},layoutProps),t),{components:o,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Found this photo of myself from a photo book published by john cates called\nauditory depravation...great documentation of michigan area noise activity. I\nam actually the last photo in the book amongst so many amazing\nartists...totally honored. I forgot I was even in the book when I picked it up\nrandomly.`),mdx(\"p\",null,\"thank you john cates!!!\"),mdx(\"img\",{src:\"/photos/noise/cover-crop-fs8.png\"}),mdx(\"p\",null,\"cover\"),mdx(\"img\",{src:\"/photos/noise/out20-crop-fs8.png\"}),mdx(\"p\",null,\"index p1\"),mdx(\"img\",{src:\"/photos/noise/out21-crop-fs8.png\"}),mdx(\"p\",null,\"index p2\"),mdx(\"img\",{src:\"/photos/noise/out22-crop-fs8.png\"}),mdx(\"p\",null,\"index p3, i'm last as xephedradap\"),mdx(\"img\",{src:\"/photos/noise/out15-crop-fs8.png\"}),mdx(\"p\",null,\"me\"),mdx(\"img\",{src:\"/photos/noise/out16-crop-fs8.png\"}),mdx(\"p\",null,\"abstract b/w\"),mdx(\"p\",null,\"some photos from the book here \",mdx(\"a\",p({parentName:\"p\"},{href:\"https://www.johncatesphoto.com/noise\"}),\"https://www.johncatesphoto.com/noise\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",p({parentName:\"li\"},{href:\"https://soundcloud.com/xephedradap/amazingnoisetreasure\"}),\"lightyear fluctuations\"),\" (hnw)\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",p({parentName:\"li\"},{href:\"https://soundcloud.com/xephedradap/symptomatic-of-extreme-decay\"}),\"symptomatic of extreme decay\"),\" (circuit bent hnw)\"),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",p({parentName:\"li\"},{href:\"https://soundcloud.com/xephedradap/2016-10-10-13-35-49a\"}),\"2016-10-10-13-35-49a\"),\" (circuit bent drum machine)\")),mdx(\"p\",null,\"I will make more noise soon...stay tuned\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Structural variants and the SAM format - the long (reads) and short (reads) of it","date":"2022-02-06","slug":"2022-02-06-sv-sam","mdxSource":{"compiledSource":"var h=Object.defineProperty,m=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var p=(n,t,i)=>t in n?h(n,t,{enumerable:!0,configurable:!0,writable:!0,value:i}):n[t]=i,e=(n,t)=>{for(var i in t||(t={}))r.call(t,i)&&p(n,i,t[i]);if(o)for(var i of o(t))s.call(t,i)&&p(n,i,t[i]);return n},l=(n,t)=>m(n,c(t));var d=(n,t)=>{var i={};for(var a in n)r.call(n,a)&&t.indexOf(a)<0&&(i[a]=n[a]);if(n!=null&&o)for(var a of o(n))t.indexOf(a)<0&&s.call(n,a)&&(i[a]=n[a]);return i};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(i){var a=i,{components:n}=a,t=d(a,[\"components\"]);return mdx(MDXLayout,l(e(e({},layoutProps),t),{components:n,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"The \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` specification is pretty amazing\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://samtools.github.io/hts-specs/SAMv1.pdf\"}),\"https://samtools.github.io/hts-specs/SAMv1.pdf\"),` but it is also fairly terse and\nabstract. True understanding might come from playing with real world data, but\nI will try to relay some things I have learned, especially as they relate to\nstructural variants.`),mdx(\"p\",null,`Disclaimer: I'm a developer of JBrowse 2. This document has some screenshots\nand links for it, feel free to try it at `,mdx(\"a\",e({parentName:\"p\"},{href:\"https://jbrowse.org\"}),\"https://jbrowse.org\")),mdx(\"p\",null,\"Also note: When I refer to a \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` record in this document, it could come from\na `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\", or \",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),\" file as \",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\" and \",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),` are just alternative\nencodings of `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\")),mdx(\"h2\",null,\"Basics\"),mdx(\"h3\",null,\"What is a \",mdx(\"inlineCode\",{parentName:\"h3\"},\"SAM\"),\" file and how does it relate to \",mdx(\"inlineCode\",{parentName:\"h3\"},\"BAM\"),\" and \",mdx(\"inlineCode\",{parentName:\"h3\"},\"CRAM\"),\"?\"),mdx(\"p\",null,\"A \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\" file \",mdx(\"strong\",{parentName:\"p\"},\"generally\"),` contains \"reads\" from a sequencer, with information\nabout how they are mapped to a reference genome `,\"[1][2]\",`. The raw unaligned reads\nare often stored in `,mdx(\"inlineCode\",{parentName:\"p\"},\"FASTQ\"),\" format files. The reads from \",mdx(\"inlineCode\",{parentName:\"p\"},\"FASTQ\"),` format are\nthen inputted into an aligner such as `,mdx(\"inlineCode\",{parentName:\"p\"},\"bwa\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"bowtie\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"minimap2\"),` (there are\nmany others) which map the reads to a reference genome, and output `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),`\nformat.`),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\" is a text format that you can read with your text editor. \",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),` and\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),\" are compressed representations of the \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\" format.\"),mdx(\"p\",null,\"You can convert \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\" to \",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\" with samtools\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"samtools view file.sam -o file.bam\")),mdx(\"p\",null,\"A slightly modified command converts \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\" to \",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),` (requires -T argument to\nspecify your reference sequence)`),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"samtools view -T reference.fa file.sam -o file.cram\")),mdx(\"p\",null,\"Also see Appendix C: piping FASTQ from \",mdx(\"inlineCode\",{parentName:\"p\"},\"minimap2\"),\" directly to CRAM\"),mdx(\"p\",null,\"[1]\",\" \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` can contain any type of sequence, not specifically reads. If you\ncreated a de novo assembly, you could align the contigs of the de novo assembly\nto a reference genome and store the results in `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\".\"),mdx(\"p\",null,\"[2]\",` Does not always have to have information about mapping to a reference\ngenome. You can also store unaligned data in `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\"/\",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\"/\",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),` (so-called\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"uBAM\"),\" for example) but most of the time, the reads in \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` format are aligned\nto a reference genome.`),mdx(\"h3\",null,\"What is in a \",mdx(\"inlineCode\",{parentName:\"h3\"},\"SAM\"),\" file\"),mdx(\"p\",null,\"A \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\" file contains a header (\",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\" and \",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),\" files also have the \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),`\nheader) and a series of records. A record is a single line in a `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file, and\nit generally corresponds to a single read, but as we will see, a split\nalignment may produce multiple records that refer to the same source read.`),mdx(\"p\",null,`Note: if a read failed to align to the reference genome, it may still be in\nyour `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file, marked as unmapped using the flag column. Sometimes, \"dumpster\ndiving\" (looking at the unmapped records from a `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file) can be used to aid\nstructural variant searches (e.g. there may be novel sequence in there not from\nthe reference genome that could be assembled)`),mdx(\"h3\",null,\"What is a \",mdx(\"inlineCode\",{parentName:\"h3\"},\"CIGAR\"),\" string\"),mdx(\"p\",null,\"A \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),` string is a \"compact idiosyncratic gapped alignment report\". Yes,\nthat's an acronym.`),mdx(\"p\",null,\"Examples of \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),\" strings\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"A \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),\" strings could look be \",mdx(\"inlineCode\",{parentName:\"p\"},\"50M\"),` which means 50 bases \"matched\". There\nare no insertions or deletions. There could be underlying mismatches in this\nsequence that only comparing to a reference sequence would tell you`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"Another \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),\" string with insertions and deletions could be \",mdx(\"inlineCode\",{parentName:\"p\"},\"50M1D1I50M\"),`.\nThis string had a deletion and an insertion back to back. This could be just\na mismatch! There is ambiguity in sequence alignment representations.\nDownstream programs must accomodate this.`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"Another \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),\" string with soft-clipping \",mdx(\"inlineCode\",{parentName:\"p\"},\"500S50M\"),` this means that 500 bases\nof the read were not aligned at this position, but 50 bases were! Note that\nthe alignment might have been a split alignment (see seciton on split\nalignments below) so another record in the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file might contain info on\nwhere the other 500 bases aligned, or they might just be fully unaligned.`))),mdx(\"p\",null,\"See SAMv1.pdf for all the CIGAR operators.\"),mdx(\"p\",null,\"And also: \\u266B don't fear the \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),\" \\u266B\"),mdx(\"p\",null,\"If you are working with \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` data, you will often write loops that directly\nparse CIGAR strings. See Appendix B for handy functions for parsing `,mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),`\nstrings.`),mdx(\"h3\",null,\"What is an \",mdx(\"inlineCode\",{parentName:\"h3\"},\"MD\"),\" string\"),mdx(\"p\",null,\"An \",mdx(\"inlineCode\",{parentName:\"p\"},\"MD\"),\" string is a tag in \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file that helps tell you where the mismatches\nare, and can be combined with a `,mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),` to get the position of the mismatches\nwithout looking at a reference genome.`),mdx(\"p\",null,\"The \",mdx(\"inlineCode\",{parentName:\"p\"},\"MD\"),\" string is commonly seen in \",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\" files (not generally \",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),` because\nit already uses reference compression and requires a reference sequence to\ndecode). The `,mdx(\"inlineCode\",{parentName:\"p\"},\"MD\"),` tag contains information about deletions (including the bases\nof the reference genome, which would otherwise not be indicated) and mismatches\n(same, indicating the base of the reference genome at a SNPs position), but not\ninsertions.`),mdx(\"p\",null,\"The command \",mdx(\"inlineCode\",{parentName:\"p\"},\"samtools calmd yourfile.bam --reference reference.fa\"),\" can add \",mdx(\"inlineCode\",{parentName:\"p\"},\"MD\"),`\ntags to your `,mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\" file. Note that there are some oddities about \",mdx(\"inlineCode\",{parentName:\"p\"},\"MD\"),` tags\nleading to complaints (e.g. `,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/samtools/hts-specs/issues/505\"}),\"https://github.com/samtools/hts-specs/issues/505\"),`)\nbut the `,mdx(\"inlineCode\",{parentName:\"p\"},\"MD\"),` tag can be helpful if you want to decode a file without referring\nto it's reference.`),mdx(\"h2\",null,\"Detecting SVs from long reads\"),mdx(\"p\",null,\"Long reads offer a wide array of methods for detecting SVs\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},`Insertions/deletions: Long reads can completely span moderate sized\ninsertions and deletions, indicated by `,mdx(\"inlineCode\",{parentName:\"li\"},\"I\"),\" or \",mdx(\"inlineCode\",{parentName:\"li\"},\"D\"),\" in a \",mdx(\"inlineCode\",{parentName:\"li\"},\"CIGAR\"),` string. If it\ndoes not completely span it, it may be split alignment (for a deletion) or\nclipped (for an insertion)`),mdx(\"li\",{parentName:\"ul\"},`Translocations: A split alignment can span inter-chromosomal translocations,\nso part of the read maps to one chromosome and one part maps to the other`),mdx(\"li\",{parentName:\"ul\"},`Inversions: A split alignment can span an inversion, the long read is split\ninto multiple parts, one part of it aligns in the reverse orientation, while\nthe other part aligns in the forward orientation`)),mdx(\"p\",null,`Note that there are many different methods for detecting SVs from long reads,\ne.g. not all use mapped reads from SAM files, some use de novo assembly, but\nit is still useful to be familiar with mapped read methods.`),mdx(\"h3\",null,\"What are split alignments?\"),mdx(\"p\",null,`Split alignments, or chimeric alignments, are alignments where part of the read\naligns to perhaps chr1, and part of it maps to perhaps chr4. It is worth\nreading the definition of \"Chimeric alignment\" from\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://samtools.github.io/hts-specs/SAMv1.pdf\"}),\"SAMv1.pdf\"),` when you get the\nchance.`),mdx(\"p\",null,`Split alignments are especially common with long reads, and it can indicate\nthat there may be a structural variant where the two chromosomes are fused\ntogether (which may create gene fusions, or other types of phenomena).`),mdx(\"p\",null,`There is no limitation on how many splits might occur so the split can align to\n3, 4, or more different places. Each part of the split puts a new line in the\nSAM file, and note that all the records also have the same `,mdx(\"inlineCode\",{parentName:\"p\"},\"QNAME\"),` (first\ncolumn of `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),`). As\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://samtools.github.io/hts-specs/SAMv1.pdf\"}),\"SAMv1.pdf\"),` tells us, one\nrecord is marked as \"representative\", I call this the \"primary\" record, while\nthe other components of the split read are maked supplementary, given the 2048\nflag. Only the \"primary\" record generally has a `,mdx(\"inlineCode\",{parentName:\"p\"},\"SEQ\"),\" field.\"),mdx(\"p\",null,`Note: split alignments are different from \"multi-mappers\" where the entire read\nmaps maps equally well to, say, chr4 and chr1. Split reads maps part to chr1,\nand part to chr4. See again the\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://samtools.github.io/hts-specs/SAMv1.pdf\"}),\"SAMv1.pdf\"),` for the definition\nof multi-mapping`),mdx(\"h3\",null,\"What is the \",mdx(\"inlineCode\",{parentName:\"h3\"},\"SA\"),\" tag?\"),mdx(\"p\",null,\"The \",mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),` tag is outputted on each part of the split alignment, e.g. the primary\ncontains an `,mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),\" tag that refers to all the locations, \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),` strings, and\nmore for all the supplementary reads, and each of the supplementary reads also\ncontains an `,mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),` tag that refers to the primary alignment and each other\nsupplementary alignment.`),mdx(\"p\",null,\"Fun fact: The \",mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),` tag conceptually can result in a 'quadratic explosion' of\ndata, because each part of the split contains references to every other part.\nFor example, if a read is split into 4 pieces, then each record would would\nhave an SA tag with 3 segments, so 3`,\"*\",\"4 segments will be documented in the\",mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),`\ntag. In many cases, this is not a problem, but if you imagine a finished\nchromosome aligned to a draft assembly, it may get split so many times this\ncould be a factor.`),mdx(\"h3\",null,\"Visualizing split reads across a breakend or translocation\"),mdx(\"p\",null,`This is a specialized JBrowse 2 feature, but if there is an inter-chromosomal\ntranslocation, you can load this into JBrowse and visualize support for this\nevent using our \"breakpoint split view\". This`),mdx(\"p\",null,`We also have a workflow called the \"SV inspector\" that helps you setup the\n\"breakpoint split views\"\n(`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://jbrowse.org/jb2/docs/user_guide/#sv-inspector\"}),\"https://jbrowse.org/jb2/docs/user_guide/#sv-inspector\"),`). The SV inspector works\nbest on Breakend spec events and `,\"<\",\"TRA\",\">\",` (translocation) events from VCF,\nor BEDPE formatted SV calls, and you can launch the \"breakpoint split view\"\nfrom the \"SV inspector\"`),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/breakpoint_split_view.png\",alt:null}))),mdx(\"h3\",null,\"Visualizing a 'read vs reference' view given a split alignment\"),mdx(\"p\",null,`If we are given the the primary alignment of an arbitrary split read, then we\ncan construct what that split looks like compared to the reference genome.`),mdx(\"p\",null,`If we are not given the primary alignment (e.g. we are starting from a\nsupplementary alignment) then we can search the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),` list for the one that is\nprimary, because at least one will be.`),mdx(\"p\",null,\"Now that we have the primary alignment, it will have the \",mdx(\"inlineCode\",{parentName:\"p\"},\"SEQ\"),` (of the entire\nread, the supplementary alignments typically have a blank `,mdx(\"inlineCode\",{parentName:\"p\"},\"SEQ\"),\"!) and the \",mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),`\ntag containing the `,mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),` of all the different parts of the split. We can then\nconstruct how the entire read, not just a particular record of the split\nalignment, compares to the genome. In JBrowse 2 we implemented this and it uses\na synteny-style rendering. This functionality also exists in GenomeRibbon\n(`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://genomeribbon.org\"}),\"https://genomeribbon.org\"),\")\"),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/linear_alignment.png\",alt:null}))),mdx(\"p\",null,`Figure showing JBrowse 2 piecing together a long read vs the reference genome\nfrom a single read`),mdx(\"p\",null,\"In order to do this reconstruction, JBrowse 2 takes the \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),` strings of the\nprimary alignment and each of the pieces of the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),` tag (it is a semi-colon\nseparated list of chunks), sort them by the amount of softclipping (the\nsoftclipping values will progressively trim off more of the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SEQ\"),` telling you\nit aligned further and further on in the long read), and then this tells me\nwhere each piece of the split alignment came from in the original `,mdx(\"inlineCode\",{parentName:\"p\"},\"SEQ\"),`, so we\ncan plot the alignments of the read vs the reference genome using synteny style\ndisplay.`),mdx(\"h3\",null,\"SAM vs VCF - Breakends vs split alignments\"),mdx(\"p\",null,\"An interesting outcome (to me) is that from a single record in a \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file, I\ncan reconstruct the \"derived\" genome around a region of interest from a single\nread.`),mdx(\"p\",null,\"If I was to try to do this with the \",mdx(\"inlineCode\",{parentName:\"p\"},\"VCF\"),` Breakend specification (section 5.4\nof `,mdx(\"a\",e({parentName:\"p\"},{href:\"https://samtools.github.io/hts-specs/VCFv4.3.pdf\"}),\"VCF4.3.pdf\"),`), it may\nactually be more challenging than from a `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` read. This is because a Breakend\nin `,mdx(\"inlineCode\",{parentName:\"p\"},\"VCF\"),` format is only an edge in a graph (and the sequences are nodes).\nTherefore, in order to properly reconstruct a structural variant from a `,mdx(\"inlineCode\",{parentName:\"p\"},\"VCF\"),`\nwith Breakends, I would have to construct a graph and decode paths through it.`),mdx(\"p\",null,`I like the ability to reconstruct the derived genome from a single read, but it\ncan be noisy. That said, de novo assembled contigs can also be stored in `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),`\nformat and is significantly less noisy (being composed of the aggregate\ninformation of many reads).`),mdx(\"p\",null,\"The point though is that interpretation of the \",mdx(\"inlineCode\",{parentName:\"p\"},\"VCF\"),` breakend specification is\nchallenging due to imposing a sequence graph on the genome, while the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SA\"),` tag\nremains just a simple set of linear alignments that can easily be pieced\ntogether, and you only need to refer to a single record in the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file to do\nso.`),mdx(\"p\",null,`I am not aware of a lot of tools that work on the VCF Breakend graph, and\nexpect more will need to be created to truly work with this standard. An\ninversion for example may create 4 record in the VCF file (see section 5.4 in\nthe `,mdx(\"a\",e({parentName:\"p\"},{href:\"https://samtools.github.io/hts-specs/VCFv4.3.pdf\"}),\"VCF4.3.pdf\"),` for\nexample), and needs careful interpretation.`),mdx(\"h3\",null,\"Haplotype tagged reads\"),mdx(\"p\",null,\"A new trend has been to create \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),\"/\",mdx(\"inlineCode\",{parentName:\"p\"},\"BAM\"),\"/\",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),` files with tagged reads,\nwhich tells us which haplotype a read was inferred to have come from. This is\ncommonly done with the `,mdx(\"inlineCode\",{parentName:\"p\"},\"HP\"),\" tag, which might have \",mdx(\"inlineCode\",{parentName:\"p\"},\"HP=0\"),\" and \",mdx(\"inlineCode\",{parentName:\"p\"},\"HP=1\"),` for a\ndiploid genome. Tools like `,mdx(\"inlineCode\",{parentName:\"p\"},\"whatshap\"),\" can add these tags to a \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` file, and\nIGV and JBrowse 2 can color and sort by these tags.`),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/color_by_tag.png\",alt:null}))),mdx(\"p\",null,`Screenshot of JBrowse 2 with the \"Color by tag\" and \"Sort by tag\" setting\nenabled (coloring and sorting by the HP tag) letting us see that only one\nhaplotype has a deletion. Tutorial for how to do this in JBrowse 2 here\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://jbrowse.org/jb2/docs/user_guide/#sort-color-and-filter-by-tag\"}),\"https://jbrowse.org/jb2/docs/user_guide/#sort-color-and-filter-by-tag\")),mdx(\"h2\",null,\"How do you detect SVs with paired-end reads?\"),mdx(\"p\",null,`Paired-end reads are short reads, e.g. 150bp each. This makes them unable to\nrecover some large structural variants.`),mdx(\"p\",null,`However, paired-end reads have a number of attributes that can be used to\ndetect paired end reads`),mdx(\"h3\",null,\"Distance between pairs being abnormally large or short\"),mdx(\"p\",null,\"The distance between pairs is encoded by the \",mdx(\"inlineCode\",{parentName:\"p\"},\"TLEN\"),\" column in the \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` format.\nThe distance between pairs with good mapping is relatively constant and called\nthe \"insert length\". This comes from how the sequencing is done: paired-end\nsequencing performs sequencing on both ends of a fragment.`),mdx(\"p\",null,`But, if you are mapping reads vs the reference genome, and you observe that\nthey are abnormally far apart, say 50kb apart instead of 1kb apart, this may\nindicate there your sample contains a deletion relative to the reference.`),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/aberrant_size.png\",alt:null}))),mdx(\"p\",null,`Screenshot of JBrowse 1 with \"View as pairs\" enabled, and large insert size\ncolored as red (from `,mdx(\"a\",e({parentName:\"p\"},{href:\"https://jbrowse.org/docs/paired_reads.html\"}),\"https://jbrowse.org/docs/paired_reads.html\"),`). Note that\nsome of JBrowse 1's View as pairs features are not yet available in JBrowse 2`),mdx(\"h3\",null,'An abundance of reads being \"clipped\" at a particular position'),mdx(\"p\",null,`This can indicate that part of the reads map well, but then there was an abrupt\nstop to the mapping. This might mean that there is a sequence that was an\ninsertion at that position, or a deletion, or a translocation.`),mdx(\"p\",null,\"The clipping is indicated by the \",mdx(\"inlineCode\",{parentName:\"p\"},\"CIGAR\"),` string, either at the start or end of\nit by an `,mdx(\"inlineCode\",{parentName:\"p\"},\"S\"),\" or an \",mdx(\"inlineCode\",{parentName:\"p\"},\"H\"),\". The \",mdx(\"inlineCode\",{parentName:\"p\"},\"S\"),` indicates \"soft clipping\", and indicates that\nthe sequence of the clipped portion can be found in the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SEQ\"),` field of the\nprimary alignment. The `,mdx(\"inlineCode\",{parentName:\"p\"},\"H\"),` is hard clipped, and the sequence that is hard\nclipped will not appear in the `,mdx(\"inlineCode\",{parentName:\"p\"},\"SEQ\"),\".\"),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/clipping_pileup.png\",alt:null}))),mdx(\"p\",null,`Screenshot of JBrowse 2 showing blue clipping indicator with a \"pileup\" of\nsoft-clipping at a particular position shown in blue. The clipping is an\n\"interbase\" operation (it occurs between base pair coordinates) so it is\nplotted separately from the normal coverage histogram.`),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/show_soft_clipping.png\",alt:null}))),mdx(\"p\",null,`Screenshot of JBrowse 2 showing an insertion with Nanopore (top), PacBio\n(middle) and Illumina short reads. The long reads may completely span the\ninsertion, so the CIGAR string on those have an `,mdx(\"inlineCode\",{parentName:\"p\"},\"I\"),` operator and are indicated\nby the purple triangle above the reads. For the short reads, the reads near the\ninsertion will be clipped since they will not properly map to the reference\ngenome and cannot span the sinsertion. The \"Show soft clipping\" setting in\nJBrowse 2 and IGV can be used to show visually the bases that extend into the\ninsertion (shown on the bottom track).`),mdx(\"h3\",null,\"Unexpected pair orientation\"),mdx(\"p\",null,\"With standard paired end sequencing, the pairs normally point at each other\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{}),`forward reverse\n --->    <---\n`)),mdx(\"p\",null,`If the stranded-ness of the pair is off, then it could indicate a structural\nvariant. See Appendix A for a handy function for calculating pair orientation.`),mdx(\"p\",null,`This guide from IGV is helpful for interpreting the pair directionality with\npatterns of SVs using \"Color by pair orientation\"`),mdx(\"p\",null,mdx(\"a\",e({parentName:\"p\"},{href:\"https://software.broadinstitute.org/software/igv/interpreting_pair_orientations\"}),\"https://software.broadinstitute.org/software/igv/interpreting_pair_orientations\")),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/inverted_duplication.png\",alt:null}))),mdx(\"p\",null,`Figure: This shows an inverted (tandem) duplication in 1000 genomes data. The\ntandem duplication can produce green arrows which have reads pointing in\nopposite directions e.g. `,mdx(\"inlineCode\",{parentName:\"p\"},\"<--\"),\" and \",mdx(\"inlineCode\",{parentName:\"p\"},\"-->\"),`, while blue arrows which can indicate\nan inversion point in the same direction e.g. `,mdx(\"inlineCode\",{parentName:\"p\"},\"-->\"),\" and \",mdx(\"inlineCode\",{parentName:\"p\"},\"-->\")),mdx(\"h3\",null,\"Caveat about TLEN\"),mdx(\"p\",null,\"Note that \",mdx(\"inlineCode\",{parentName:\"p\"},\"TLEN\"),` is a field in the SAM format that is somewhat ill defined,\nat least in the sense that different tools may use it differently\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/pysam-developers/pysam/issues/667#issuecomment-381521767\"}),\"https://github.com/pysam-developers/pysam/issues/667#issuecomment-381521767\")),mdx(\"p\",null,\"If needed, you can calculate \",mdx(\"inlineCode\",{parentName:\"p\"},\"TLEN\"),` yourself if you process the file yourself\n(e.g. process all reads, get the actual records for the pairs, and calculate\ndistance) but I have not had trouble with relying on the `,mdx(\"inlineCode\",{parentName:\"p\"},\"TLEN\"),` from the data\nfiles themselves.`),mdx(\"h2\",null,\"Calling copy number variants with your short or long reads\"),mdx(\"p\",null,\"Another type of SV that you can get from your \",mdx(\"inlineCode\",{parentName:\"p\"},\"SAM\"),` files are copy number\nvariants (CNVs). By looking at the depth-of-coverage for your data files, you\ncan look for abnormalities that may indicate copy number variants. By using a\ntool like `,mdx(\"inlineCode\",{parentName:\"p\"},\"mosdepth\"),`, you can quickly get a file showing the coverage across\nthe genome.`),mdx(\"p\",null,`Be aware that if you are comparing the coverage counts from different tools,\nthat they have different defaults that may affect comparison. Some discard\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"QC_FAIL\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"DUP\"),\", and \",mdx(\"inlineCode\",{parentName:\"p\"},\"SECONDARY\"),` flagged reads. This is probably appropriate,\nand corresponds to what most genome browsers will display (see\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://gist.github.com/cmdcolin/9f677eca28448d8a7c5d6e9917fc56af\"}),\"https://gist.github.com/cmdcolin/9f677eca28448d8a7c5d6e9917fc56af\"),` for a short\nsummary of depth calculated from different tools)`),mdx(\"p\",null,`Note that both long and short reads can be used for CNV detection. Long reads\nmay give more accurate measurements also, with their better ability to map\nsmoothly through difficult regions of the genome.`),mdx(\"p\",null,mdx(\"img\",e({parentName:\"p\"},{src:\"/media/coverage_cnv.png\",alt:null}))),mdx(\"p\",null,`Screenshot showing coverage in BigWig format from nanopore reads on normal and\ntumor tissue from a melanoma cancer cell line (COLO829) plotted using JBrowse 2\n(`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://jbrowse.org/code/jb2/v1.6.4/?config=test_data%2Fconfig_demo.json&session=share-MZj3d18lzH&password=3X7bS\"}),\"demo\"),`\nand\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://jbrowse.org/jb2/docs/user_guide/#viewing-whole-genome-coverage-for-profiling-cnv\"}),\"tutorial\"),\")\"),mdx(\"h2\",null,\"The future, with graph genomes and de-novo assemblies\"),mdx(\"p\",null,`Currently, SV visualization is highly based on comparing data versus a\nreference genome (and the SAM format is a signature of this: it stores data in\nterms of reference genome coordinates). In the future, SV visualization may\nlook more similar to comparative genomics, where we compare an SV to a\npopulation specific reference from a graph genomes or something like this.`),mdx(\"p\",null,`It is known that de-novo assembly has more power to detect SVs than some read\noperations (`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://twitter.com/lh3lh3/status/1362921612690010118/photo/1\"}),\"https://twitter.com/lh3lh3/status/1362921612690010118/photo/1\"),`) so\nas de novo assembled genomes improve and become more widespread, we may see a\nshift in how SVs are called`),mdx(\"p\",null,`I would also like to see improved ability to do fast or 'on the fly' gene\nprediction on the de novo assembled genomes, and we can see what SNPs or\nmodified splicing might occur in CNV copies of genes.`),mdx(\"h2\",null,\"Conclusion\"),mdx(\"p\",null,`Algorithms that actually call structural variants face many challenges, but\nunderstanding how the reads are encoded in SAM format, and seeing what they\nlook like in the genome browser is a useful first step to gaining a better\nunderstanding.`),mdx(\"p\",null,\"In summary, some of the signatures of SVs may include:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Aberrant insert size (\",mdx(\"inlineCode\",{parentName:\"li\"},\"TLEN\"),`) detection (longer for deletion, shorter for\ninsertion)`),mdx(\"li\",{parentName:\"ul\"},\"Split-read detection (\",mdx(\"inlineCode\",{parentName:\"li\"},\"SA\"),\" tag)\"),mdx(\"li\",{parentName:\"ul\"},\"CIGAR string processing (\",mdx(\"inlineCode\",{parentName:\"li\"},\"D\"),\" operator for deletions, \",mdx(\"inlineCode\",{parentName:\"li\"},\"I\"),` operator for\ninsertions)`),mdx(\"li\",{parentName:\"ul\"},\"Over-abundance of clipping (\",mdx(\"inlineCode\",{parentName:\"li\"},\"S\"),\" or \",mdx(\"inlineCode\",{parentName:\"li\"},\"H\"),\" operators in \",mdx(\"inlineCode\",{parentName:\"li\"},\"CIGAR\"),\")\"),mdx(\"li\",{parentName:\"ul\"},\"Depth of coverage changes for CNVs\"),mdx(\"li\",{parentName:\"ul\"},`Aligning de novo assembly vs a reference genome\n(`,mdx(\"a\",e({parentName:\"li\"},{href:\"https://twitter.com/lh3lh3/status/1362921612690010118/photo/1\"}),\"https://twitter.com/lh3lh3/status/1362921612690010118/photo/1\"),`) which can\noutput `,mdx(\"inlineCode\",{parentName:\"li\"},\"SAM\"),`, but it can also output\n`,mdx(\"a\",e({parentName:\"li\"},{href:\"https://github.com/lh3/miniasm/blob/master/PAF.md\"}),mdx(\"inlineCode\",{parentName:\"a\"},\"PAF\")),` format (which can\nbe loaded in JBrowse 2 in the synteny views). Techniques of detecting SVs on\nPAF will be fundamentally pretty similar to the techniques listed above but\nmay look a bit different (see `,mdx(\"inlineCode\",{parentName:\"li\"},\"cs\"),\" tag in PAF for example)\")),mdx(\"p\",null,\"If you have any ideas I should include here, let me know!\"),mdx(\"h3\",null,\"Appendix A: Parsing CIGAR strings\"),mdx(\"p\",null,`This is code that can help determine the pair orientation from a single BAM\nrecord. Might be too much detail but follow along`),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-typescript\"}),`// @param flags - flags from a single read\n// @param ref - the string of the reference sequence, just used to determine if it matches rnext\n// @param rnext - the string of the RNEXT, just used to determine if it matches ref\n// @param tlen - the TLEN field from SAM\n// @return e.g. F1R2 normal paired end orientation\nfunction getPairOrientation(\n  flags: number,\n  ref: string,\n  rnext: string,\n  tlen: number,\n) {\n  // this read is not unmapped &&\n  // this read's mate is also not unmapped &&\n  // this read's mate is on the same reference genome\n  if (!flags & 4 && !flags & 8 && ref === rnext) {\n    const s1 = flags & 16 ? 'R' : 'F'\n    const s2 = flags & 32 ? 'R' : 'F'\n    let o1 = ' '\n    let o2 = ' '\n\n    // if first in pair\n    if (flags & 64) {\n      o1 = '1'\n      o2 = '2'\n    }\n\n    // else if second in pair\n    else if (flags & 128) {\n      o1 = '2'\n      o2 = '1'\n    }\n\n    const tmp = []\n    if (tlen > 0) {\n      tmp[0] = s1\n      tmp[1] = o1\n      tmp[2] = s2\n      tmp[3] = o2\n    } else {\n      tmp[2] = s1\n      tmp[3] = o1\n      tmp[0] = s2\n      tmp[1] = o2\n    }\n    return tmp.join('')\n  }\n  return null\n}\n`)),mdx(\"p\",null,\"Then this can be broken down further by orientation type\"),mdx(\"p\",null,`Paired end reads are \"fr\"\nMate pair reads are \"rf\"`),mdx(\"p\",null,\"So you can interpret e.g. F1R2 in relation to being a paired end read (fr) or mate pair (rf) below and with this link \",mdx(\"a\",e({parentName:\"p\"},{href:\"https://software.broadinstitute.org/software/igv/interpreting_pair_orientations\"}),\"https://software.broadinstitute.org/software/igv/interpreting_pair_orientations\")),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-json\"}),`{\n  \"fr\": {\n    \"F1R2\": \"LR\",\n    \"F2R1\": \"LR\",\n\n    \"F1F2\": \"LL\",\n    \"F2F1\": \"LL\",\n\n    \"R1R2\": \"RR\",\n    \"R2R1\": \"RR\",\n\n    \"R1F2\": \"RL\",\n    \"R2F1\": \"RL\"\n  },\n\n  \"rf\": {\n    \"R1F2\": \"LR\",\n    \"R2F1\": \"LR\",\n\n    \"R1R2\": \"LL\",\n    \"R2R1\": \"LL\",\n\n    \"F1F2\": \"RR\",\n    \"F2F1\": \"RR\",\n\n    \"F1R2\": \"RL\",\n    \"F2R1\": \"RL\"\n  }\n}\n`)),mdx(\"h3\",null,\"Appendix B - CIGAR parsing\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-typescript\"}),`// @param cigar: CIGAR string in text form\nfunction parseCigar(cigar: string) {\n  return cigar.split(/([MIDNSHPX=])/)\n}\n`)),mdx(\"p\",null,\"Then parse the returned array two at a time\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-typescript\"}),`// this function does nothing, but is informative for how to parse interpret a\n// CIGAR string\n// @param cigar:CIGAR string from record\n// @param readSeq: the SEQ from record\n// @param refSeq: the reference sequence underlying the read\nfunction interpretCigar(cigar: string, readSeq: string, refSeq: string) {\n  const opts = parseCigar(cigar)\n  let qpos = 0 // query position, position on the read\n  let tpos = 0 // target position, position on the reference sequence\n  for (let i = 0; i < ops.length - 1; i += 2) {\n    const length = parseInt(opts[i], 10)\n    const operator = opts[i + 1]\n    // do things. refer to the CIGAR chart in SAMv1.pdf for which operators\n    // \"consume reference\" to see whether to increment\n    if (op === 'M' || op === '=') {\n      // matches consume query and reference\n      qpos += len\n      tpos += len\n    }\n    if (op === 'I') {\n      // insertions only consume query\n      // sequence of the insertion from the read is\n      const insSeq = readSeq.slice(qpos, qpos + len)\n      qpos += len\n    }\n    if (op === 'D') {\n      // deletions only consume reference\n      // sequence of the deletion from the reference is\n      const delSeq = refSeq.slice(tpos, tpos + len)\n      tpad += len\n    }\n    if (op === 'N') {\n      // skips only consume reference\n      // skips are similar to deletions but are related to spliced alignments\n      tpad += len\n    }\n    if (op === 'X') {\n      // mismatch using the extended CIGAR format\n      // could lookup the mismatch letter in a string containing the reference\n      const mismatch = refSeq.slice(tpos, tpos + len)\n      qpos += len\n      tpos += len\n    }\n    if (op === 'H') {\n      // does not consume query or reference\n      // hardclip is just an indicator\n    }\n    if (op === 'S') {\n      // softclip consumes query\n      // below gets the entire soft clipped portion\n      const softClipStr = readSeq.slice(qpos, qpos + len)\n      qpos += len\n    }\n  }\n}\n`)),mdx(\"p\",null,`Note for example, that to determine how long a record is on the reference\nsequence, you have to combine the records start position with the CIGAR string,\nbasically parsing the CIGAR string to add up tpos and return tpos`),mdx(\"h3\",null,\"Appendix C - align FASTQ directly to CRAM\"),mdx(\"p\",null,`This example from the htslib documentation\n(`,mdx(\"a\",e({parentName:\"p\"},{href:\"http://www.htslib.org/workflow/fastq.html\"}),\"http://www.htslib.org/workflow/fastq.html\"),`) shows how you can stream directly\nfrom `,mdx(\"inlineCode\",{parentName:\"p\"},\"FASTQ\"),\" to \",mdx(\"inlineCode\",{parentName:\"p\"},\"CRAM\"),\" (and generate the index file .crai too)\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`minimap2 -t 8 -a -x sr reference.fa reads1.fq reads2.fq  | \\\\\nsamtools fixmate -u -m - - | \\\\\nsamtools sort -u -@2 - | \\\\\nsamtools markdup -@8 --reference reference.fa - --write-index final.cram\n`)),mdx(\"p\",null,\"If you want, you can make this a little shell script, easy_align.sh\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`#!/bin/bash\nminimap2 -t 8 -a -x sr \"$1\" \"$2\" \"$3\"  | \\\\\nsamtools fixmate -u -m - - | \\\\\nsamtools sort -u -@2 - | \\\\\nsamtools markdup -@8 --reference \"$1\" - --write-index \"$4\"\n`)),mdx(\"p\",null,\"Then call\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`bash easy_align.sh ref.fa reads1.fq reads2.fq out.cram\n`)),mdx(\"p\",null,\"This same concept works with other common aligners as well like bwa\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"How to make your own npm package with typescript","date":"2021-12-31","slug":"2021-12-31-npm-package","mdxSource":{"compiledSource":"var c=Object.defineProperty,u=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var p=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var s=(a,n,t)=>n in a?c(a,n,{enumerable:!0,configurable:!0,writable:!0,value:t}):a[n]=t,e=(a,n)=>{for(var t in n||(n={}))p.call(n,t)&&s(a,t,n[t]);if(o)for(var t of o(n))r.call(n,t)&&s(a,t,n[t]);return a},l=(a,n)=>u(a,m(n));var d=(a,n)=>{var t={};for(var i in a)p.call(a,i)&&n.indexOf(i)<0&&(t[i]=a[i]);if(a!=null&&o)for(var i of o(a))n.indexOf(i)<0&&r.call(a,i)&&(t[i]=a[i]);return t};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(t){var i=t,{components:a}=i,n=d(i,[\"components\"]);return mdx(MDXLayout,l(e(e({},layoutProps),n),{components:a,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"There is a lot of mystery around making your own \",mdx(\"inlineCode\",{parentName:\"p\"},\"npm\"),` package. Every package\nlikely does it a bit differently, and it can be tricky to get a setup you like.\nShould you use a \"starter kit\" or a boilerplate example? Or just roll your own?\nShould you use a bundler? How do you use typescript?`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"*\",\"Record scratch \",\"*\",\"*\")),mdx(\"p\",null,\"Why don't we try starting from scratch and seeing where we can get?\"),mdx(\"p\",null,`TLDR: here is a github repo with a template package\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/cmdcolin/npm-package-tutorial/\"}),\"https://github.com/cmdcolin/npm-package-tutorial/\")),mdx(\"h2\",null,\"Introduction\"),mdx(\"p\",null,\"An \",mdx(\"inlineCode\",{parentName:\"p\"},\"npm\"),` package can be very bare bones. In some sense, npmjs.com is just an\narbitrary file host, and you can upload pretty much anything you want to it.`),mdx(\"p\",null,\"The magic is in the package.json file, which tells npm:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"what files are part of your package\"),mdx(\"li\",{parentName:\"ul\"},`what to use as the \"entry point\" (e.g. the file that should be referenced\nwhen you say `,mdx(\"inlineCode\",{parentName:\"li\"},\"const lib = require('mypackage')\"),\")\"),mdx(\"li\",{parentName:\"ul\"},`what pre- and post- processing steps should be done when the package is being\npublished`),mdx(\"li\",{parentName:\"ul\"},\"and more!\")),mdx(\"p\",null,\"Let's try an experiment...\"),mdx(\"h2\",null,\"Initializing a package\"),mdx(\"p\",null,\"Open up a terminal, and run\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`mkdir mypackage\ncd mypackage\ngit init # make mypackage version controlled\nnpm init\n# or\nyarn init\n`)),mdx(\"p\",null,\"This init command outputs something like this, and we accept the defaults\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`This utility will walk you through creating a package.json file.\nIt only covers the most common items, and tries to guess sensible defaults.\n\nSee \\`npm help init\\` for definitive documentation on these fields\nand exactly what they do.\n\nUse \\`npm install <pkg>\\` afterwards to install a package and\nsave it as a dependency in the package.json file.\n\nPress ^C at any time to quit.\npackage name: (mypackage)\nversion: (1.0.0)\ndescription:\nentry point: (index.js)\ntest command:\ngit repository:\nkeywords:\nlicense: (ISC)\nAbout to write to /home/cdiesh/mypackage/package.json:\n\n{\n  \"name\": \"mypackage\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\\\"Error: no test specified\\\\\" && exit 1\"\n  },\n  \"author\": \"Colin\",\n  \"license\": \"ISC\"\n}\n\n`)),mdx(\"p\",null,\"Then, you can create a file named \",mdx(\"inlineCode\",{parentName:\"p\"},\"index.js\"),` (in your package.json it says\n`,mdx(\"inlineCode\",{parentName:\"p\"},'\"main\": \"index.js\"'),\" to refer to this file, the entrypoint)\"),mdx(\"p\",null,\"In your \",mdx(\"inlineCode\",{parentName:\"p\"},\"index.js\"),` file, generally, you would do things like export a function\nor functions. I will use commonjs exports here for maximum compatibility:`),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-js\"}),`module.exports = {\n  hello: () => {\n    console.log('hello world')\n  },\n}\n`)),mdx(\"h2\",null,\"Publishing a package\"),mdx(\"p\",null,\"This npm package, \",mdx(\"inlineCode\",{parentName:\"p\"},\"mypackage\"),\" can now be published to \",mdx(\"inlineCode\",{parentName:\"p\"},\"npm\"),` with a simple\ncommand.`),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npm publish\n# or\nyarn publish\n`)),mdx(\"p\",null,`This will prompt you for your npmjs.com username, password, email, and if\nneeded, 2FA token (highly recommended)`),mdx(\"h2\",null,\"Using your package after it is published\"),mdx(\"p\",null,`Once it is published, you can use it in your create-react-app app or other npm\npackage.`),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npm install mypackage\n# or\nyarn add mypackage\n`)),mdx(\"p\",null,\"Then you can use\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-js\"}),`import { hello } from 'mypackage'\n`)),mdx(\"p\",null,\"in any of your other codebases\"),mdx(\"h2\",null,\"Summary of the simplest NPM package\"),mdx(\"p\",null,\"This all seems pretty boring thus far but it tells us a couple things\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},\"packages can be very very bare bones\"),mdx(\"li\",{parentName:\"ol\"},\"no transpiler or bundler is needed for publishing an npm package\"),mdx(\"li\",{parentName:\"ol\"},`our package can consist of a single file and it is uploaded to npm, and the\n\"main\" field in package.json provides an entry point`),mdx(\"li\",{parentName:\"ol\"},`the filename index.js is not special, probably it is a hangover from the\nname index.html. you can use whatever name you want`)),mdx(\"h2\",null,\"Adding typescript\"),mdx(\"p\",null,\"Let's try adding typescript\"),mdx(\"p\",null,`To do this, we will use the typescript compiler to compile a directory of files\nin our \"src\" directory and output the compiled files to a directory named\n\"dist\"`),mdx(\"p\",null,\"To start, let's add typescript\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npm install --save-dev typescript\n# or\nyarn add -D typescript\n`)),mdx(\"p\",null,\"Our package.json now will have \",mdx(\"inlineCode\",{parentName:\"p\"},\"typescript\"),\" in it's \",mdx(\"inlineCode\",{parentName:\"p\"},\"devDependencies\"),` (this\nmeans that when someone installs your package, it they don't get typescript as\na dependency, it is just a dependency for while you are developing the library\nlocally).`),mdx(\"p\",null,\"Then we need to create a tsconfig.json for typescript to use\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`yarn tsc --init\n# or\nnpx tsc --init\n`)),mdx(\"p\",null,\"This will generate a \",mdx(\"inlineCode\",{parentName:\"p\"},\"tsconfig.json\"),\" file (needed by \",mdx(\"inlineCode\",{parentName:\"p\"},\"typescript\"),`) with a bunch of\noptions, but I have stripped it down in my projects to look like this`),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-json\"}),`{\n  \"include\": [\"src\"],\n  \"compilerOptions\": {\n    \"target\": \"es2018\",\n    \"moduleResolution\": \"node\",\n    \"declaration\": true, // generate .d.ts files\n    \"sourceMap\": true, // generate source map\n    \"outDir\": \"dist\", // output compiled js, d.ts, and source map to dist folder\n    \"strict\": true,\n    \"esModuleInterop\": true\n  }\n}\n`)),mdx(\"p\",null,\"Now, we want to change our \",mdx(\"inlineCode\",{parentName:\"p\"},\"js\"),\" to \",mdx(\"inlineCode\",{parentName:\"p\"},\"ts\"),\" files to use \",mdx(\"inlineCode\",{parentName:\"p\"},\"typescript\"),`, let's change them\nto use normal ESM import/exports`),mdx(\"p\",null,\"util.ts\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-typescript\"}),`export function getMessage() {\n  return 'hello'\n}\n`)),mdx(\"p\",null,\"index.ts\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-typescript\"}),`import { getMessage } from './util'\nexport function sayMessage() {\n  console.log(getMessage())\n}\n`)),mdx(\"p\",null,\"And then we will add a \",mdx(\"inlineCode\",{parentName:\"p\"},'\"build\"'),\" script to \",mdx(\"inlineCode\",{parentName:\"p\"},\"package.json\"),` to compile the\nlibrary, and refer to the `,mdx(\"inlineCode\",{parentName:\"p\"},'\"dist\"'),\" directory for the \",mdx(\"inlineCode\",{parentName:\"p\"},'\"files\"'),\" and \",mdx(\"inlineCode\",{parentName:\"p\"},'\"main\"'),`\nfields in `,mdx(\"inlineCode\",{parentName:\"p\"},\"package.json\")),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-json\"}),`{\n  \"name\": \"mypackage\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"src/index.js\",\n  \"files\": [\"dist\"],\n  \"scripts\": {\n    \"build\": \"tsc\"\n  },\n  \"author\": \"Colin\",\n  \"license\": \"ISC\",\n  \"devDependencies\": {\n    \"typescript\": \"^4.5.4\"\n  }\n}\n`)),mdx(\"p\",null,\"We can now run\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npm run build\n# or\nyarn build\n`)),mdx(\"p\",null,\"And this will run the \",mdx(\"inlineCode\",{parentName:\"p\"},'\"build\"'),` script we created, which in turn, just runs\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"tsc\"),\" with no arguments.\"),mdx(\"p\",null,\"You can also add a \",mdx(\"inlineCode\",{parentName:\"p\"},'\"prebuild\"'),` script that clears out the old contents. In fact,\nnpm scripts generalizes the naming system -- you can make scripts with whatever name you want, e.g.`),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-json\"}),`{\n  \"scripts\": {\n    \"preparty\": \"echo preparty\",\n    \"party\": \"echo party\",\n    \"postparty\": \"echo postparty\"\n  }\n}\n`)),mdx(\"p\",null,\"Then running\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`$ yarn party\npreparty\nparty\npostparty\n`)),mdx(\"p\",null,\"To make this useful, we will use \",mdx(\"inlineCode\",{parentName:\"p\"},\"rimraf\"),` (a node package) to make a\ncross-platform removal of the `,mdx(\"inlineCode\",{parentName:\"p\"},\"dist\"),\" directory\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npm install --save-dev rimraf\n# or\nyarn add -D rimraf\n`)),mdx(\"p\",null,\"and then update your package.json\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-json\"}),`{\n  ...\n  \"scripts\": {\n    \"clean\": \"rimraf dist\",\n    \"prebuild\": \"npm run clean\",\n    \"build\": \"tsc\"\n  },\n  \"devDependencies\": {\n    \"rimraf\": \"^3.0.2\",\n    \"typescript\": \"^4.5.4\"\n  }\n}\n`)),mdx(\"p\",null,`We could make it say \"rm -rf dist\" instead of \"rimraf dist\" (e.g. run arbitrary\nshell commands), but rimraf allows it to be cross-platform`),mdx(\"h2\",null,\"Making sure you create a fresh build before you publish\"),mdx(\"p\",null,\"Without extra instructions, your \",mdx(\"inlineCode\",{parentName:\"p\"},\"yarn publish\"),` command would not create a\nfresh build and you could publish an older version that was lingering in the\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"dist\"),\" folder.\"),mdx(\"p\",null,\"We can use a \",mdx(\"inlineCode\",{parentName:\"p\"},\"preversion\"),` script that will automatically get invoked when you\nrun `,mdx(\"inlineCode\",{parentName:\"p\"},\"yarn publish\"),\" to make sure you get a fresh build in the \",mdx(\"inlineCode\",{parentName:\"p\"},\"dist\"),` folder\nbefore you publish`),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-json\"}),`{\n  ...\n  \"scripts\": {\n    ...\n    \"preversion\": \"npm run build\",\n  },\n}\n`)),mdx(\"h2\",null,\"Making sure you push your tag to github after publish\"),mdx(\"p\",null,\"When you run \",mdx(\"inlineCode\",{parentName:\"p\"},\"yarn publish\"),`, npm will automatically create a commit with the\nversion name and a git tag, it `,mdx(\"em\",{parentName:\"p\"},\"will not\"),` automatically push tag to your\nrepository.`),mdx(\"p\",null,\"Add a \",mdx(\"inlineCode\",{parentName:\"p\"},\"postversion\"),\" script that pushes the tag to your repo after your publish\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-json\"}),`{\n  ...\n  \"scripts\": {\n    ...\n    \"postversion\": \"git push --follow-tags\",\n  },\n}\n`)),mdx(\"h2\",null,\"Incremental builds\"),mdx(\"p\",null,\"We can use this to do incremental/watch builds\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{}),`npm run build --watch\n# or\nyarn build --watch\n`)),mdx(\"h2\",null,\"Adding testing with ts-jest\"),mdx(\"p\",null,\"You can use ts-jest to test your code. This involves installing jest, typescript, ts-jest, @types/jest, and then initializing a jest.config.json\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npm i -D jest typescript\n# or\nyarn add --dev jest typescript\n`)),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npm i -D ts-jest @types/jest\n# or\nyarn add --dev ts-jest @types/jest\n`)),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-sh\"}),`npx ts-jest config:init\n# or\nyarn ts-jest config:init\n`)),mdx(\"p\",null,\"We can then create a test\"),mdx(\"p\",null,mdx(\"inlineCode\",{parentName:\"p\"},\"test/util.spec.ts\")),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-typescript\"}),`import { getMessage } from '../src/util'\ntest('expected message returned', () => {\n  expect(getMessage()).toBe('hello')\n})\n`)),mdx(\"p\",null,\"Then we can then create a script in the package.json that says \",mdx(\"inlineCode\",{parentName:\"p\"},'\"test\": \"jest\"'),\", and then we can say\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{}),`npm run test\n# or\nyarn test\n`)),mdx(\"p\",null,\"You can also create an alternative system where you use \",mdx(\"inlineCode\",{parentName:\"p\"},\"babel-eslint\"),` and\nvarious babel strategies to test your code, but if you are using typescript,\nts-jest+typescript works great.`),mdx(\"h2\",null,\"Add a .gitignore\"),mdx(\"p\",null,\"Create a .gitignore with just a line that references this \",mdx(\"inlineCode\",{parentName:\"p\"},\"dist\"),\" folder and \",mdx(\"inlineCode\",{parentName:\"p\"},\"node_modules\"),\" folder\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{}),`dist\nnode_modules\n`)),mdx(\"h2\",null,\"The future of ESM modules\"),mdx(\"p\",null,`There is a shift happening where modules are changing to be pure ESM rather\nthan keeping commonjs equivalents`),mdx(\"p\",null,mdx(\"a\",e({parentName:\"p\"},{href:\"https://gist.github.com/sindresorhus/a39789f98801d908bbc7ff3ecc99d99c\"}),\"https://gist.github.com/sindresorhus/a39789f98801d908bbc7ff3ecc99d99c\")),mdx(\"p\",null,`There are many challenges here, and will not be discussed, but it may be a\nuseful further reading page`),mdx(\"h2\",null,\"Conclusion\"),mdx(\"p\",null,`This tutorial shows you how you can create a basic package that you can publish\nto `,mdx(\"inlineCode\",{parentName:\"p\"},\"npm\"),\". This little boilerplate includes these features:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Makes clean build when running \",mdx(\"inlineCode\",{parentName:\"li\"},\"yarn build\"),\" or \",mdx(\"inlineCode\",{parentName:\"li\"},\"yarn publish\")),mdx(\"li\",{parentName:\"ul\"},\"Pushes to github after publish\"),mdx(\"li\",{parentName:\"ul\"},\"Uses ts-jest for testing\"),mdx(\"li\",{parentName:\"ul\"},\"Uses esm modules\")),mdx(\"p\",null,`You also have full control, and understand the decisions we took to get to this\npoint. This package does not use any bundling (rollup or webpack or otherwise).\nIt just uses `,mdx(\"inlineCode\",{parentName:\"p\"},\"tsc\"),\" is used to compile the files to the \",mdx(\"inlineCode\",{parentName:\"p\"},\"dist\"),` folder, and the\ndist folder is published to `,mdx(\"inlineCode\",{parentName:\"p\"},\"npm\"),`! If you need your package to be usable by\nconsumers that don't themselves use bundlers, consider looking into `,mdx(\"inlineCode\",{parentName:\"p\"},'<script type=\"module\">'),` for importing ESM modules in the browser, or you can bundle\nyour library using rollup or webpack and output e.g. a UMD bundle`),mdx(\"h2\",null,\"Final product\"),mdx(\"p\",null,\"See \",mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/cmdcolin/npm-package-tutorial/\"}),\"https://github.com/cmdcolin/npm-package-tutorial/\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"My next.js static blog setup","date":"2021-12-26","slug":"2021-12-26-nextjs","mdxSource":{"compiledSource":"var d=Object.defineProperty,h=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,l=Object.prototype.propertyIsEnumerable;var r=(t,a,i)=>a in t?d(t,a,{enumerable:!0,configurable:!0,writable:!0,value:i}):t[a]=i,e=(t,a)=>{for(var i in a||(a={}))s.call(a,i)&&r(t,i,a[i]);if(o)for(var i of o(a))l.call(a,i)&&r(t,i,a[i]);return t},p=(t,a)=>h(t,c(a));var m=(t,a)=>{var i={};for(var n in t)s.call(t,n)&&a.indexOf(n)<0&&(i[n]=t[n]);if(t!=null&&o)for(var n of o(t))a.indexOf(n)<0&&l.call(t,n)&&(i[n]=t[n]);return i};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(i){var n=i,{components:t}=n,a=m(n,[\"components\"]);return mdx(MDXLayout,p(e(e({},layoutProps),a),{components:t,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`My personal homepage originally used statocles, a perl-based static site\ngenerator (`,mdx(\"a\",e({parentName:\"p\"},{href:\"http://preaction.me/statocles/\"}),\"http://preaction.me/statocles/\"),`). I didn't really blog using it, just\na homepage for myself plus some links to my tumblr blog. But, if I linked\npeople to the tumblr blog directly, it would give people terrible popup ads and\ntrackers. So, I switched to github pages+next.js this year. I considered a\nnumber of alternative static site systems, but next.js seemed to hit some nice\ngoals`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Flexible\"),mdx(\"li\",{parentName:\"ul\"},\"React-based (as opposed to template-based like jekyll, eleventy, etc.)\"),mdx(\"li\",{parentName:\"ul\"},\"Markdown driven, and can use MDX\"),mdx(\"li\",{parentName:\"ul\"},\"RSS feed (bonus)\"),mdx(\"li\",{parentName:\"ul\"},\"Active community\")),mdx(\"p\",null,\"Other systems almost worked and were attempted but aborted\"),mdx(\"h3\",null,\"First and second iterations\"),mdx(\"p\",null,\"The first iteration of my next.js blog\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},`I put every blog post in the \"pages\" folder. This worked ok but I had to\nmanually edit the index.mdx file to have long lists of stuff like this\n`,mdx(\"inlineCode\",{parentName:\"li\"},\"![link to new blogpost](manually_inserted_link_here)\"))),mdx(\"p\",null,`The second iteration, I wanted to automatically generate a list of recent\nblogposts from files on disk`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`I used the next.js \"blog-template-typescript\" example folder from their\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/vercel/next.js/tree/canary/examples/blog-starter-typescript\"}),\"monorepo\"),\".\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"The new blog posts are generated from markdown files in the \",mdx(\"inlineCode\",{parentName:\"p\"},\"_posts\"),` folder,\nand get rendered by the file `,mdx(\"inlineCode\",{parentName:\"p\"},\"pages/posts/[slug].tsx\"),` (yes, the filename\nincludes square brackets).`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"getAllPosts in\",mdx(\"br\",{parentName:\"p\"}),`\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/cmdcolin/cmdcolin.github.io/blob/master/lib/api.ts\"}),mdx(\"inlineCode\",{parentName:\"a\"},\"lib/api.ts\")),`\ngets a listing of the files in `,\"_\",\"posts folder, which I can call from the \",mdx(\"inlineCode\",{parentName:\"p\"},\"getStaticProps\"),\" method on next.js pages\"))),mdx(\"h3\",null,\"Stripping off unnecessary stuff from blog-starter-typescript\"),mdx(\"p\",null,\"The \",mdx(\"inlineCode\",{parentName:\"p\"},\"blog-starter-typescript\"),` template has many tiny components, I removed some\nof them to make it easier for me to orient myself`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",e({parentName:\"li\"},{href:\"https://github.com/vercel/next.js/tree/canary/examples/blog-starter-typescript/components\"}),\"theirs\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"a\",e({parentName:\"li\"},{href:\"https://github.com/cmdcolin/cmdcolin.github.io/tree/master/components\"}),\"mine\"))),mdx(\"h3\",null,\"Removing tailwind CSS\"),mdx(\"p\",null,\"The \",mdx(\"inlineCode\",{parentName:\"p\"},\"blog-starter-typescript\"),` template uses tailwind CSS and uses \"modern web design\" (aka:\ngigantic \"tiles\" instead of links, images that are way too large, etc)`),mdx(\"p\",null,`I started making a more basic design. I tried to roll with the tailwind CSS for\na bit, but ended up removing it entirely.`),mdx(\"p\",null,\"Tailwind CSS is sort of like a CSS-in-JS system, except every CSS attribute is encoded in a CSS classname. For example, here are some tailwind CSS snippets\"),mdx(\"pre\",null,mdx(\"code\",e({parentName:\"pre\"},{className:\"language-html\"}),`<div className=\"container mx-auto px-5\"></div>\n<footer className=\"bg-accent-1 border-t border-accent-2\"></footer>\n<div className=\"max-w-1xl mx-auto\"></div>\n<div className=\"min-h-screen\"></div>\n<a className=\"hover:underline\"></a>\n<h1\n  className=\"text-2xl md:text-2xl lg:text-2xl font-bold tracking-tighter leading-tight md:leading-none mb-12 text-center md:text-left\"\n></h1>\n`)),mdx(\"p\",null,`They claim this is better than using external CSS (see comparison here\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://tailwindcss.com/docs/utility-first\"}),\"https://tailwindcss.com/docs/utility-first\"),`) but it is yet another language to\nlearn, and kind of tricky.`),mdx(\"p\",null,`But, the reason I gave up with tailwind is actually because tailwind CSS resets\na lot of HTML styles so things like `,mdx(\"inlineCode\",{parentName:\"p\"},\"<h1>\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"<h2>\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"<ul>\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"<li>\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"<a>\"),` have\nno styling at all. This is done by `,mdx(\"inlineCode\",{parentName:\"p\"},\"tailwind preflight\"),`\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://tailwindcss.com/docs/preflight\"}),\"https://tailwindcss.com/docs/preflight\"),` (which you can disable, but it is\nenabled by default)`),mdx(\"p\",null,`Stackoverflow has some ways to help restore styling and keep preflight, but it\nstill struck me as odd. Examples`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"a\",e({parentName:\"p\"},{href:\"https://stackoverflow.com/a/68853223/2129219\"}),\"Example: you have to manually restore underlines on \",mdx(\"inlineCode\",{parentName:\"a\"},\"<a>\"),\" elements if using tailwind XSS\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"a\",e({parentName:\"p\"},{href:\"https://stackoverflow.com/questions/69264976/cant-display-markdown-on-nextjs\"}),`Another example: \"It looks like you're using TailwindCSS, the default\nstyles for elements are reset, that's why the h1 text will look like any other\ntext.\"`))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},mdx(\"a\",e({parentName:\"p\"},{href:\"https://raw.githubusercontent.com/vercel/next.js/canary/examples/blog-starter-typescript/components/markdown-styles.module.css\"}),\"Another example \",mdx(\"inlineCode\",{parentName:\"a\"},\"blog-template-typescript\"),` uses this file to try to style\nthe markdown using some general\nstyles`)))),mdx(\"p\",null,`To me it was surprising the extend that tailwind goes to unstyle the default\nbrowser styles, removing \"idiomatic HTML\" styles, so I removed tailwind for\nnow. Perhaps I'll return to it another time`),mdx(\"h2\",null,\"Using MDX for blogposts in next.js\"),mdx(\"p\",null,\"In the template from next.js team, the \",mdx(\"inlineCode\",{parentName:\"p\"},\"blog-template-typescript\"),`, it uses a\nfairly simple `,mdx(\"inlineCode\",{parentName:\"p\"},\"lib/markdownToHtml.ts\"),` function right in the\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"pages/posts/[slug].tsx\"),` file (the markdown is statically pre-rendered in the\ntrue static blog sense, using the getStaticProps function). This is,\nunfortunately, over-simplified for the MDX case, because MDX properly needs to\nhydrate the components using react on the client side also`),mdx(\"p\",null,\"To fix, the module \",mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/hashicorp/next-mdx-remote\"}),\"https://github.com/hashicorp/next-mdx-remote\"),` offers a way to\nload actual MDX files.`),mdx(\"h2\",null,\"Adding syntax highlighting the next.js code snippets\"),mdx(\"p\",null,`There are a couple results from google about how to add syntax highlighting to\nnext.js but I still found it difficult.`),mdx(\"p\",null,`My method ended up a bit different where I manually included the prism JS and\nCSS from a CDN essentially and it worked`),mdx(\"p\",null,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/cmdcolin/cmdcolin.github.io/blob/aa080193f45cb3e3d11ca1ead2bbd5eb2ae09633/styles/index.css#L14-L15\"}),\"https://github.com/cmdcolin/cmdcolin.github.io/blob/aa080193f45cb3e3d11ca1ead2bbd5eb2ae09633/styles/index.css#L14-L15\")),mdx(\"p\",null,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/cmdcolin/cmdcolin.github.io/blob/aa080193f45cb3e3d11ca1ead2bbd5eb2ae09633/pages/_document.tsx#L12-L17\"}),\"https://github.com/cmdcolin/cmdcolin.github.io/blob/aa080193f45cb3e3d11ca1ead2bbd5eb2ae09633/pages/_document.tsx#L12-L17\")),mdx(\"p\",null,`Other methods e.g. adding react-prism in next.config.js (like\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://github.com/mikeesto/next-mdx-prism-example\"}),\"https://github.com/mikeesto/next-mdx-prism-example\"),` does) I think clashed with\nMDXRemote perhaps, or maybe I was tussling with tailwind CSS too much to make a\nclear thought out of it, but syntax blocks on my blogposts should now be\nproperly highlighted`),mdx(\"h2\",null,\"RSS feed\"),mdx(\"p\",null,`I also followed this great guide to add a RSS file for next.js\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://ashleemboyer.com/how-i-added-an-rss-feed-to-my-nextjs-site\"}),\"https://ashleemboyer.com/how-i-added-an-rss-feed-to-my-nextjs-site\")),mdx(\"p\",null,`Link here, for your feed readers\n`,mdx(\"a\",e({parentName:\"p\"},{href:\"https://cmdcolin.github.io/rss.xml\"}),\"https://cmdcolin.github.io/rss.xml\")),mdx(\"p\",null,`Not many people may use RSS much anymore, but I do use it (via feedly), and I\nlove music blogs that keep posting on blogspot year after year, and the\noccasional programming post is nice too`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"A spooky error when you have a string bigger than 512MB in Chrome","date":"2021-10-30","slug":"2021-10-30-spooky","mdxSource":{"compiledSource":"var h=Object.defineProperty,d=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var p=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,i=Object.prototype.propertyIsEnumerable;var s=(e,t,o)=>t in e?h(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,a=(e,t)=>{for(var o in t||(t={}))r.call(t,o)&&s(e,o,t[o]);if(p)for(var o of p(t))i.call(t,o)&&s(e,o,t[o]);return e},l=(e,t)=>d(e,u(t));var c=(e,t)=>{var o={};for(var n in e)r.call(e,n)&&t.indexOf(n)<0&&(o[n]=e[n]);if(e!=null&&p)for(var n of p(e))t.indexOf(n)<0&&i.call(e,n)&&(o[n]=e[n]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var n=o,{components:e}=n,t=c(n,[\"components\"]);return mdx(MDXLayout,l(a(a({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"Now gather round for a spooky story\"),mdx(\"p\",null,`Late one night... in the haunted office space castle (hindenbugs cackling in\nthe background amongst the dusty technical books) the midnight candles were\nburning bright and we entered data for a user file`),mdx(\"p\",null,`A simple 52MB gzipped datafile that we want to process in the browser. We unzip\nit, decode it, and ...an error`),mdx(\"p\",null,\"ERROR: data not found\"),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"/media/pumpkin-dark.jpg\",alt:null}))),mdx(\"p\",null,'But... our code is so simple (we of course abide by the religion of writing \"simple code\" you know)...what could be happening?'),mdx(\"p\",null,\"The code looks like this\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`const buf = unzip(file)\nconst str = new TextDecoder().decode(buf)\n`)),mdx(\"p\",null,\"We trace it back and run a console.log(str)\"),mdx(\"p\",null,\"It looks empty. We try running console.log(str.length) ... it prints out 0\"),mdx(\"p\",null,\"But if we console.log(buffer.length) we get 546,483,710 bytes...\"),mdx(\"p\",null,\"What could be happening?\"),mdx(\"p\",null,'We see in the TextDecoder documentation that it has a note called \"fatal\". We try'),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`const buf = unzip(file)\nconst str = new TextDecoder('utf8', { fatal: true }).decode(buf)\n`)),mdx(\"p\",null,\"This doesn't change the results though\"),mdx(\"p\",null,`Then it dawns on us while the lightning hits and the thunderclap booms and the\nwind blows through the rattly windows`),mdx(\"p\",null,\"We have hit...the maximum string length in Chrome\"),mdx(\"p\",null,\"BWAHAHAHAHA\"),mdx(\"p\",null,\"The maximum string length!!! Nooooooo\"),mdx(\"p\",null,\"It is 512MB on the dot... 536,870,888 bytes. We test this to be sure\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`const len = 536_870_888\nconst buf = new Uint8Array(len)\nfor (let i = 0; i < len; i++) {\n  buf[i] = 'a'.charCodeAt(0)\n}\nconst str = new TextDecoder().decode(buf)\nconsole.log(str.length)\n`)),mdx(\"p\",null,\"This is correct, outputs 536,870,888\"),mdx(\"p\",null,\"With anything, even one byte more, it fails and outputs 0\"),mdx(\"p\",null,\"happy halloween!!\"),mdx(\"p\",null,\"pumpkin photo source: \",mdx(\"a\",a({parentName:\"p\"},{href:\"http://mountainbikerak.blogspot.com/2010/11/google-chrome-pumpkin.html\"}),\"http://mountainbikerak.blogspot.com/2010/11/google-chrome-pumpkin.html\")),mdx(\"p\",null,\"chrome 95 tested\"),mdx(\"p\",null,\"nodejs 15 - at 512MB+1 bytes it prints an error message \",mdx(\"inlineCode\",{parentName:\"p\"},\"Error: Cannot create a string longer than 0x1fffffe8 characters\"),` for significantly greater than 512MB\ne.g. 600MB it actually prints a different error `,mdx(\"inlineCode\",{parentName:\"p\"},\"TypeError [ERR_ENCODING_INVALID_ENCODED_DATA]: The encoded data was not valid for encoding utf-8\"),\")\"),mdx(\"p\",null,'firefox 93 - goes up to ~1GB but then gives Exception { name: \"NS_ERROR_OUT_OF_MEMORY\", message: \"\", result: 2147942414'),mdx(\"p\",null,\"midori 6 (safari-alike/webkit) - goes up to ~2GB fine! will have to test more\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Jest parallelization, globals, mocks, and squawkless tests","date":"2021-10-05","slug":"2021-10-05-jest","mdxSource":{"compiledSource":"var p=Object.defineProperty,h=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var a=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,l=Object.prototype.propertyIsEnumerable;var i=(e,t,o)=>t in e?p(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,r=(e,t)=>{for(var o in t||(t={}))n.call(t,o)&&i(e,o,t[o]);if(a)for(var o of a(t))l.call(t,o)&&i(e,o,t[o]);return e},c=(e,t)=>h(e,m(t));var u=(e,t)=>{var o={};for(var s in e)n.call(e,s)&&t.indexOf(s)<0&&(o[s]=e[s]);if(e!=null&&a)for(var s of a(e))t.indexOf(s)<0&&l.call(e,s)&&(o[s]=e[s]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var s=o,{components:e}=s,t=u(s,[\"components\"]);return mdx(MDXLayout,c(r(r({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I found that there is a little bit of confusion and misunderstanding around how\nthings like parallelization work in jest, which sometimes leads to additional\nhacking around problems that may not exist or speculating incorrectly about\ntest failure. This is also of course a point of concern when you have code that\nfor some reason or another uses global variables. Here are a short summary of\nthings that may cause confusion.`),mdx(\"h2\",null,\"Tests in a single file are NOT run in parallel\"),mdx(\"p\",null,`Simple example, the global variable r is included in the test condition, but it\nis accurately run in all cases because the tests are not run in parallel.`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`let r = 0\n\nfunction timeout(ms) {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n\ndescribe('tests', () => {\n  it('t1', async () => {\n    await timeout(1000)\n    expect(r).toBe(0)\n    r++\n  })\n  it('t2', async () => {\n    await timeout(1000)\n    expect(r).toBe(1)\n    r++\n  })\n  it('t3', async () => {\n    await timeout(1000)\n    expect(r).toBe(2)\n    r++\n  })\n})\n`)),mdx(\"p\",null,`This test will take 3 seconds, and will accurately count the global variable.\nIf it was in parallel, it may only take 1 second, and would inaccurately count\nthe global variable due to race conditions`),mdx(\"h2\",null,\"Tests in different files ARE run in parallel\"),mdx(\"p\",null,`Let's take another example where we use a global variable, and then two\ndifferent tests use the global variable.`),mdx(\"p\",null,\"file_using_some_globals.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`let myGlobal = 0\n\nexport function doStuff() {\n  myGlobal++\n  return myGlobal\n}\n\nexport function resetMyGlobal() {\n  myGlobal = 0\n}\n\nexport function timeout(ms) {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n`)),mdx(\"p\",null,\"test_global_vars1.test.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`import { doStuff, timeout } from './dostuff'\ntest('file1', async () => {\n  doStuff()\n  await timeout(1000)\n  expect(doStuff()).toEqual(2)\n})\n`)),mdx(\"p\",null,\"test_global_vars2.test.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`import { doStuff, timeout } from './dostuff'\n\ntest('file1', async () => {\n  await timeout(1000)\n  expect(doStuff()).toEqual(1)\n})\n`)),mdx(\"p\",null,`This test completes in less than 2 seconds, and these tests are run in\nparallel. They use different instances of the global state, and therefore have\nno worries with colliding their state.`),mdx(\"h2\",null,\"Does a mock from one test affect another test?\"),mdx(\"p\",null,`While seeking the fabled \"squawk-less\" test, it is often useful to mock console\nso that tests that produce an expected error don't actually print an error\nmessage. However, if not done carefully, you will remove errors across tests`),mdx(\"p\",null,`So, could a mock from one test affect another test? If it's in the same file,\nyes!`),mdx(\"p\",null,\"mock_console.test.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`test('test1', () => {\n  console.error = jest.fn()\n  console.error('wow')\n  expect(console.error).toHaveBeenCalled()\n})\n\ntest('test2', () => {\n  // this console.error will not appear because test1 mocked away console.error\n  // without restoring it\n  console.error(\"Help I can't see!\")\n})\n`)),mdx(\"p\",null,`To properly mock these, you should restore the console mock at the end of your\nfunction`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`test('test1', () => {\n  const orig = console.error\n  console.error = jest.fn()\n  console.error('I should not see this!')\n  expect(console.error).toHaveBeenCalled()\n  console.error = orig\n})\n\ntest('test2', () => {\n  const consoleMock = jest.spyOn(console, 'error').mockImplementation()\n  console.error('I should not see this!')\n  consoleMock.mockRestore()\n})\n\ntest('test3', () => {\n  console.error('I should see this error!')\n})\n`)),mdx(\"h2\",null,\"Add-on: Achieve squawkless tests!\"),mdx(\"p\",null,`Your test output should just be a big list of PASS statements, not interleaved\nwith console.error outputs from when you are testing error conditions of your\ncode`),mdx(\"p\",null,`\"Squawkless tests\" is a term I made up, but it means that if you have code\nunder test that prints some errors to the console, then mock the console.error\nfunction, as in the previous section. Don't stand for having a bunch of verbose\nerrors in your CI logs! However, I also suggest only mocking out console.error\nfor tests that are `,mdx(\"strong\",{parentName:\"p\"},\"expected\"),` to have errors, lest you paper over unexpected\nerrors.`),mdx(\"p\",null,mdx(\"img\",r({parentName:\"p\"},{src:\"/media/squawkless_tests.png\",alt:null}))),mdx(\"p\",null,\"Figure: a nice clean test suite without a bunch of crazy console.error outputs\"),mdx(\"h2\",null,\"Conclusion\"),mdx(\"p\",null,`Getting better at testing requires exercise, and understanding the basics of\nyour tools can help! Hopefully this helps you achieve a better understanding\nand write cleaner jest tests.`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Decrease your idle CPU usage when developing typescript apps with this one weird environment variable","date":"2021-09-05","slug":"2021-09-05-typescript","mdxSource":{"compiledSource":"var l=Object.defineProperty,u=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var p=(e,t,s)=>t in e?l(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s,i=(e,t)=>{for(var s in t||(t={}))n.call(t,s)&&p(e,s,t[s]);if(o)for(var s of o(t))r.call(t,s)&&p(e,s,t[s]);return e},h=(e,t)=>u(e,m(t));var c=(e,t)=>{var s={};for(var a in e)n.call(e,a)&&t.indexOf(a)<0&&(s[a]=e[a]);if(e!=null&&o)for(var a of o(e))t.indexOf(a)<0&&r.call(e,a)&&(s[a]=e[a]);return s};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(s){var a=s,{components:e}=a,t=c(a,[\"components\"]);return mdx(MDXLayout,h(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"TL;DR:\"),mdx(\"p\",null,\"add this to your bashrc\"),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`export TSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling\n`)),mdx(\"hr\",null),mdx(\"p\",null,`By default, the typescript watcher configuration e.g. tsc --watch or whatever\nis run internally to a create-react-app typescript app (I see it in the process\nmanager as fork-ts-checker-webpack-plugin cpu usage) can have high idling\n(doing nothing...) CPU usage`),mdx(\"p\",null,`This is because the default configuration polls for file changes (constantly\nasks the computer if there are changes every 250ms or so). There is an\nalternative configuration for this to change it to a file watcher so it\nreceives file system notifications on file change. There is discussion here on\nthis.`),mdx(\"p\",null,`The main summary is that a env variable set to\nTSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling allows this`),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/microsoft/TypeScript/issues/31048\"}),\"https://github.com/microsoft/TypeScript/issues/31048\")),mdx(\"p\",null,`The issue thread shows that it can go from roughly ~7% idle CPU usage to 0.2%.\nThis corresponds with what I see too after applying this! Detailed docs for\ntypescript discuss some of the reasoning behing not making this the default`),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/microsoft/TypeScript-Handbook/blob/master/pages/Configuring%20Watch.md#background\"}),\"https://github.com/microsoft/TypeScript-Handbook/blob/master/pages/Configuring%20Watch.md#background\")),mdx(\"p\",null,`It claims that some OS specific behaviors of file watching could be harmful to\nmaking it the default. For example, that (maybe?) on linux, it may use a large\nnumber of file watchers which can exceed notify handles (this is a setting I\ncommonly have to increase in linux, guide here\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://dev.to/rubiin/ubuntu-increase-inotify-watcher-file-watch-limit-kf4\"}),\"https://dev.to/rubiin/ubuntu-increase-inotify-watcher-file-watch-limit-kf4\"),\")\"),mdx(\"p\",null,\"PS: if you have a package.json of a \",mdx(\"inlineCode\",{parentName:\"p\"},\"create-react-app --template typescript\"),` or\nsomething like this then you can edit the package.json to apply this\nautomatically`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`-\"start\": \"react-scripts start\"\n+\"start\": \"cross-env TSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling react-scripts start\"\n`)),mdx(\"p\",null,`Phew. I can already feel my laptop running cooler...or at least I can sleep\nmore soundly knowing that my readers adopt this and save some CPU cycles for\nplanet earth...and hopefully don't run into any of the caveats`),mdx(\"p\",null,`Edit: It may be worth it to note, the 'UseFsEvents' part of this uses the\nnode.js fs.watch API and the polling based API is based on fs.watchFile`),mdx(\"p\",null,`Fun table of how the watchers are implemented on different OSs\n[`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/microsoft/TypeScript/issues/31048#issuecomment-495483957\"}),\"1\"),\"]\"),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`On Linux systems, this uses inotify(7).\nOn BSD systems, this uses kqueue(2).\nOn macOS, this uses kqueue(2) for files and FSEvents for directories.\nOn SunOS systems (including Solaris and SmartOS), this uses event ports.\nOn Windows systems, this feature depends on ReadDirectoryChangesW.\nOn Aix systems, this feature depends on AHAFS, which must be enabled.\n`)),mdx(\"p\",null,`And in general, these should all respond more or less the same, but there are\nsmall corner cases that are discussed\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://nodejs.org/docs/latest/api/fs.html#fs_availability\"}),\"https://nodejs.org/docs/latest/api/fs.html#fs_availability\")),mdx(\"p\",null,`Disclaimer: it may be worth reading the reasons that typescript does not have\nthis enabled by default before pushing this into your dev environment and all\nyour teammates, but as far as I could tell, it seems ok!`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"An amazing error message if you put more than 2^24 items in a JS Map object","date":"2021-08-15","slug":"2021-08-15-map-limit","mdxSource":{"compiledSource":"var l=Object.defineProperty,d=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var s=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,n=Object.prototype.propertyIsEnumerable;var m=(e,t,a)=>t in e?l(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,o=(e,t)=>{for(var a in t||(t={}))r.call(t,a)&&m(e,a,t[a]);if(s)for(var a of s(t))n.call(t,a)&&m(e,a,t[a]);return e},h=(e,t)=>d(e,u(t));var p=(e,t)=>{var a={};for(var i in e)r.call(e,i)&&t.indexOf(i)<0&&(a[i]=e[i]);if(e!=null&&s)for(var i of s(e))t.indexOf(i)<0&&n.call(e,i)&&(a[i]=e[i]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var i=a,{components:e}=i,t=p(i,[\"components\"]);return mdx(MDXLayout,h(o(o({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`One of the fun things about working with big data is that you can often hit\nweird limits with a system.`),mdx(\"p\",null,`I was personally trying to load every 'common' single nucleotide polymorphism\nfor the human genome into memory (dbSNP), of which there are over 37 million\nentries (there are many more uncommon ones) for the purposes of making a custom\nsearch index for them `,\"[1]\",\".\"),mdx(\"p\",null,`Turns out, you may run into some hard limits. Note that these are all V8-isms\nand may not apply to all browsers or engines (I was using node.js for this)`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`const myObject = new Map();\nfor (let i = 0; i <= 50_000_000; i++) {\n  myObject.set(i,i);\n  if(i%100000==0) { console.log(i) }\n}\n`)),mdx(\"p\",null,\"This will crash after adding approx 16.7M elements and say\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`0\n100000\n200000\n...\n16400000\n16500000\n16600000\n16700000\n\nUncaught RangeError: Value undefined out of range for undefined options\nproperty undefined\n`)),mdx(\"p\",null,`That is a very weird error message. It says \\u201Cundefined\\u201D three times! Much\nbetter than your usual \\u201CTypeError: Can\\u2019t find property \\u2018lol\\u2019 of undefined\\u201D. See\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://bugs.chromium.org/p/v8/issues/detail?id=11852\"}),\"https://bugs.chromium.org/p/v8/issues/detail?id=11852\"),` for a bug filed to help\nimprove the error message perhaps.`),mdx(\"p\",null,\"Now, also interestingly enough, if you use an Object instead of a Map\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-js\"}),`const myObject = {};\nfor (let i = 0; i <= 50_000_000; i++) {\n  myObject['myobj_\\u2019+i]=i;\n  if(i%100000==0) { console.log(i) }\n}\n`)),mdx(\"p\",null,\"Then it will print\\u2026.\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`0\n100000\n200000\n...\n8000000\n8100000\n8200000\n8300000\n`)),mdx(\"p\",null,`And it will actually just hang there\\u2026frozen\\u2026no error message though! And it is\nfailing at ~8.3M elements. Weird right? This is roughly half the amount of\nelements as the 16.7M case`),mdx(\"p\",null,\"Turns out there is a precise hard limit for the Map case\"),mdx(\"p\",null,\"For the Map: 2^24=16,777,216\"),mdx(\"p\",null,`For the Object it is around 2^23=8,388,608 HOWEVER, I can actually add more\nthan this, e.g. I can add 8,388,609 or 8,388,610 or even more, but the\noperations start taking forever to run, e.g. 8,388,999 was taking many minutes`),mdx(\"p\",null,`Very weird stuff! If you expected me to dig into this and explain it in deep\ntechnical detail, well, you\\u2019d be wrong. I am lazy. However, this helpful post\non stackoverflow by a V8 js engine developer clarifies the Map case!!\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://stackoverflow.com/questions/54452896/maximum-number-of-entries-in-node-js-map\"}),\"https://stackoverflow.com/questions/54452896/maximum-number-of-entries-in-node-js-map\")),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`V8 developer here. I can confirm that 2^24 is the maximum number of entries in\na Map. That\\u2019s not a bug, it\\u2019s just the implementation-defined limit.\n\nThe limit is determined by:\n\nThe FixedArray backing store of the Map has a maximum size of 1GB (independent\nof the overall heap size limit) On a 64-bit system that means 1GB / 8B = 2^30 /\n2^3 = 2^27 ~= 134M maximum elements per FixedArray A Map needs 3 elements per\nentry (key, value, next bucket link), and has a maximum load factor of 50% (to\navoid the slowdown caused by many bucket collisions), and its capacity must be\na power of 2. 2^27 / (3 * 2) rounded down to the next power of 2 is 2^24, which\nis the limit you observe.  FWIW, there are limits to everything: besides the\nmaximum heap size, there\\u2019s a maximum String length, a maximum Array length, a\nmaximum ArrayBuffer length, a maximum BigInt size, a maximum stack size, etc.\nAny one of those limits is potentially debatable, and sometimes it makes sense\nto raise them, but the limits as such will remain. Off the top of my head I\ndon\\u2019t know what it would take to bump this particular limit by, say, a factor\nof two \\u2013 and I also don\\u2019t know whether a factor of two would be enough to\nsatisfy your expectations.\n\n`)),mdx(\"p\",null,`Great details there. It would also be good to know what the behavior is for the\nObject, which has those 100% CPU stalls after ~8.3M, but not the same error\nmessage...`),mdx(\"p\",null,`Another fun note: if I modify the Object code to use only \\u201Cinteger IDs\\u201D the\ncode actually works fine, does not hit any errors, and is \\u201Cblazingly fast\\u201D as\nthe kids call it`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-js\"}),`const myObject = {}\nfor (let i = 0; i <= 50_000_000; i++) {\n  myObject[i] = i\n  if (i % 100000 == 0) {\n    console.log(i)\n  }\n}\n`)),mdx(\"p\",null,`I presume that this code works because it detects that I\\u2019m using it like an\narray and it decides to transform how it is working internally and not use a\nhash-map-style data structure, so does not hit a limit. There is a slightly\nhigher limit though, e.g. 1 billion elements gives \\u201CUncaught RangeError:\nInvalid array length\\u201D`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-js\"}),`const myObject = {}\nfor (let i = 0; i <= 1_000_000_000; i++) {\n  myObject[i] = i\n  if (i % 100000 == 0) {\n    console.log(i)\n  }\n}\n`)),mdx(\"p\",null,`This has been another episode of ....the twilight zone (other episodes\ncatalogued here) `,mdx(\"a\",o({parentName:\"p\"},{href:\"https://github.com/cmdcolin/technical_oddities/\"}),\"https://github.com/cmdcolin/technical_oddities/\")),mdx(\"p\",null,\"[1]\",` The final product of this adventure was this, to create a search index for\na large number of elements `,mdx(\"a\",o({parentName:\"p\"},{href:\"https://github.com/GMOD/ixixx-js\"}),\"https://github.com/GMOD/ixixx-js\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Do you understand your NPM dependencies?","date":"2021-07-27","slug":"2021-07-27-npm-dependencies","mdxSource":{"compiledSource":"var y=Object.defineProperty,m=Object.defineProperties;var d=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,l=Object.prototype.propertyIsEnumerable;var u=(e,a,o)=>a in e?y(e,a,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[a]=o,t=(e,a)=>{for(var o in a||(a={}))r.call(a,o)&&u(e,o,a[o]);if(n)for(var o of n(a))l.call(a,o)&&u(e,o,a[o]);return e},s=(e,a)=>m(e,d(a));var p=(e,a)=>{var o={};for(var i in e)r.call(e,i)&&a.indexOf(i)<0&&(o[i]=e[i]);if(e!=null&&n)for(var i of n(e))a.indexOf(i)<0&&l.call(e,i)&&(o[i]=e[i]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var i=o,{components:e}=i,a=p(i,[\"components\"]);return mdx(MDXLayout,s(t(t({},layoutProps),a),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`You are writing a library...or you are writing an app and you want to publish\nsome of the components of it as a library...`),mdx(\"p\",null,\"Here are some questions in the form of comments\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you realize that your yarn.lock will be ignored for anyone who installs\nyour libraries?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you realize this means that your perfectly running test suite with your\nyarn.lock could be a failing case for consumers of your app unless you don\\u2019t\nuse semver strings like ^1.0.0 and just hardcode it to 1.0.0?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you realize the default of ^1.0.0 automatically gets minor version bumps\nwhich are often fairly substantial changes, e.g. even breaking possibly?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you know that larger libraries like @material-ui/core don\\u2019t like to bump\ntheir major version all the time for example so large changes are often made\nto the minor version?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"Did you know if you run \",mdx(\"inlineCode\",{parentName:\"p\"},\"yarn upgrade\"),`, it may update what is in your\nyarn.lock file but will not update what is in your package.json?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you realize that this means that if you depend on the results of running\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"yarn upgrade\"),` e.g. it gave you a bugfix, you will be shipping buggy code to\nconsumers of your library?`))),mdx(\"p\",null,`Just something to be aware of! You can always ride the dragon and accept these\nminor breakages from semver bumps, but it can introduce some issues for your\nconsumers`),mdx(\"p\",null,`Random fun thing: Adding a yarn package can even downgrade some other packages.\nFor example if you have ^6.0.0 in your package.json, you yarn upgrade it so in\nthe lockfile it says 6.1.0 but then later install another library that requires\na hard 6.0.1, yarn will decide to downgrade you to 6.0.1 (it will not have a\nduplicate entry in yarn.lock, just that the 6.1.0 in the yarn.lock will\ndowngrade to 6.0.1)`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Making a HTTPS accessible S3 powered static site with CloudFront+route 53","date":"2020-12-26","slug":"2020-12-26-pt2","mdxSource":{"compiledSource":"var l=Object.defineProperty,m=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var p=(e,t,o)=>t in e?l(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,i=(e,t)=>{for(var o in t||(t={}))r.call(t,o)&&p(e,o,t[o]);if(n)for(var o of n(t))s.call(t,o)&&p(e,o,t[o]);return e},u=(e,t)=>m(e,c(t));var d=(e,t)=>{var o={};for(var a in e)r.call(e,a)&&t.indexOf(a)<0&&(o[a]=e[a]);if(e!=null&&n)for(var a of n(e))t.indexOf(a)<0&&s.call(e,a)&&(o[a]=e[a]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var a=o,{components:e}=a,t=d(a,[\"components\"]);return mdx(MDXLayout,u(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`This is not a very authoritative post because I stumbled though this but\nI think I got it working now on my website :)`),mdx(\"h2\",null,\"Setup your S3 bucket\"),mdx(\"p\",null,`First setup your S3 bucket, your bucket must be named yourdomain.com\ne.g. named after your domain`),mdx(\"p\",null,`Then if you have a create-react-app setup I add a script in package.json\nthat runs`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),` \"predeploy\": \"npm run build\",\n \"deploy\": \"aws sync --delete build s3://yourdomain.com\"\n`)),mdx(\"p\",null,`Then we can run \"yarn deploy\" and it will automatically upload our\ncreate-react-app website to our S3 static site bucket.`),mdx(\"p\",null,`Then make sure your bucket has public permissions enabled\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\"}),\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\"),`Then\nmake sure your bucket has \"static site hosting\" enabled too`),mdx(\"h2\",null,\"Setup route 53, and make your NS entries in domains.google.com\"),mdx(\"p\",null,\"I bought a domain with domains.google.com\"),mdx(\"p\",null,\"Google then emailed me to validate my ownership\"),mdx(\"p\",null,\"Then I went to aws.amazon.com route 53\\xA0and I created a hosted zone\"),mdx(\"p\",null,`This generated 4 name server entries and I added those to the\ndomains.google.com site`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/638618421776515072_0.png\",alt:null}))),mdx(\"p\",null,`Screenshot shows copying the NS values from route 53 to the name servers\narea of domains.google.com`),mdx(\"h2\",null,\"Setup your Amazon certificate for making SSL work on CloudFront\"),mdx(\"p\",null,`To properly setup However, this does not work so you need to go to\nAmazon Certificates->Provision certificates`),mdx(\"p\",null,\"We request the certificate for\"),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"http://www.yourdomain.com\"}),\"www.yourdomain.com\"),`\nyourdomain.com`),mdx(\"p\",null,`Then it generates some codes for a CNAME value for each of those two\nentries, and has a button to autoimport those CNAME values to route53`),mdx(\"p\",null,`Then it will say\\xA0\"Pending validation\"...I waited like an hour and then\nit changed to\\xA0\"Success\".`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/638618421776515072_1.png\",alt:null}))),mdx(\"p\",null,`Screenshot shows the now successful Amazon Certificate. After you get\nthis, you can proceed to finishing your cloudfront`),mdx(\"h2\",null,'Create a CloudFront distribution and add \"Alternative CNAME\" entries for your domain'),mdx(\"p\",null,`Then we can update our CloudFront distribution and add these to\nthe\\xA0\"Alternative CNAME\" input box`),mdx(\"p\",null,`yourdomain.com\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://www.yourdomain.com\"}),\"www.yourdomain.com\")),mdx(\"p\",null,`Note also that I first generated my certificate in us-east-2 but the\n\"Import certificate form\" in cloudfront said I had to create it in\nus-east-1`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/638618421776515072_2.png\",alt:null}))),mdx(\"h2\",null,\"Add a default object index.html to the CloudFront setting\"),mdx(\"p\",null,'Make your CloudFront\\xA0\"default object\" is index.html'),mdx(\"p\",null,\"You have to manually type this in :)\"),mdx(\"h2\",null,\"Add the CloudFront distribution to your Route 53\"),mdx(\"p\",null,`Add a Route 53 \"A\" record that points to the CloudFront domain name e.g.\nd897d897d87d98dd.cloudfront.net`),mdx(\"h2\",null,\"Summary of steps needed\"),mdx(\"p\",null,\"The general hindsight 20/20 procedure is\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},`Upload your static content to an S3 bucket called yoursite.com (must\nbe your domain name)`),mdx(\"li\",{parentName:\"ol\"},`Make your S3 bucket have the \"static website\" setting on in the\nproperties menu and add a permissions policy that supports getObject\ne.g.\\xA0`,mdx(\"a\",i({parentName:\"li\"},{href:\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\"}),\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\")),mdx(\"li\",{parentName:\"ol\"},\"Create a CloudFront distribution for your website\"),mdx(\"li\",{parentName:\"ol\"},\"Make the CloudFront default object index.html\"),mdx(\"li\",{parentName:\"ol\"},\"Create your domain with domains.google.com or similar\"),mdx(\"li\",{parentName:\"ol\"},\"Point the google domain's name server to Route 53 NS list from AWS\"),mdx(\"li\",{parentName:\"ol\"},`Add Route 53 A records that point to the CloudFront domain name e.g.\nd897d897d87d98dd.cloudfront.net`),mdx(\"li\",{parentName:\"ol\"},`Create Amazon issued certificate for yourdomain.com, which can\nauto-import a validation CNAME to your Route 53`),mdx(\"li\",{parentName:\"ol\"},`Make your CloudFront domain support your Alternative CNAME's e.g.\nyourdomain.com which requires importing (e.g. selecting from a list\nthat they auto-populate) your Amazon-issued-certificate`)),mdx(\"h2\",null,\"Troubleshooting and notes\"),mdx(\"p\",null,`Problem: Your website gives 403 CloudFlare error\nSolution: You have to get the Alternateive CNAME configuration setup\n(pre-step involves the certificate request and validation)`),mdx(\"p\",null,`Problem: Your website gives an object not found error\nSolution: Set the CloudFront \"default object\" to index.html`),mdx(\"h2\",null,\"Random comment\"),mdx(\"p\",null,`This is one of those processes (creating the cloudfront/route 53) that\nprobably could have done with the aws-sam CLI and it would have possibly\nbeen easier, it is quite fiddly doing all these steps in the web\ninterface`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Making a serverless website for photo and video upload pt. 2","date":"2020-12-26","slug":"2020-12-26","mdxSource":{"compiledSource":"var c=Object.defineProperty,m=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var i=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var l=(e,t,o)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,a=(e,t)=>{for(var o in t||(t={}))i.call(t,o)&&l(e,o,t[o]);if(n)for(var o of n(t))r.call(t,o)&&l(e,o,t[o]);return e},p=(e,t)=>m(e,u(t));var d=(e,t)=>{var o={};for(var s in e)i.call(e,s)&&t.indexOf(s)<0&&(o[s]=e[s]);if(e!=null&&n)for(var s of n(e))t.indexOf(s)<0&&r.call(e,s)&&(o[s]=e[s]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var s=o,{components:e}=s,t=d(s,[\"components\"]);return mdx(MDXLayout,p(a(a({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`This post follows\non\\xA0`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://cmdcolin.github.io/2020-12-24.html\"}),\"https://cmdcolin.github.io/2020-12-24.html\")),mdx(\"p\",null,`It is possible I zoomed ahead too fast to make this a continuous\ntutorial, but overall I just wanted to post an update`),mdx(\"p\",null,\"In pt. 1 I learned how to use the \",mdx(\"inlineCode\",{parentName:\"p\"},\"aws-sam\"),` CLI tool. This was a great\ninsight for me about automating deployments. I can now simply run `,mdx(\"inlineCode\",{parentName:\"p\"},\"sam deploy\"),\" and it will create new dynamodb tables, lambda functions, etc.\"),mdx(\"p\",null,`After writing pt 1. I converted the existing vue-js app that was in the\naws tutorial and converted it to react. Then I extended the app to allow`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Posting comments on photos\"),mdx(\"li\",{parentName:\"ul\"},\"Uploading multiple files\"),mdx(\"li\",{parentName:\"ul\"},`Uploading videos\netc.`)),mdx(\"p\",null,`It will be hard to summarize all the changes since now the app has taken\noff a little bit but it looks like this:`),mdx(\"p\",null,\"Repo structure\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` ./frontend # created using npx create-react-app frontend --template\n typescript\n ./frontend/src/App.tsx # main frontend app code in react\n ./lambdas/\n ./lambdas/postFile # post a file to the lambda, this uploads a row to\n dynamodb and returns a pre-signed URL for uploading (note that if the\n client failed it's upload, that row in the lambda DB might be in a bad\n state...)\n ./lambdas/getFiles # get all files that were ever posted\n ./lambdas/postComment # post a comment on a picture with POST\n request\n ./lambdas/getComments?file=filename.jpg # get comments on a\n picture/video with GET request\n`)),mdx(\"p\",null,`Here is a detailed code for uploading the file. We upload one file at a\ntime, but the client code post to the lambda endpoint individually for\neach file`),mdx(\"p\",null,`This generates a pre-signed URL to allow the client-side JS (not the\nlambda itself) to directly upload to S3, and also posts a row in the S3\nto the filename that will. It is very similar code in\nto\\xA0`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://cmdcolin.github.io/2020-12-24.html\"}),\"https://cmdcolin.github.io/2020-12-24.html\")),mdx(\"p\",null,\"./lambdas/postFile/app.js\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`'use strict'\n\nconst AWS = require('aws-sdk')\nconst multipart = require('./multipart')\nAWS.config.update({ region: process.env.AWS_REGION })\nconst s3 = new AWS.S3()\n\n// Change this value to adjust the signed URL's expiration\nconst URL_EXPIRATION_SECONDS = 300\n\n// Main Lambda entry point\nexports.handler = async event => {\n  return await getUploadURL(event)\n}\n\nconst { AWS_REGION: region } = process.env\n\nconst dynamodb = new AWS.DynamoDB({ apiVersion: '2012-08-10', region })\n\nasync function uploadPic({\n  timestamp,\n  filename,\n  message,\n  user,\n  date,\n  contentType,\n}) {\n  const params = {\n    Item: {\n      timestamp: {\n        N: \\`\\${timestamp}\\`,\n      },\n      filename: {\n        S: filename,\n      },\n      message: {\n        S: message,\n      },\n      user: {\n        S: user,\n      },\n      date: {\n        S: date,\n      },\n      contentType: {\n        S: contentType,\n      },\n    },\n    TableName: 'files',\n  }\n  return dynamodb.putItem(params).promise()\n}\n\nconst getUploadURL = async function (event) {\n  try {\n    const data = multipart.parse(event)\n    const { filename, contentType, user, message, date } = data\n    const timestamp = +Date.now()\n    const Key = \\`\\${timestamp}-\\${filename}\\` // Get signed URL from S3\n\n    const s3Params = {\n      Bucket: process.env.UploadBucket,\n      Key,\n      Expires: URL_EXPIRATION_SECONDS,\n      ContentType: contentType, // This ACL makes the uploaded object publicly readable. You must also uncomment // the extra permission for the Lambda function in the SAM template.\n\n      ACL: 'public-read',\n    }\n\n    const uploadURL = await s3.getSignedUrlPromise('putObject', s3Params)\n\n    await uploadPic({\n      timestamp,\n      filename: Key,\n      message,\n      user,\n      date,\n      contentType,\n    })\n\n    return JSON.stringify({\n      uploadURL,\n      Key,\n    })\n  } catch (e) {\n    const response = {\n      statusCode: 500,\n      body: JSON.stringify({ message: \\`\\${e}\\` }),\n    }\n    return response\n  }\n}\n`)),mdx(\"p\",null,\"./lambdas/getFiles/app.js\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`// eslint-disable-next-line import/no-unresolved\nconst AWS = require('aws-sdk')\n\nconst { AWS_REGION: region } = process.env\n\nconst docClient = new AWS.DynamoDB.DocumentClient()\n\nconst getItems = function () {\n  const params = {\n    TableName: 'files',\n  }\n\n  return docClient.scan(params).promise()\n}\n\nexports.handler = async event => {\n  try {\n    const result = await getItems()\n    return {\n      statusCode: 200,\n      body: JSON.stringify(result),\n    }\n  } catch (e) {\n    return {\n      statusCode: 400,\n      body: JSON.stringify({ message: \\`\\${e}\\` }),\n    }\n  }\n}\n`)),mdx(\"p\",null,\"./frontend/src/App.tsx (excerpt)\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-tsx\"}),`async function myfetch(params: string, opts?: any) {\n  const response = await fetch(params, opts)\n  if (!response.ok) {\n    throw new Error(\\`HTTP \\${response.status}\n \\${response.statusText}\\`)\n  }\n  return response.json()\n}\n\nfunction UploadDialog({\n  open,\n  onClose,\n}: {\n  open: boolean\n  onClose: () => void\n}) {\n  const [images, setImages] = useState<FileList>()\n  const [error, setError] = useState<Error>()\n  const [loading, setLoading] = useState(false)\n  const [total, setTotal] = useState(0)\n  const [completed, setCompleted] = useState(0)\n  const [user, setUser] = useState('')\n  const [message, setMessage] = useState('')\n  const classes = useStyles()\n\n  const handleClose = () => {\n    setError(undefined)\n    setLoading(false)\n    setImages(undefined)\n    setCompleted(0)\n    setTotal(0)\n    setMessage('')\n    onClose()\n  }\n\n  return (\n    <Dialog onClose={handleClose} open={open}>\n      \\xA0 \\xA0 \\xA0<DialogTitle>upload a file (supports picture or video)</DialogTitle>\\xA0\n      \\xA0 \\xA0<DialogContent>\n        \\xA0 \\xA0 \\xA0 \\xA0<label htmlFor=\"user\">name (optional) </label>\n        \\xA0 \\xA0 \\xA0 \\xA0<input\n          type=\"text\"\n          value={user}\n          onChange={event => setUser(event.target.value)}\n          id=\"user\"\n        />\n        \\xA0 \\xA0 \\xA0 \\xA0<br />\\xA0 \\xA0 \\xA0 \\xA0<label htmlFor=\"user\">message (optional) </label>\n        \\xA0 \\xA0 \\xA0 \\xA0\n        <input\n          type=\"text\"\n          value={message}\n          onChange={event => setMessage(event.target.value)}\n          id=\"message\"\n        />\n        \\xA0 \\xA0 \\xA0 \\xA0<br />\n        \\xA0 \\xA0 \\xA0 \\xA0\n        <input\n          multiple\n          type=\"file\"\n          onChange={e => {\n            let files = e.target.files\n            if (files && files.length) {\n              setImages(files)\n            }\n          }}\n        />\n        \\xA0 \\xA0 \\xA0 \\xA0{error ? (\n          <div className={classes.error}>{\\`\\${error}\\`}</div>\n        ) : loading ? (\n          \\`Uploading...\\${completed}/\\${total}\\`\n        ) : completed ? (\n          <h2>Uploaded </h2>\n        ) : null}\\xA0 \\xA0 \\xA0 \\xA0\n        <DialogActions>\n          \\xA0 \\xA0 \\xA0 \\xA0 \\xA0\n          <Button\n            style={{ textTransform: 'none' }}\n            onClick={async () => {\n              try {\n                if (images) {\n                  setLoading(true)\n                  setError(undefined)\n                  setCompleted(0)\n                  setTotal(images.length)\n                  await Promise.all(\n                    Array.from(images).map(async image => {\n                      const data = new FormData()\n                      data.append('message', message)\n                      data.append('user', user)\n                      data.append('date', new Date().toLocaleString())\n                      data.append('filename', image.name)\n                      data.append('contentType', image.type)\n                      const res = await myfetch(API_ENDPOINT + '/postFile', {\n                        method: 'POST',\n                        body: data,\n                      })\n\n                      await myfetch(res.uploadURL, {\n                        method: 'PUT',\n                        body: image,\n                      })\n\n                      setCompleted(completed => completed + 1)\n                    }),\n                  )\n                  setTimeout(() => {\n                    handleClose()\n                  }, 500)\n                }\n              } catch (e) {\n                setError(e)\n              }\n            }}\n            color=\"primary\"\n          >\n            \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0upload \\xA0 \\xA0 \\xA0 \\xA0 \\xA0\n          </Button>\n          \\xA0 \\xA0 \\xA0 \\xA0 \\xA0<Button\n            onClick={handleClose}\n            color=\"primary\"\n            style={{ textTransform: 'none' }}\n          >\n            \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0cancel \\xA0 \\xA0 \\xA0 \\xA0 \\xA0\n          </Button>\\xA0 \\xA0 \\xA0 \\xA0\n        </DialogActions>\n        \\xA0 \\xA0 \\xA0\n      </DialogContent>\\xA0 \\xA0\n    </Dialog>\n  )\n}\n`)),mdx(\"p\",null,\"template.yaml for AWS\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` AWSTemplateFormatVersion: 2010-09-09\n Transform: AWS::Serverless-2016-10-31\n Description: S3 Uploader\n\n Resources:\n \\xA0filesDynamoDBTable:\n \\xA0 \\xA0Type: AWS::DynamoDB::Table\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0AttributeDefinitions:\n \\xA0 \\xA0 \\xA0 \\xA0- AttributeName: \"timestamp\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0AttributeType: \"N\"\n \\xA0 \\xA0 \\xA0KeySchema:\n \\xA0 \\xA0 \\xA0 \\xA0- AttributeName: \"timestamp\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0KeyType: \"HASH\"\n \\xA0 \\xA0 \\xA0ProvisionedThroughput:\n \\xA0 \\xA0 \\xA0 \\xA0ReadCapacityUnits: \"5\"\n \\xA0 \\xA0 \\xA0 \\xA0WriteCapacityUnits: \"5\"\n \\xA0 \\xA0 \\xA0TableName: \"files\"\n\n \\xA0# HTTP API\n \\xA0MyApi:\n \\xA0 \\xA0Type: AWS::Serverless::HttpApi\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0# CORS configuration - this is open for development only and\n should be restricted in prod.\n \\xA0 \\xA0 \\xA0# See\n <https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-property-httpapi-httpapicorsconfiguration.html>\n \\xA0 \\xA0 \\xA0CorsConfiguration:\n \\xA0 \\xA0 \\xA0 \\xA0AllowMethods:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- GET\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- POST\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- DELETE\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- OPTIONS\n \\xA0 \\xA0 \\xA0 \\xA0AllowHeaders:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n \\xA0 \\xA0 \\xA0 \\xA0AllowOrigins:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n\n \\xA0UploadRequestFunction:\n \\xA0 \\xA0Type: AWS::Serverless::Function\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0CodeUri: lambdas/postFile/\n \\xA0 \\xA0 \\xA0Handler: app.handler\n \\xA0 \\xA0 \\xA0Runtime: nodejs12.x\n \\xA0 \\xA0 \\xA0Timeout: 3\n \\xA0 \\xA0 \\xA0MemorySize: 128\n \\xA0 \\xA0 \\xA0Environment:\n \\xA0 \\xA0 \\xA0 \\xA0Variables:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0UploadBucket: !Ref S3UploadBucket\n \\xA0 \\xA0 \\xA0Policies:\n \\xA0 \\xA0 \\xA0 \\xA0- AmazonDynamoDBFullAccess\n \\xA0 \\xA0 \\xA0 \\xA0- S3WritePolicy:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0BucketName: !Ref S3UploadBucket\n \\xA0 \\xA0 \\xA0 \\xA0- Statement:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- Effect: Allow\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Resource: !Sub \"arn:aws:s3:::\\${S3UploadBucket}/\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Action:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- s3:putObjectAcl\n \\xA0 \\xA0 \\xA0Events:\n \\xA0 \\xA0 \\xA0 \\xA0UploadAssetAPI:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Type: HttpApi\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Path: /postFile\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Method: post\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0ApiId: !Ref MyApi\n\n\n \\xA0FileReadFunction:\n \\xA0 \\xA0Type: AWS::Serverless::Function\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0CodeUri: lambdas/getFiles/\n \\xA0 \\xA0 \\xA0Handler: app.handler\n \\xA0 \\xA0 \\xA0Runtime: nodejs12.x\n \\xA0 \\xA0 \\xA0Timeout: 3\n \\xA0 \\xA0 \\xA0MemorySize: 128\n \\xA0 \\xA0 \\xA0Policies:\n \\xA0 \\xA0 \\xA0 \\xA0- AmazonDynamoDBFullAccess\n \\xA0 \\xA0 \\xA0Events:\n \\xA0 \\xA0 \\xA0 \\xA0UploadAssetAPI:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Type: HttpApi\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Path: /getFiles\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Method: get\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0ApiId: !Ref MyApi\n\n \\xA0## S3 bucket\n \\xA0S3UploadBucket:\n \\xA0 \\xA0Type: AWS::S3::Bucket\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0CorsConfiguration:\n \\xA0 \\xA0 \\xA0 \\xA0CorsRules:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- AllowedHeaders:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0AllowedMethods:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- GET\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- PUT\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- HEAD\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0AllowedOrigins:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n\n\n ## Take a note of the outputs for deploying the workflow templates\n in this sample application\n Outputs:\n \\xA0APIendpoint:\n \\xA0 \\xA0Description: \"HTTP API endpoint URL\"\n \\xA0 \\xA0Value: !Sub\n \"https://\\${MyApi}.execute-api.\\${AWS::Region}.amazonaws.com\"\n \\xA0S3UploadBucketName:\n \\xA0 \\xA0Description: \"S3 bucket for application uploads\"\n \\xA0 \\xA0Value: !Ref \"S3UploadBucket\"\n\n`)),mdx(\"p\",null,`To display all the pictures I use a switch from video or img tag based\non contentType.startsWith('video'). I also use the\\xA0\"figcaption\" HTML tag\nto have a little caption on the pics/videos`),mdx(\"p\",null,\"./frontend/src/App.tsx\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` function Media({\n \\xA0file,\n \\xA0style,\n \\xA0onClick,\n \\xA0children,\n }: {\n \\xA0file: File;\n \\xA0onClick?: Function;\n \\xA0style?: React.CSSProperties;\n \\xA0children?: React.ReactNode;\n }) {\n \\xA0const { filename, contentType } = file;\n \\xA0const src = \\`\\${BUCKET}/\\${filename}\\`;\n \\xA0return (\n \\xA0 \\xA0<figure style={{ display: \"inline-block\" }}>\n \\xA0 \\xA0 \\xA0<picture>\n \\xA0 \\xA0 \\xA0 \\xA0{contentType.startsWith(\"video\") ? (\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0<video style={style} src={src} controls onClick={onClick as\n any} />\n \\xA0 \\xA0 \\xA0 \\xA0) : (\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0<img style={style} src={src} onClick={onClick as any} />\n \\xA0 \\xA0 \\xA0 \\xA0)}\n \\xA0 \\xA0 \\xA0</picture>\n \\xA0 \\xA0 \\xA0<figcaption>{children}</figcaption>\n \\xA0 \\xA0</figure>\n \\xA0);\n }\n`)),mdx(\"p\",null,`Now the really fun part: if you get an image of a picture frame\nlike\\xA0`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://www.amazon.com/Paintings-Frames-Antique-Shatterproof-Osafs2-Gld-A3/dp/B06XNQ8W9T\"}),\"https://www.amazon.com/Paintings-Frames-Antique-Shatterproof-Osafs2-Gld-A3/dp/B06XNQ8W9T\")),mdx(\"p\",null,\"You can make it a border for any image or video using border-image CSS\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` \\xA0 \\xA0 style = {\n \\xA0 \\xA0 \\xA0 \\xA0 border: \"30px solid\",\n \\xA0 \\xA0 \\xA0 \\xA0 borderImage: \\`url(borders/\\${border}) 30 round\\`\n \\xA0 \\xA0 }\n`)),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"/media/638602799897329664_0.png\",alt:null}))),mdx(\"p\",null,\"Summary\"),mdx(\"p\",null,`The template.yaml automatically deploys the lambdas for postFile/getFile\nand the files table in dynamoDB`),mdx(\"p\",null,\"The React app uses postFile for each file in an \",mdx(\"inlineCode\",{parentName:\"p\"},'<input type=\"file\"/>'),`,\nthe code uses React hooks and functional components but is hopefully not\ntoo complex`),mdx(\"p\",null,`I also added commenting on photos. The code is not shown here but you\ncan look in the source code for details`),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"/media/638602799897329664_1.png\",alt:null}))),mdx(\"p\",null,`Overall this has been a good experience learning to develop this app and\nlearning to automate the cloud deployment is really good for ensuring\nreliability and fast iteration.`),mdx(\"p\",null,`Also quick note on serverless CLI vs aws-sam. I had tried a serverless\nCLI tutorial from another user but it didn't click with me, while the\naws-sam tutorial from\n`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://searchvoidstar.tumblr.com/post/638408397901987840/making-a-serverless-website-for-photo-upload-pt-1\"}),\"https://searchvoidstar.tumblr.com/post/638408397901987840/making-a-serverless-website-for-photo-upload-pt-1\"),`\\xA0was\na great kick start for me. I am sure the serverless CLI is great too and\nit ensures a bit less vendor lock in, but then is also a little bit\nremoved from the native aws config schemas. Probably fine though`),mdx(\"p\",null,\"Source code\\xA0\",mdx(\"a\",a({parentName:\"p\"},{href:\"https://github.com/cmdcolin/aws_photo_gallery/\"}),\"https://github.com/cmdcolin/aws_photo_gallery/\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Making a serverless website for photo upload pt. 1","date":"2020-12-24","slug":"2020-12-24","mdxSource":{"compiledSource":"var u=Object.defineProperty,m=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var i=Object.getOwnPropertySymbols;var p=Object.prototype.hasOwnProperty,n=Object.prototype.propertyIsEnumerable;var l=(e,t,a)=>t in e?u(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,s=(e,t)=>{for(var a in t||(t={}))p.call(t,a)&&l(e,a,t[a]);if(i)for(var a of i(t))n.call(t,a)&&l(e,a,t[a]);return e},r=(e,t)=>m(e,c(t));var d=(e,t)=>{var a={};for(var o in e)p.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&i)for(var o of i(e))t.indexOf(o)<0&&n.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=d(o,[\"components\"]);return mdx(MDXLayout,r(s(s({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I set out to make a serverless website for photo uploads. Our dearly\ndeparted dixie dog needed a place to have photo uploads.`),mdx(\"p\",null,`I didn't want to get charged dollars per month for a running ec2\ninstance, so I wanted something that was lightweight e.g. serverless,\nand easy`),mdx(\"p\",null,\"I decided to follow this tutorial\"),mdx(\"p\",null,mdx(\"a\",s({parentName:\"p\"},{href:\"https://aws.amazon.com/blogs/compute/uploading-to-amazon-s3-directly-from-a-web-or-mobile-application/\"}),\"https://aws.amazon.com/blogs/compute/uploading-to-amazon-s3-directly-from-a-web-or-mobile-application/\")),mdx(\"p\",null,`I really liked the command line deployment (aws-sam) because fiddling\naround with the AWS web based control panel is ridiculously complicated`),mdx(\"p\",null,`For example I also tried following this tutorial which uses the web\nbased UI (`,mdx(\"a\",s({parentName:\"p\"},{href:\"https://www.youtube.com/watch?v=mw_-0iCVpUc\"}),\"https://www.youtube.com/watch?v=mw_-0iCVpUc\"),`) and it just did\nnot work for me....I couldn't stay focused (blame ADHD or just my CLI\nobsession?) and certain things like\\xA0\"Execution role\" that they say to\nmodify are not there in the web UI anymore, so I just gave up (I did try\nthough!)`),mdx(\"p\",null,\"To install aws-sam I used homebrew\"),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),` brew tap aws/tap\n brew install aws-sam-cli\n brew install aws-sam-cli # I had to run the install command twice ref\\xA0https://github.com/aws/aws-sam-cli/issues/2320#issuecomment-721414971\n\n git clone https://github.com/aws-samples/amazon-s3-presigned-urls-aws-sam\n cd amazon-s3-presigned-urls-aws-sam\n sam deploy --guided\n\n # proceeeds with a guided installation, I used all defaults except I\n made\\xA0\"UploadRequestFunction may not have authorization defined, Is\n this okay? [y/N]: y\"\n`)),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_0.png\",alt:null}))),mdx(\"p\",null,\"They then in the tutorial describe trying to use postman to test\"),mdx(\"p\",null,\"I test with \",mdx(\"inlineCode\",{parentName:\"p\"},\"curl\"),\" instead\"),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),`curl 'https://fjgbqj5436.execute-api.us-east-2.amazonaws.com/uploads' {\"uploadURL\":\"https://sam-app-s3uploadbucket-1653634.s3.us-east-2.amazonaws.com/112162.jpg?Content-Type=image%2Fjpeg&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAU6CQBER6YBNCDDMJ%2F20201224%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20201224T174804Z&X-Amz-Expires=300&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDIaCXVzLWVhc3QtMiJGMEQCIH65IvgJsofUpIX46lTaG3Pi5WC85ti1lukM3iICh%2BB%2BAiAJEyynPNPhZN8%2Bg1ylO7wthqud9cBcNIChIp2H%2F%2BR7mCryAQjb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDMzOTQ3MDI2MzQyMSIMLqPo1IYyH7udCGZuKsYBSEF3c50YXkmPeSWcLsEzq%2BFBTpeOIrwZTyCUjbJ7fgJUakhM1YRX40jExstN8eJcMXqw00Xd5lYHvZDbU9ajwWPLRAxcEN5BQ0utqn0NGTLyJhibzJUj8cjgm5RguIEKe9GUtMVWa9mi7C5%2FlFpS0i9jK5BSVf74JyPSLETV5mzMMzy5kHBQMGjw1dR66E3MG8PjIqfgKjhVtZmlaicf5OmeqNI2%2F8T5ye%2FICRsH4d7KNEmj4FELa8buW8U%2Fn97ThfH3P7XmMNOok%2F8FOuEBDj1EHluCT4DfZ1jIXjvrJsVv1WtV4POQDn2Dah%2BWosBn%2BFNTtQtw841ACDarYR1ZVbuwcpTjfBPlGuSOncPsbzOhzDy7wYyumsPKsXoPdxTncMWbx4BQkbU5SeF9hjpfIKRMSOqkJBN7%2BtgHXwuW1rfYMDN2OAlQZpTj7uWMPWojUMbvMzyHvI2pfgcRAlrBdGGYDigyjWl9QXP%2Bdi6WiR7XCSXbWcIAJDZh%2Beb%2BIH1asmMJtpAK6nMP8gWczaYh7PMeYyVOIs2B20xQBy%2Bz7oe%2BYQ2GfdEr2hgqPH3jd%2B7c&X-Amz-Signature=11b8cd524c25ef51193e3b3fc4816760ebcde8bfc74bd52f3f91d8bf409620f5&X-Amz-SignedHeaders=host\",\"Key\":\"112162.jpg\"}%\\xA0\n\n`)),mdx(\"p\",null,`The premise of this is you make a request, and then the response from\nthe API is a pre-signed URL that then allows you to upload directly to\nS3. You can use `,mdx(\"inlineCode\",{parentName:\"p\"},\"curl <url> --upload-file yourfile.jpg\"),`. This\nautomatically does a PUT request to the s3 bucket (yes, this is talking\ndirectly to s3 now, not the lambda! the lambda is just for generating\nthe \"pre-signed URL\" to let you upload). Careful to copy it exactly as\nis`),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),` curl \"https://sam-app-s3uploadbucket-1653634.s3.us-east-2.amazonaws.com/112162.jpg?Content-Type=image%2Fjpeg&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAU6CQBER6YBNCDDMJ%2F20201224%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20201224T174804Z&X-Amz-Expires=300&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDIaCXVzLWVhc3QtMiJGMEQCIH65IvgJsofUpIX46lTaG3Pi5WC85ti1lukM3iICh%2BB%2BAiAJEyynPNPhZN8%2Bg1ylO7wthqud9cBcNIChIp2H%2F%2BR7mCryAQjb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDMzOTQ3MDI2MzQyMSIMLqPo1IYyH7udCGZuKsYBSEF3c50YXkmPeSWcLsEzq%2BFBTpeOIrwZTyCUjbJ7fgJUakhM1YRX40jExstN8eJcMXqw00Xd5lYHvZDbU9ajwWPLRAxcEN5BQ0utqn0NGTLyJhibzJUj8cjgm5RguIEKe9GUtMVWa9mi7C5%2FlFpS0i9jK5BSVf74JyPSLETV5mzMMzy5kHBQMGjw1dR66E3MG8PjIqfgKjhVtZmlaicf5OmeqNI2%2F8T5ye%2FICRsH4d7KNEmj4FELa8buW8U%2Fn97ThfH3P7XmMNOok%2F8FOuEBDj1EHluCT4DfZ1jIXjvrJsVv1WtV4POQDn2Dah%2BWosBn%2BFNTtQtw841ACDarYR1ZVbuwcpTjfBPlGuSOncPsbzOhzDy7wYyumsPKsXoPdxTncMWbx4BQkbU5SeF9hjpfIKRMSOqkJBN7%2BtgHXwuW1rfYMDN2OAlQZpTj7uWMPWojUMbvMzyHvI2pfgcRAlrBdGGYDigyjWl9QXP%2Bdi6WiR7XCSXbWcIAJDZh%2Beb%2BIH1asmMJtpAK6nMP8gWczaYh7PMeYyVOIs2B20xQBy%2Bz7oe%2BYQ2GfdEr2hgqPH3jd%2B7c&X-Amz-Signature=11b8cd524c25ef51193e3b3fc4816760ebcde8bfc74bd52f3f91d8bf409620f5&X-Amz-SignedHeaders=host\" --upload-file test.jpg\n`)),mdx(\"p\",null,`There is no response, but I can then check the s3 console and see the\nfile upload is successful (all files are renamed)`),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_1.png\",alt:null}))),mdx(\"p\",null,\"Figure shows that the file upload is successful :)\"),mdx(\"p\",null,`Then we can edit the file frontend/index.html from the repo we cloned to\ncontain the lambda with the /uploads/ suffix`),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_2.png\",alt:null}))),mdx(\"p\",null,\"Figure shows editing the index.html with the lambda endpoint\"),mdx(\"p\",null,`Then we manually upload this file to another s3 bucket or test it\nlocally`),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),` aws s3 cp index.html s3://mybucket/\n\n\n# then ...visit that in the browser\n`)),mdx(\"p\",null,`At this point the files are getting uploaded but not publically\naccessible. To make them publically accessible we uncomment the\nACL:\\xA0'public-read' in the getSignedURL/app.js folder in the github repo`),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_3.png\",alt:null}))),mdx(\"p\",null,\"Figure showing the public-read uncommented\"),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_4.png\",alt:null}))),mdx(\"p\",null,`Figure showing the lines that need uncommenting in template.yaml in the\nroot of the github repo that allows putObject in s3 with the public-read\nACL`),mdx(\"p\",null,\"Re-run \",mdx(\"inlineCode\",{parentName:\"p\"},\"sam deploy --guided\"),\", same thing as at the start\"),mdx(\"p\",null,\"Now the objects are publicly accessible!\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Challenges I have faced learning React","date":"2020-07-04","slug":"2020-07-04","mdxSource":{"compiledSource":"var h=Object.defineProperty,c=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var r=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,i=Object.prototype.propertyIsEnumerable;var l=(e,t,a)=>t in e?h(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,o=(e,t)=>{for(var a in t||(t={}))s.call(t,a)&&l(e,a,t[a]);if(r)for(var a of r(t))i.call(t,a)&&l(e,a,t[a]);return e},d=(e,t)=>c(e,u(t));var p=(e,t)=>{var a={};for(var n in e)s.call(e,n)&&t.indexOf(n)<0&&(a[n]=e[n]);if(e!=null&&r)for(var n of r(e))t.indexOf(n)<0&&i.call(e,n)&&(a[n]=e[n]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var n=a,{components:e}=n,t=p(n,[\"components\"]);return mdx(MDXLayout,d(o(o({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Learning React was a big challenge for me. I started learning React in earnest\nin 2019. It was a difficult experience overall, but I wanted to go over my\nlearning experience, and maybe find some lessons in the mix. This goes mostly\ninto personal details and doesn't really get too technical, however, I review\nthe commit logs and try and backtrace my feelings that I remember at the time.`),mdx(\"p\",null,`If I were to take away anything from this, it's probably that pair programming\nwas really useful especially as a remote worker, I had nothing before that\nexcept weekly standups where I felt really depressed. Also stay patient, stay\nthankful, and try to focus while you learn`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Introduction to me\")),mdx(\"p\",null,`I am maybe what you'd call a front-end engineer. I have done web development\nfor about 7 years now. I worked on various fast-becoming-legacy projects and\ngreenfield that were made in Ruby, PHP, Perl CGI, Java servlets, etc.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Early dabbles with React circa 2016\")),mdx(\"p\",null,\"I had a random \",mdx(\"inlineCode\",{parentName:\"p\"},\"<form>\"),` that I was tasked with making and I wanted to code and\nwanted to try using React. I tried importing React via a CDN\\xA0 and gave it a\nshot, and it seemed simple enough, but I kept getting really confused about how\nto even read and initialize the value of a textbox for example properly. TLDR:\nI was not aware of what a `,mdx(\"em\",{parentName:\"p\"},\"controlled component\"),\" was.\"),mdx(\"p\",null,`The idea of controlled components (not a word in my vocabulary at the time) was\nquite unintuitive and instead, I kept googling weird things like \"two way data\nbinding react\" and variants of this. I had never used Angular but I heard of\ntwo-way data binding from Angular, and I just felt like it was what I needed.\nI even posted about my frustrations about this on the React subreddit and was\ndownvoted. Felt bad. I was just really confused. I abandoned the project in\nReact and just used our normal jqueryish thing.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"New job in 2018\")),mdx(\"p\",null,`When I got a call about a new job in 2018, I was really happy and started in\nJune 2018. They decided they are going to do \"the big rewrite\" and are going to\nuse React. My coworker started building the new React app prototype. My\ncoworker keeps asking me \"what state management library should we use\". I just\nhad no idea about React still, I had not ever looked into state management, and\nbasically just was like \"I dunno!\". I had no way to form an opinion. I was also\nworking on some misc stuff sort of unrelated to the rewrite and remained pretty\nout of the loop. We would have weekly meetings but I just wouldn't really\nunderstand the goings ons. The project started using mobx-state-tree and I saw\nthem start to write fresh code for the project but things like prop-types just\nwere confusing to me, e.g. there were the mobx-state-tree model types, and\nsuddenly and the React prop-types and it was still the days of class-based\nReact components. I couldn't get any clear idea of what was happening`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"I am floundering...not understanding what's going on with the rewrite\")),mdx(\"p\",null,`It's December 2018, I go home for Christmas and I have an honest talk with my\nparents and tell them\\xA0\"I don't get what is happening in the new codebase, I'm\nhonestly unhappy, and it just does all this\\xA0'React' stuff\" but I can't explain\nReact to them I just say the code is automatically reacting to other things. My\nparents say \"well if you are unhappy you might have to leave your job\" and they\nare not like, cheering for me to leave, but they tell me that. At this point,\nit really hit me that I do like this job and I decided to try to focus on work.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},`I try and make an honest attempt to get involved in the project, start pair\nprogramming`)),mdx(\"p\",null,`On January 10th 2019 I make my first commit to the rewrite by doing some\nmonkey-see monkey-do type coding. I copy a bunch of files and just put them in\nthe right place, tweak some lines, and start to figure out how to make things\nrun. By the end of January 2019 I get my first code change merged.`),mdx(\"p\",null,\"I also suggested that we start doing \",mdx(\"strong\",{parentName:\"p\"},\"pair-programming sessions\"),`. Once I\nstarted these it made a huge difference for me in learning how to code. The\npair programming often still way over my head due to how my coworker presented\nstuff or how much he assumed I understood. Nevertheless, these were extremely\nhelpful for me to help get caught up.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},'I start to reading \"Learning React\"')),mdx(\"p\",null,`In March 2019, I got the book \"Learning React\" (O'Reilly2017\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://www.oreilly.com/library/view/learning-react/9781491954614/\"}),\"https://www.oreilly.com/library/view/learning-react/9781491954614/\"),`) for my\nkindle.\\xA0 Reading this book was a big help I felt, and provided a needed \"brain\nreset\" for me. The book worked well for me, I read it each night on my kindle,\nand the function component concepts were super enlightening. To me it was so\nmuch better reading a book than, say, an internet tutorial. With the book, I\ncould focus, not have distractions, etc. My eyes would just glaze over every\ntime I clicked on internet tutorials and stuff before this.`),mdx(\"p\",null,`So anyways, March 2019 goes on, and I'm learning, but our codebase still feels\npretty complicated and alien. We use mobx-state-tree and the glue for\nmobx-state-tree to React e.g. the mobx-react doesn't really make sense to me. I\nremember asking my coworkers why my component was not updating and they\neventually find out it's because I keep not using the observe() wrapper around\nmy components.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"I start to experiment with Typescript\")),mdx(\"p\",null,`In April 2019 I start to experiment with typescript and release a typescript\nversion of some data parsing code. I start by explicity specifying a lot of\ntypes but I eventually start getting\\xA0into the zen of \"type inference\" and I\nturn off the @typescript-eslint/explicit-function-return-type so I get implied\nreturn types.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"I start using React hooks\")),mdx(\"p\",null,`In May 2019 I try out my first React hook, a useState. It worked well. I\ncouldn't really figure out why I would use it instead of the mobx state\nmanagement we used elsewhere, but the example was that it was a click and drag\nand it made sense to keep that click and drag state local to the component\nrather than the\\xA0\"app\"`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"I start using react-testing-library\")),mdx(\"p\",null,`In June 2019, I create \"integration test\" level tests for our app. I had used\nreact-testing-library for some components before this, but this was using\nreact-testing-library to render the entire \"app level\" component. I was happy\nto pioneer this and was happy to try this out instead of doing true browser\ntests, and I think this has worked out well.`),mdx(\"p\",null,`Some caveats: I got very caught up with trying to do canvas tests initially. I\nreally wanted to use jest-mock-canvas but we were using offscreencanvas via a\npretty complicated string of things, so I don't make progress here, and I also\ngot confused about the relationship between node-canvas and jest-mock-canvas\n(they are basically totally different approaches). Later on, I find using\njest-image-snapshot of the canvas contents works nice (ref\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://stackoverflow.com/questions/33269093/how-to-add-canvas-support-to-my-tests-in-jest\"}),\"https://stackoverflow.com/questions/33269093/how-to-add-canvas-support-to-my-tests-in-jest\"),\")\"),mdx(\"p\",null,`Other random note: when building out the integration tests, we got a lot\nof\\xA0\"act warnings\" which were confusing. These were fixed in React 16.9\n(released August 2019), but we had to ignore them and they basically just\nconfused me a lot and made it feel like I was battling a very complex system\nrather than a nice simple one.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Conclusions\")),mdx(\"p\",null,`Overall, I just wanted to write up my whole experience. It felt really\ndifficult for me to make these changes. I also went through a breakup during\nthis time, had a bad living situation, etc. so things were a struggle. If\nanyone else has had struggles learning React, tell your story, and let me know.\nI'd like to also thank everyone who helped me along the way. I feel like a much\nbetter coder now, yet, I should always keep growing. The feeling of\nuncomfortableness could be a growing experience.`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Misconceptions your team might have during The Big Rewrite","date":"2020-06-03","slug":"2020-06-03","mdxSource":{"compiledSource":"var d=Object.defineProperty,c=Object.defineProperties;var p=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,i=Object.prototype.propertyIsEnumerable;var l=(e,t,o)=>t in e?d(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,r=(e,t)=>{for(var o in t||(t={}))s.call(t,o)&&l(e,o,t[o]);if(n)for(var o of n(t))i.call(t,o)&&l(e,o,t[o]);return e},h=(e,t)=>c(e,p(t));var u=(e,t)=>{var o={};for(var a in e)s.call(e,a)&&t.indexOf(a)<0&&(o[a]=e[a]);if(e!=null&&n)for(var a of n(e))t.indexOf(a)<0&&i.call(e,a)&&(o[a]=e[a]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var a=o,{components:e}=a,t=u(a,[\"components\"]);return mdx(MDXLayout,h(r(r({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Disclaimer: I enjoy the project I am working on and this is still a work\nin progress. I just had to rant about the stuff I go through in my job\nhere, but it does not reflect the opinions of my emplorer, and my\npersonal opinion is despite these troubles we are coming along nicely`),mdx(\"p\",null,`I joined a team that was doing the big rewrite in 2018. I was involved\nin the project before then and knew it's ins and outs, and frankly think\nit's still a great system. In order to break it's\\xA0\"limitations\" a grand\nv2 gets started. I think my team has been good. My tech lead is really\ngood at architecture. Where I really resist kind of\\xA0\"writing new\narchitecture that is not already there\", he can pull up entirely new\nconcepts and abstractions that are all pretty good. Myself, I don't much\nenjoy writing \"new architecture\" if there is something already there\nthat I can use, and I'll try to refer to the existence of an existing\nthing instead of creating new exotic stuff.`),mdx(\"p\",null,`Now, what happened during the big rewrite so far. 4 people on the team,\n2 years in`),mdx(\"p\",null,\"Persistent confusion about sources of slowness in our app\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},`it's only slow because devtools is open (maybe it is! but this is\ndefinitely a red herring. the code should work with devtools open.\nreason that's been stated: devtools adds a \"bunch of instrumentation to\nthe promises that slows it down\"...stated without any evidence during a\n3 hour long planning call...)\n\\xA0- it's only slow because we're using a development build of react, try\na production build (the production build makes some stuff faster, but it\nis NOT going to save your butt if you are constantly rerending all your\ncomponents unnecessarily every millisecond during user scroll, which is\nsomething we suffered from, and it creeps back in if you are not careful\nbecause you can't write tests against this so often one day I'll be\nlooking at my devtools and suddenly things are rendering twice per frame\n(signature of calling an unnecessary setState), tons of unnecessary\ncomponents rendering in every frame (signature of\ncomponentShouldUpdate/bad functional react memoizing, etc))\n\\xA0- it's slow because we are hogging the main thread all the time, our\nkiller new feature in v2 is an intense webworker framework. now main\nthread contention is a concern, but really our app needs to just be\nperformant all around, webworkers just offloads that cpu spinning to\nanother core. what we have done in v2 is we went whole hog and made our\ncode rely on OffscreenCanvas which 0 browsers support. also, our\nwebworker bundles (worker-loader webpack build) are huge webpack things\nthat pretty much contain all the code that is on the main thread so it's\njust massive. that makes it slow at loading time, and makes it harder to\nthink about our worker threads in a lighter-weight way, and the worker\nconcept is now very deeply entrenched in a lot of the code (all code has\nto think of things in terms of rpc calls)\n\\xA0- it's slow because there are processes that haven't been aborted\nspinning in the background, so we must build out an intensive\nAbortController thing that touches the entirety of all our code\nincluding sending abort signals across the RPC boundary in hopes that a\nlocked up webworker will respond to this (note: our first version of the\nsoftware had zero aborting, did not from my perspective suffer.\narguments with the team have gotten accusatory where I just claim that\nthere is no evidence that the aborting is helping us, pointing to the\nfact that our old code works fine, and that if our new code suffers\nwithout aborting, that means something else is wrong. I have not really\nbeen given a proper response for this, and so the curse of passing\nAbortSignals onto every function via an extra function parameter drags\non\n\\xA0- it's slow because we are not multithreading..., so we put two views\nof the same data into different webworkers (but now each webworker\nseparately downloads the same data, which leads to more resource spent,\nmore network IO, more slowness)`)),mdx(\"p\",null,\"confusion about what our old users needs are\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`tracks not having per-track scroll (problem: leads to many scrolls\nwithin-scrolls, still unresolved problem)\n\\xA0- the name indexing was always a big problem (yes it is slow but is it\nreally THE critical problem we face? likely not: bioinformatics people\nrun a data pipeline, it takes a couple days, so what). use elasticsearch\nif it sucks so bad\n\\xA0- our users are \"stupid\" so they need to have every single thing GUI\neditable (interesting endeavor, but our design for this has been\ndifficult, and has not yet delivered on simplifying the system for\nusers)\n\\xA0- our users \"do not like modal popups\" so we design everything into a\ntiny sidedrawer that barely can contain the relevant data that they want\nto see`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`having interest in catering to obscure or not very clear\\xA0\"user\nstories\" like displaying the same exact region twice on the screen at\nonce saying\\xA0\"someone will want to do this\", but causing a ton of extra\nlogical weirdness from this`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`not catering to emerging areas of user needs such as breaking our\nlarge app into components that can be re-used, and instead just going\nfull hog on a large monolith project and treating our monolith as a\ngiant hammer that will solve everyones problems, when in reality, our\nusers are also programmers that could benefit from using smaller\ncomponentized versions of our code`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`confusion about\\xA0\"what our competitors have\". sometimes my team one day\nwas like\\xA0\"alright we just do that and then we have everything product X\nhas?\" and I just had to be clear and be like, no! the competitor has a\nreall pretty intricate complex system that we could never hope to\nreplicate. but does that matter? probably not, but even still, we likely\ndon't have even 20% of the full set of functions of a competitor.\nluckily we have our own strengths that make us compelling besides that\n20%`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`making it so our product requires a server side component to run,\nwhere our first version was much more amenable to running as a static\nsite`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"etc...\"))),mdx(\"p\",null,\"but what does all this imply?\"),mdx(\"p\",null,`there are persistent confusion about what the challenges we face are,\nwhat the architectural needs are, what our user stores are, what our new\nv2 design goals are, and more. It's really crazy`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Behind the release - the story of the bugs and features in JBrowse 1.16.0","date":"2018-12-17","slug":"2018-12-17","mdxSource":{"compiledSource":"var u=Object.defineProperty,p=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var s=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var l=(e,t,a)=>t in e?u(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,i=(e,t)=>{for(var a in t||(t={}))n.call(t,a)&&l(e,a,t[a]);if(s)for(var a of s(t))r.call(t,a)&&l(e,a,t[a]);return e},d=(e,t)=>p(e,c(t));var h=(e,t)=>{var a={};for(var o in e)n.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&s)for(var o of s(e))t.indexOf(o)<0&&r.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=h(o,[\"components\"]);return mdx(MDXLayout,d(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Every once in awhile, you might see that your favorite program, JBrowse,\\xA0 has a\nnew release. There are a ton of little snippets in the release notes, you might\nas well just go ahead and upgrade, but what went into all those little fixes?\nGoing to the blog post has links to the github\nissues,\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://jbrowse.org/blog/2018/12/13/jbrowse-1-16-0.html\"}),\"http://jbrowse.org/blog/2018/12/13/jbrowse-1-16-0.html\"),`\\xA0but I felt\nlike maybe I'd add a little more context for some of them:`),mdx(\"p\",null,`PS This is sort of motivated by @zcbenz blog on Electron\n(`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://twitter.com/zcbenz\"}),\"https://twitter.com/zcbenz\"),\"\\xA0\",mdx(\"a\",i({parentName:\"p\"},{href:\"http://cheng.guru/\"}),\"http://cheng.guru/\"),`) which tells the software in\nterms of actual commit messages and such.`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`The webpack build doing a production build by default. This seems pretty\nstraightforward, but was also difficult because I use WSL and the UglifyJs\nplugin had trouble on WSL using the parallel: 4 option to use multiple\nprocessors. This was really annoying and resulted in the webpack build just\nhanging for no reason and only careful google-fu really uncovered other\npeople having this issue. I removed the parallelism as the speed gain wasn't\neven really justifiable\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/gmod/jbrowse/pull/1223\"}),\"https://github.com/gmod/jbrowse/pull/1223\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"The incorporation of the \",mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/bam\"),` module. This was an almost 2 months\nprocess after my first module, `,mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/indexedfasta\"),`. It required really\ngetting down to the binary level for BAM and was pretty tough. The module\nhas already itself had 12 releases `,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/GMOD/bam-js/blob/master/CHANGELOG.md\"}),\"here\")))),mdx(\"p\",null,`-\\xA0Added support for indexing arbitrary fields from GFF3Tabix files. This was\nfairly straightforward but required making design decisions about this.\nPreviously flatfile-to-json.pl files would have a command line flag to index\narbitrary fields. Since gff3tabix files are specified via config, I allowed\nspecifying arbitrary fields via config.`),mdx(\"p\",null,`-\\xA0Added ability to render non-coding transcript types to the default Gene\nglyph. This one was a nice feature and enables you to see non-coding types, but\nrequired some weird design decisions because I could not override\nthe\\xA0`,mdx(\"inlineCode\",{parentName:\"p\"},\"box->style->color\"),` from a higher level type simply using the\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"_defaultConfig\"),\" function, so I needed to override the \",mdx(\"inlineCode\",{parentName:\"p\"},\"getStyle\"),` callback\nthat was passed down to the lower levels, so that it was able to use the\ndefault lower level style and also our non-coding transcript style. See this\npart of the code for\ndetails\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/GMOD/jbrowse/commit/ec638ea1cc62c8727#diff-a14e88322d8f4e8e940f995417277878R22\"}),\"https://github.com/GMOD/jbrowse/commit/ec638ea1cc62c8727#diff-a14e88322d8f4e8e940f995417277878R22\")),mdx(\"p\",null,\"-\\xA0Added \",mdx(\"inlineCode\",{parentName:\"p\"},\"hideImproperPairs\"),` filter. This was fairly straightforward but it is one\nof these bugs that went unnoticed for years...the `,mdx(\"inlineCode\",{parentName:\"p\"},\"hideMissingMatepairs\"),` flag\nwould hide things didn't have the sam 0x02 flag for \"read mapped in proper\npair\", but reads with this flag could still be paired. Doing the 1.16 release\nthat focused on paired reads helped focus on this issue and now\nhideMissingMatepairs filters on \"mate unmapped\" and `,mdx(\"inlineCode\",{parentName:\"p\"},\"hideImproperPairs\"),` is\nthe\\xA0\"read mapped in proper pair\"`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Added \",mdx(\"inlineCode\",{parentName:\"li\"},\"useTS\"),` flag. This one is fairly straightforward, it is similar to\n`,mdx(\"inlineCode\",{parentName:\"li\"},\"useXS\"),` which colors reads based on their alignment in canonical splice site\norientations. I figured I could just copy the `,mdx(\"inlineCode\",{parentName:\"li\"},\"useXS\"),\" to the \",mdx(\"inlineCode\",{parentName:\"li\"},\"useTS\"),` since I\nfigured they are the same, but I went ahead and manually generated RNA-seq\nalignments with minimap2 and found that the useTS is actually flipped the\nopposite of `,mdx(\"inlineCode\",{parentName:\"li\"},\"useXS\"),\", so it was valuable to get actual test data here.\")),mdx(\"p\",null,\"-\\xA0Fixed issue where some \",mdx(\"inlineCode\",{parentName:\"p\"},\"generate-names\"),` setups would fail to index features.\nThis was a bad bug that was brought to light by a user. I was kind of mind\nboggled when I saw it. In JBrowse 1.13-JBrowse 1.15 a change was introduced to\nname indexing with a memory leak. In JBrowse 1.15 that was removed. But, there\nwas another change where refseqs could return empty name records, because they\nwere handled separately. But if the initial fill up of the name buffer of 50000\nwas exceeded by the reference sequence, then there would be empty name records\nafter this point and cause the name indexing to stop. Therefore this bug would\nonly happen when the reference sequence indexing buffer exceeded 50000 items\nwhich could happen even when there are less than 50000 refseqs due to\nautocompletions`),mdx(\"p\",null,`-\\xA0 Fixed issue with getting feature density from BAM files via the index stats\nestimation. This involved parsing the\\xA0\"dummy bin\" from index files, and I found\nit was failing on certain 1000 genomes files. I actually don't really know what\nthe story behind this was, but our tabix code was better at parsing the dummy\nbins than my bam code, and it was the same concept, so I took a note from their\ncodebase to use it in bam-js code. Commit\nhere\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/GMOD/bam-js/commit/d5796dfc8750378ac8b875615ae0a7e81371af76\"}),\"https://github.com/GMOD/bam-js/commit/d5796dfc8750378ac8b875615ae0a7e81371af76\")),mdx(\"p\",null,`-\\xA0 Fixed issue with some GFF3Tabix tracks having some inconsistent layout of\nfeatures. This is a persistently annoying fact in tabix files where we cannot\nreally get a unique ID of a feature based on it's file offset. Therefore this\ntakes the full crc32 of a line as it's unique ID.`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},`Fixed CRAM store not renaming reference sequences in the same way as other\nstores. This one was interesting because rbuels made a fix but it caused\nfeatures from one chromosome to show up on the wrong ones, so chr1 reads\nwhere showing up on chrMT. This happened because it was falling back to the\nrefseq index if it chrMT wasn't in the embedded \"sam header\" in the CRAM\nfile, but it should only fallback to refseq index if there is not any\nembedded\\xA0\"sam header\" in the CRAM file.`)),mdx(\"p\",null,`-\\xA0 Fixed bug where older browsers e.g. IE11 were not being properly supported\nvia babel. This was a absolutely terrible bug that I found over thanksgiving\nbreak. It was a regression from 1.15 branch of JBrowse. Previous versions from\n1.13 when webpack was up until 1.15 used `,mdx(\"inlineCode\",{parentName:\"p\"},\"@babel/env\"),`. It was changed to\nbabel-preset-2015 but it was not being run correctly. Then I found that even if\nI did get it running correctly, it was unable to properly babel-ify the\nlru-cache module because it used something called\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"Object.defineProperty('length', ...)\"),` to change how the length property was\nintepreted which was illegal in IE11. The 'util.promisify' NPM module also did\nthis in some contexts. I found that I could use the quick-lru module and the\nes6-promisify module instead of lru-cache and util.promisify as a workaround.\nThen I had to update all `,mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/tabix\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/vcf\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/bgzf-filehandle\"),`,\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/indexedfasta\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/tribble-index\"),\", \",mdx(\"inlineCode\",{parentName:\"p\"},\"@gmod/bam\"),`, and JBrowse proper to\nuse these modules instead, and make the bable chain, which typically does not\nparse node_modules, to build these modules specifically (I didn't want to setup\nbabel toolchains for every single one of these modules, just one in the jbrowse\nmain codebase...). This was really a lot of work to support IE11 but now that\nworks so ...ya`),mdx(\"p\",null,`-\\xA0 Fixed bug where some files were not being fetched properly when changing\nrefseqs. This was actually fixed when I changed out lru-cache for quick-lru and\nfixed a bug where the cache size was set to 0 due to a erroneous comment that\nsaid\\xA0`,mdx(\"inlineCode\",{parentName:\"p\"},\"50*1024 // 50MB\"),\"...of course it should have said\\xA0\",mdx(\"inlineCode\",{parentName:\"p\"},\"50*1024*1024 // 50MB\"),\"\\xA0\",mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/GMOD/jbrowse/commit/2025dc0aa0091b70\"}),\"https://github.com/GMOD/jbrowse/commit/2025dc0aa0091b70\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Fixed issue where JBrowse would load the wrong area of the refseq on startup\nresulting in bad layouts and excessive data fetches. This was actually a\nheinous bug where jbrowse upon loading would just navigateTo the start of the\nreference sequence automatically and then to wherever was specified by the\nuser. This resulted in track data to start downloading immediately from the\nstart of the chromosome and resulted in for example 350 kilobases of\nreference sequence from all tracks to start downloading, which when I was\nimplementing view as pairs, was causing me to download over 100MB routinely.\nThis was terrible, and after fixing I only download about 10MB over even\nlarge regions for most BAM files. Additionally, this bug was causing the\ntrack heights to be calculated incorrectly because the track heights would\nactually be calculated based on distorted canvas\nbitmaps.\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/gmod/jbrowse/issues/1187\"}),\"https://github.com/gmod/jbrowse/issues/1187\"))),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`JBrowse Desktop was not fetching remote files. This was a weird issue where\nremote file requests were considered a CORS requests to any external remote.\nThis was solved by changing the usage of the fetch API in JBrowse for\nnode-fetch which does not obey CORS. Note that electron-fetch was also\nconsidered, which uses Chromiums network stack instead of node's, but that\nhad specific assumptions about the context in which it was called.`))),mdx(\"p\",null,`-\\xA0 Fixed issue where some parts of a CRAM file would not be displayed in\nJBrowse due to a CRAM index parsing issue. This was based on a sort of binary\nsearch that was implemented in JBrowse where the elements of the lists were\nnon-overlapping regions, and the query was a region, and the output should be a\nlist of the non-overlapping regions that overlap the query. Most algorithms for\nbinary search don't really tell you how to do searches on ranges so needed to\nroll up my sleeves and write a little custom code. An interval tree could have\nbeen used but this is too heavy-weight for non-overlapping regions from the\nindex\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/GMOD/cram-js/pull/10\"}),\"https://github.com/GMOD/cram-js/pull/10\")),mdx(\"p\",null,`-\\xA0 Fixed an issue where BAM features were not lazily evaluating their tags.\nWhen a function `,mdx(\"inlineCode\",{parentName:\"p\"},\"feature.get('blahblah')\"),` is called on a BAM feature, it checks\nto see if it's part of a default list of things that are parsed like feature\nstart, end, id, but if not, it has to parse all the BAM tags to see if it is a\ntag. Since they are called\\xA0\"lazy features\" the tag processing is deferred until\nit is absolutely needed. As it turned out, the incorporation of CRAM in 1.15\nwas calling a function to try to get the CRAM's version of CIGAR/MD on the BAM\nfeatures unnecessarily invoking the tag parsing on every feature up front and\ntherefore making the feature not really lazy anymore. This restored\nthe\\xA0\"lazyness\" aspect of BAM.`),mdx(\"p\",null,`-\\xA0 Fixed issue where CRAM layout and mouseover would be glitchy due to ID\ncollisions on features. In the 1.15 releases, CRAM was introduced, and we\nthought that the concept of taking CRC32 of the entire feature data days were\nover because there is the concept of a\\xA0\"unique ID\" on the features. However,\nthis ID was only unique within the slices, so around the slice boundaries there\nwere a lot of bad feature layouts and mouseovers would fail because they would\nmap to multiple features, etc. I found a way to unique-ify this by giving it\nthe sliceHeader file offset.\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/GMOD/cram-js/pull/10\"}),\"https://github.com/GMOD/cram-js/pull/10\")),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`We also had behind the scenes work by igv.js team member jrobinso who helped\non the CRAM codebase to incorporate a feature where for lossy read names, so\nthat a read and it's mate pair would consistently be assigned the same read\nname based on the unique ID mentioned above. There was also a rare issue\nwhere sometimes the mate pair's orientation was incorrectly reported based on\nthe CRAM flags, but the embedded BAM flags correctly reported it.`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Finally the paired reads feature. This was a feature that I really wanted to\nget right. It started when garrett and rbuels were going to san diego for the\nCIVIC hackathon, and we talked about doing something that matched a\\xA0\"variant\nreview system\" that they had done for the IGV codebase, which involved\ndetailed inspection of reads. I thought it would probably be feasible for\njbrowse to do this, but I thought essentially at some point that enhancing\njbrowse's read visualizations with paired reads would be a big win. I had\nthought about this at the JBrowse hackathon also and my discussions then were\nthat this was very hard. Overall, I invented a compromise that I thought was\nreasonable which was that there can be a\\xA0\"maxInsertSize\" for the pileup view\nbeyond which the pairing wouldn't be resolved. This allowed (a) a significant\nreduction in data fetches because I implemented a\\xA0\"read redispatcher\" that\nwould actually literally resolve the read pairs in the separate chunks and\n(b) a cleaner view because the layout wouldn't be polluted by very long read\ninserts all the time and also, for example, if you scrolled to the right, and\nsuddenly a read was paired to the left side of your view, it would result in\na bad layout (but with max insert size, the window of all reads within\nmaxinsertsize are always resolved so this does not happen) and finally ( c)\nthe paired arc view was incorporated which does not use read redispatching\nand which can do very long reads. All of these things took time to think\nthrough and resolve, but it is now I think a pretty solid system and I look\nforward to user feedback!`))))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Problems that I experienced with the HPCC","date":"2017-04-21","slug":"2017-04-21","mdxSource":{"compiledSource":"var p=Object.defineProperty,m=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var i=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,a=Object.prototype.propertyIsEnumerable;var c=(e,o,t)=>o in e?p(e,o,{enumerable:!0,configurable:!0,writable:!0,value:t}):e[o]=t,n=(e,o)=>{for(var t in o||(o={}))r.call(o,t)&&c(e,t,o[t]);if(i)for(var t of i(o))a.call(o,t)&&c(e,t,o[t]);return e},d=(e,o)=>m(e,u(o));var s=(e,o)=>{var t={};for(var l in e)r.call(e,l)&&o.indexOf(l)<0&&(t[l]=e[l]);if(e!=null&&i)for(var l of i(e))o.indexOf(l)<0&&a.call(e,l)&&(t[l]=e[l]);return t};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(t){var l=t,{components:e}=l,o=s(l,[\"components\"]);return mdx(MDXLayout,d(n(n({},layoutProps),o),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Many of these issues may be due to me being stubborn with a weird build system.\nNonetheless, they were baffling, and I had very little interest in debugging\nthese issues. I just wanted to get my science done after all!`),mdx(\"h1\",null,\"Module load completely barfs with incomprehensible error\"),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`$ module spider bedtools\nUsing system spider cache file\n/opt/software/lmod/bin/lua: /opt/software/lmod/4.1.4icer5/libexec/Spider.lua:662: attempt to perform arithmetic on a nil value\nstack traceback:\n    /opt/software/lmod/4.1.4icer5/libexec/Spider.lua:662: in function 'Level1'\n    /opt/software/lmod/4.1.4icer5/libexec/Spider.lua:640: in function 'spiderSearch'\n    /opt/software/lmod/4.1.4icer5/libexec/lmod:967: in function 'cmd'\n    /opt/software/lmod/4.1.4icer5/libexec/lmod:1195: in function 'main'\n    /opt/software/lmod/4.1.4icer5/libexec/lmod:1222: in main chunk\n    [C]: ?\n`)),mdx(\"h1\",null,\"Linuxbrew is terribly confused by things that depend on gcc\"),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`brew install hello\n==> Installing dependencies for hello: glibc, xz, gmp, mpfr, libmpc, isl, gcc\n==> Installing hello dependency: glibc\nError: glibc cannot be built with any available compilers.\nInstall Clang or brew install gcc\n`)),mdx(\"p\",null,\"Using module load Clang does not fix problem \",\">\",\"_\",\"\\\\<\"),mdx(\"h1\",null,\"Compiling things manually on software machine does not work on interactive machine\"),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`$ mummer\nIllegal instruction (core dumped)\n`)),mdx(\"h1\",null,\"Many modules have a secret dependency on loading other modules\"),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`$ module load LASTZ\n\nLmod Warning: Did not find: LASTZ\n\nTry: \"module spider LASTZ\"\n$ module load GNU\n$ module load LASTZ\n$ lastz\nYou must specify a target file\nlastz-- Local Alignment Search Tool, blastZ-like\n  (version 1.03.02 released 20110719)\n...\n`)),mdx(\"p\",null,\"Etc etc.\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"How I learned to hate ORM (especially for data import scripts)","date":"2017-03-12","slug":"2017-03-12","mdxSource":{"compiledSource":"var u=Object.defineProperty,h=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var s=Object.getOwnPropertySymbols;var o=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var l=(a,e,t)=>e in a?u(a,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):a[e]=t,n=(a,e)=>{for(var t in e||(e={}))o.call(e,t)&&l(a,t,e[t]);if(s)for(var t of s(e))r.call(e,t)&&l(a,t,e[t]);return a},p=(a,e)=>h(a,m(e));var d=(a,e)=>{var t={};for(var i in a)o.call(a,i)&&e.indexOf(i)<0&&(t[i]=a[i]);if(a!=null&&s)for(var i of s(a))e.indexOf(i)<0&&r.call(a,i)&&(t[i]=a[i]);return t};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(t){var i=t,{components:a}=i,e=d(i,[\"components\"]);return mdx(MDXLayout,p(n(n({},layoutProps),e),{components:a,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`When I was tasked with making a new application for our websites, I was\ngiven several CSV files with some expectation that these files could\nbasically be just loaded into a database and jumped into production really\nquickly. If you are using R and Shiny to make a data visualization dashboard,\nespecially if it is read only, this can actually be a reality for you: load\nthose CSVs and just pretend you're a full featured database. I had to actually\ncreate some read write functionality though. This was sort of experimental for\nme and I'm not that well versed in databases, but I wanted to share my\nexperience`),mdx(\"p\",null,`When I started, I chose grails/groovy/hibernate/GORM as a platform to\nuse. This quickly turned into pain when I tried to make a data importer\nusing grails also.`),mdx(\"p\",null,`Each CSV row from the source file would have to be turned into many\ndifferent rows in the database because it represented multiple\nrelationships, example:`),mdx(\"p\",null,mdx(\"img\",n({parentName:\"p\"},{src:\"/media/158300473458_0.png\",alt:null}))),mdx(\"p\",null,`Initially I made my data importer in grails, and was hardcoding column\nnames knowing full well this was really inflexible. At the same time I\nwas also trying to\\xA0\"iterate\" on my database schema, and I'd want to\nre-import my data to test it out, but it was really really slow. I tried\nmany different approaches to try to speed this up such as cleanUpGorm,\nStatelessSessions, and other tricks, but it would take 10-20 minutes for\nimports on a 100KB input file.`),mdx(\"p\",null,\"What I basically realised is that for bulk data import\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"1) Using the ORM is really painful for bulk import.\")),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},`2) If you can pre-process your data so that it is already in the\nformat the database expects, then you can use the CSV COPY command which\nis very fast`)),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},`3) If you can then abandon the ORM mentality and even ignore it as\na\\xA0convenience factor, then you can embrace my database system itself`)),mdx(\"p\",null,`Overall, after all this work, it just seemed like ORM treats the\ndatabase as a danger and something to be heavily abstracted over, but I\nactually found joy in learning how to treat my database as a first class\ncitizen. Soon I started gaining appreciation of`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"using plain SQL queries\"),mdx(\"li\",{parentName:\"ul\"},\"learning about full text search in postgres with ts_query\"),mdx(\"li\",{parentName:\"ul\"},`learning about triggers to make a\\xA0\"last updated\" field get updated\nautomatically`)),mdx(\"p\",null,`I am pretty happy this way, and although I miss some things like\ncriteria queries which are very powerful, I am happy that I can interact\nwith my database as a friend`),mdx(\"p\",null,`At the very least, due to the fact that I now pre-process the data\nbefore database loading, I can now import large amounts of data super\nfast with the CSV COPY command`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Plotting a coordinate on the screen","date":"2017-02-16","slug":"2017-02-16","mdxSource":{"compiledSource":"var c=Object.defineProperty,d=Object.defineProperties;var y=Object.getOwnPropertyDescriptors;var p=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,i=Object.prototype.propertyIsEnumerable;var s=(e,t,o)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,n=(e,t)=>{for(var o in t||(t={}))r.call(t,o)&&s(e,o,t[o]);if(p)for(var o of p(t))i.call(t,o)&&s(e,o,t[o]);return e},u=(e,t)=>d(e,y(t));var h=(e,t)=>{var o={};for(var a in e)r.call(e,a)&&t.indexOf(a)<0&&(o[a]=e[a]);if(e!=null&&p)for(var a of p(e))t.indexOf(a)<0&&i.call(e,a)&&(o[a]=e[a]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var a=o,{components:e}=a,t=h(a,[\"components\"]);return mdx(MDXLayout,u(n(n({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I always end up having to remember the math for plotting a coordinate on the\nscreen,\\xA0for example an HTML5 canvas and end up stitching it together manually`),mdx(\"p\",null,\"If you step through the math it becomes very simple though\"),mdx(\"p\",null,`Say you have a coordinate range of 1000 to 2000 that you want to plot in a\nHTML5 canvas of size 100px`),mdx(\"p\",null,`Let's do a quick example and then generalize. Let's say you want to plot the\nvalue 1500, and put it into screen coordinates, so you take that and subtract\nthe minimum of the range`),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`1500-1000\n`)),mdx(\"p\",null,`Second, you know your point is going to be halfway in the range, and in\ngeneral, to get this position, you divide now by the size of the interval you\nare plotting in, e.g. 2000-1000`),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`(1500-1000)/(2000-1000) = 0.5\n`)),mdx(\"p\",null,`We get 0.5 as expected. Then you multiply this proportion times the width of\nbox you are rendering in, e.g. 100 pixels wide, and get that you put your pixel\nat position 50px`),mdx(\"p\",null,`To summarize, the general formula for plotting a point x in a range (x1,x2) on\na screen of width w is`),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`w*(x - \\xA0x1) / (x2 - x1)\n`)),mdx(\"p\",null,\"Of course same thing applies for y\"),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`h*(y - y1) / (y2 - y1)\n`)),mdx(\"p\",null,`This does not take into account small possible adjustments for closed vs open\nranges, which could be important to avoid subpixel rendering on a canvas, but\nthat can be a further exercise`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Creating a JBrowse plugin","date":"2016-11-10","slug":"2016-11-10","mdxSource":{"compiledSource":"var c=Object.defineProperty,d=Object.defineProperties;var h=Object.getOwnPropertyDescriptors;var i=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var u=(e,t,o)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,a=(e,t)=>{for(var o in t||(t={}))r.call(t,o)&&u(e,o,t[o]);if(i)for(var o of i(t))s.call(t,o)&&u(e,o,t[o]);return e},l=(e,t)=>d(e,h(t));var p=(e,t)=>{var o={};for(var n in e)r.call(e,n)&&t.indexOf(n)<0&&(o[n]=e[n]);if(e!=null&&i)for(var n of i(e))t.indexOf(n)<0&&s.call(e,n)&&(o[n]=e[n]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var n=o,{components:e}=n,t=p(n,[\"components\"]);return mdx(MDXLayout,l(a(a({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I have been very impressed with peoples creativity and willingness to\ndig into all the details of JBrowse to customize it's features. One\ngreat way to do this in a modular way is to create a \"JBrowse plugin\".\nThis concept sounds hard but you can set up a simple couple of files and\nrefresh your browser and it will \"just work\"!`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Introduction to the plugin mindset\")),mdx(\"p\",null,`In a plugin, you can define new things like custom track types, custom\nadaptors to new file types, new track selectors, or something really\ndifferent. A key insight about the custom types of tracks and things\nthough is that you can put the name of your new custom class in the\njbrowse config file which will then find the code in your plugin and run\nit. Plugins can do other things, but the ability to just swap out track\ntypes or other components in the config file is a great benefit.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"A scenario\")),mdx(\"p\",null,`One example that was talked about on the mailing list might involve\nadding new menu items for a given track. We might consider a plugin that\ndefines a custom track type to add that functionality.`),mdx(\"p\",null,`Basically, we can use object- oriented principles to \"inherit\" from some\nexisting track type like CanvasFeatures and then extend its\nfunctionality by overriding the functions.`),mdx(\"p\",null,`If you are not familiar with object-oriented javascript, dojo makes it\npretty easy (but, especially get a background on this if you need to,\nsee footnotes below).`),mdx(\"p\",null,`We can inherit a new track type by using the \"define\" function to\ninclude the dependencies needed in a file, and they are listed in an\narray at the top of your file.`),mdx(\"p\",null,`Then the \"declare\" function creates a new class. The first argument to\ndeclare is the is your parent class, like CanvasFeatures, and we type\n\"return declare\" because we are returning our new track class from the\nmodule.`),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` define( [\"dojo/_base/declare\",\n \"JBrowse/View/Track/CanvasFeatures\"],\n \\xA0\\xA0\\xA0 function(declare,CanvasFeatures) {\n \\xA0\\xA0\\xA0 return declare(CanvasFeatures, {\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 _trackMenuOptions: function() {\n\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 var opts=this.inherited(arguments); //call the parent\n classes function\n\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 opts.push( // add an extra menu item to the array returned\n from parent class function\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 {\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 label: \"Custom item\",\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 type: 'dijit/CheckedMenuItem',\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 onClick: function(event) {\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 console.log('Clicked');\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 }, \\xA0\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 iconClass: \"dijitIconPackage\"\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 }\\xA0 \\xA0\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 ); \\xA0\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 return opts;\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 }\\xA0 \\xA0\n \\xA0\\xA0\\xA0 });\n \\xA0\\xA0\\xA0 }\\xA0 \\xA0\n );\n`)),mdx(\"p\",null,`Code listing 1. an example custom track type, MyTrack.js, that adds an\nextra track menu item`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Now how do we make this a plugin?\")),mdx(\"p\",null,`In the above section, we created a new track subclass with a custom menu\noption. How do we use this track? We want to turn it into part of afine\nthe boilerplate code from the `,mdx(\"a\",a({parentName:\"p\"},{href:\"http://gmod.org/wiki/JBrowse_Configuration_Guide#Writing_JBrowse_Plugins\"}),`Writing\nplugins`),`\nguide.`),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),` define([\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 'dojo/_base/declare',\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 'JBrowse/Plugin'\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 ], \\xA0\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 function(\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 declare,\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 JBrowsePlugin\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 ) {\n \\xA0\n return declare( JBrowsePlugin, // our plugin's main.js derives from\n the \"JBrowse/Plugin\" base class\n {\n \\xA0\\xA0\\xA0 constructor: function( args ) {\n \\xA0\\xA0\\xA0\\xA0\\xA0\\xA0\\xA0 /*don't necessarily have to do any initializing here, but you\n can get a handle to various jbrowse components if any initialization\n is needed from the args.browser variable*/\n \\xA0\\xA0\\xA0 }\\xA0 \\xA0\n });\n });\n`)),mdx(\"p\",null,\"Code listing 2. Our plugin's main.js\"),mdx(\"p\",null,\"After this, we create the plugin directory structure\"),mdx(\"blockquote\",null,mdx(\"p\",{parentName:\"blockquote\"},\"jbrowse/plugins/MyPlugin\"),mdx(\"blockquote\",{parentName:\"blockquote\"},mdx(\"p\",{parentName:\"blockquote\"},\"jbrowse/plugins/MyPlugin/js\"),mdx(\"blockquote\",{parentName:\"blockquote\"},mdx(\"p\",{parentName:\"blockquote\"},\"jbrowse/plugins/MyPlugin/js/main.js\"),mdx(\"p\",{parentName:\"blockquote\"},\"jbrowse/plugins/MyPlugin/js/MyTrack.js\")))),mdx(\"p\",null,`Then we can add our new plugin to a config file like jbrowse_conf.json\nas \"plugins\": `,'[\"MyPlugin\"]',`\\xA0 and then make a track in trackList.json\nhave \"type\":\\xA0 \"MyPlugin/MyTrack\" instead of for\nexample\\xA0\"type\":\\xA0\"CanvasFeatures\". That will tell jbrowse to load the\nMyTrack class from your plugin instead of the normal CanvasFeatures\nclass.`),mdx(\"p\",null,\"That's about it!\"),mdx(\"p\",null,`Note that the bin/new-plugin.pl script can automatically initialize some\nof this directory structure too. Try running \"bin/new-plugin.pl\nMyPlugin\" and see what happens.`),mdx(\"p\",null,\"Footnotes:\"),mdx(\"p\",null,`It is important to understand the module format (AMD) which is what the\n\"define\" function is about and the dojo way of definining classes using\nthe \"declare\" function. Together, this allows the dojo to create\nobject-oriented programs that are modular in javascript. See\n`,mdx(\"a\",a({parentName:\"p\"},{href:\"http://dojotoolkit.org/reference-guide/1.10/dojo/_base/declare.html\"}),\"http://dojotoolkit.org/reference-guide/1.10/dojo/_base/declare.html\"),`\nand `,mdx(\"a\",a({parentName:\"p\"},{href:\"http://dojotoolkit.org/documentation/tutorials/1.9/modules/\"}),\"http://dojotoolkit.org/documentation/tutorials/1.9/modules/\"),`\n(understanding this helps you understand the \"preamble\" for declaring a\njbrowse plugin)`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Fixing spiky CPU issues with Tomcat","date":"2016-09-16","slug":"2015-09-16","mdxSource":{"compiledSource":"var h=Object.defineProperty,l=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var s=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,p=Object.prototype.propertyIsEnumerable;var r=(e,t,o)=>t in e?h(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,i=(e,t)=>{for(var o in t||(t={}))n.call(t,o)&&r(e,o,t[o]);if(s)for(var o of s(t))p.call(t,o)&&r(e,o,t[o]);return e},g=(e,t)=>l(e,u(t));var m=(e,t)=>{var o={};for(var a in e)n.call(e,a)&&t.indexOf(a)<0&&(o[a]=e[a]);if(e!=null&&s)for(var a of s(e))t.indexOf(a)<0&&p.call(e,a)&&(o[a]=e[a]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var a=o,{components:e}=a,t=m(a,[\"components\"]);return mdx(MDXLayout,g(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`The symptoms of spiking that we saw were simply that after light usage\nof the applications, the CPU usage would start spiking and rapidly cycle\nfrom many CPU cores (e.g. 2000% CPU usage) back to 0% CPU for no\napparent reason.`),mdx(\"p\",null,`We now know this was due to memory issues and garbage collection, but it\nwas confusing because it wasn't strictly showing up as GC usage in\nJVisualVm (the GC usage, blue spikes on the left in fig 1, are small,\nbut the orange spikes are large, even though the memory issues are the\nproblem)`),mdx(\"p\",null,`Here is what it looked like during spiking (obviously, pushing the\nmemory limits here, a linked in article suggests having 6GB of\\xA0\"newgen\"\nmemory, so on top of the old gen, tomcat needs a bunch more for the\nnewgen to make things happy.`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/129241954103_0.png\",alt:null}))),mdx(\"p\",null,\"Here is what it looks like when it is not spiking\"),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/129241954103_1.png\",alt:null}))),mdx(\"p\",null,`Edit: See this follow up post for showing that increasing memory helps\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://searchvoidstar.tumblr.com/post/131229569383/tomcat-memory-debugging\"}),\"http://searchvoidstar.tumblr.com/post/131229569383/tomcat-memory-debugging\")),mdx(\"p\",null,`::: {#footer}\n`,\"[ September 16th, 2015 6:37pm ]\",\"{#timestamp} \",\"[tomcat]\",\"{.tag} \",\"[java]\",`{.tag}\n`,\"[programming]\",\"{.tag} \",\"[coding]\",\"{.tag} \",\"[troubleshooting]\",`{.tag}\n`,\"[intermine]\",\"{.tag} \",\"[bioinformatics]\",`{.tag}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Installing clamav on OSX","date":"2016-06-20","slug":"2016-06-20","mdxSource":{"compiledSource":"var d=Object.defineProperty,m=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var r=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,c=Object.prototype.propertyIsEnumerable;var i=(e,a,t)=>a in e?d(e,a,{enumerable:!0,configurable:!0,writable:!0,value:t}):e[a]=t,o=(e,a)=>{for(var t in a||(a={}))s.call(a,t)&&i(e,t,a[t]);if(r)for(var t of r(a))c.call(a,t)&&i(e,t,a[t]);return e},l=(e,a)=>m(e,u(a));var p=(e,a)=>{var t={};for(var n in e)s.call(e,n)&&a.indexOf(n)<0&&(t[n]=e[n]);if(e!=null&&r)for(var n of r(e))a.indexOf(n)<0&&c.call(e,n)&&(t[n]=e[n]);return t};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(t){var n=t,{components:e}=n,a=p(n,[\"components\"]);return mdx(MDXLayout,l(o(o({},layoutProps),a),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`It is a common trope that OSX doesn't need anti-virus because everyone targets\nwindows. That is maybe comforting to some but I think it's pretty naive. It\nwould be better to have a system on your machine to tell you about viruses,\ntrojan horses, malware, or spying. \\xA0I have decided to employ a free open source\nscanner called clamAV\\xA0`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://www.clamav.net/\"}),\"https://www.clamav.net/\"),`. I don't really know if it has\nany good features for Mac scanning but thought it could be fun to install`),mdx(\"p\",null,`ClamAV is the top choice for linux based OSs being free and open source (GPL)\nvirus scanner.`),mdx(\"p\",null,\"To install we can use homebrew\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`\\xA0 \\xA0 $ brew install clamav\n`)),mdx(\"p\",null,`Then there is s config file to setup. This is located\nin\\xA0/usr/local/etc/clamav/freshclam.conf`),mdx(\"p\",null,`To setup, edit this file and delete the line that says\\xA0\"Example\" and\nthen uncheck the desired settings. I would chose to enable logging to\n/var/log/clamav.log and also database directories in /var/lib/clamav`),mdx(\"p\",null,'Then run the\\xA0\"freshclam\" program'),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`\\xA0 \\xA0 $ freshclam\n`)),mdx(\"p\",null,`This will download the virus scanner database (main) and daily scanning\nupdates`),mdx(\"p\",null,`Then you can run clamscan on a given directory (recursively, only print\ninfected files)`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`\\xA0 \\xA0 $ clamscan -ri ~/\n`)),mdx(\"p\",null,\"Or add this to a cronjob\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`\\xA0 \\xA0 $ crontab -\n\n\\xA0 \\xA0 @hourly clamscan -ri ~/ | mail -v -s \"clamscan results\" your.email@gmail.com \\xA0>/dev/null 2>&1\n\n`)))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Querying InterMine databases using R","date":"2016-06-17","slug":"2016-06-17","mdxSource":{"compiledSource":"var l=Object.defineProperty,d=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var i=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var p=(e,t,n)=>t in e?l(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,r=(e,t)=>{for(var n in t||(t={}))i.call(t,n)&&p(e,n,t[n]);if(o)for(var n of o(t))s.call(t,n)&&p(e,n,t[n]);return e},m=(e,t)=>d(e,c(t));var u=(e,t)=>{var n={};for(var a in e)i.call(e,a)&&t.indexOf(a)<0&&(n[a]=e[a]);if(e!=null&&o)for(var a of o(e))t.indexOf(a)<0&&s.call(e,a)&&(n[a]=e[a]);return n};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(n){var a=n,{components:e}=a,t=u(a,[\"components\"]);return mdx(MDXLayout,m(r(r({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`In the past, I had found some ways to do simple queries on InterMine web\nservices using basic HTTP commands with R (see\n`,mdx(\"a\",r({parentName:\"p\"},{href:\"https://gist.github.com/cmdcolin/4758167bdd89e6c9c055\"}),\"https://gist.github.com/cmdcolin/4758167bdd89e6c9c055\"),\")\"),mdx(\"p\",null,\"However, the InterMineR (\",mdx(\"a\",r({parentName:\"p\"},{href:\"https://github.com/intermine/intermineR\"}),\"https://github.com/intermine/intermineR\"),`)\npackage automates some of these features and makes it easier to load the\ndata in R.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Installation\")),mdx(\"p\",null,`One way to install InterMineR is to install from github with\nhadley/devtools`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{}),`install.packages(\"devtools\")\ndevtools::install_github(\"hadley/devtools\")\ndevtools::install_github(\"intermine/intermineR\")\n`)),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Usage\")),mdx(\"p\",null,`Basic usage includes loading the\\xA0\"intermine URL\" using the initInterMine\nfunction. Then various functions can be called on this result.`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{}),`library(InterMineR)\nmine=initInterMine(\"http://bovinegenome.org/bovinemine/\")\ngetVersion(mine) #18, intermine API version\ngetRelease(mine) #1.0, our data release version\ngetTemplates(mine) # lists all templates on interminer\n`)),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Run a template query\")),mdx(\"p\",null,`From the getTemplates function, if you see a template query that you\nwant to run, you can use the getTemplateQuery function with it's name,\nand run it with the runQuery function`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{}),`getTemplateQuery(mine,\"TQ_protein_to_gene\") # see what template looks like\ntemplate=getTemplateQuery(mine,\"TQ_protein_to_gene\") # save template\nrunQuery(mine,template) # run the template query with default params, receive data.frame\n`)),mdx(\"p\",null,`This method is good, but some improvement could be added to change\ndefault parameters in the template query, etc.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Run query XML\")),mdx(\"p\",null,`Another option for running queries is to use the query XML that you can\ndownload from the InterMine query result pages.`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{}),` # get all Ensembl genes on chr28 from bovinemine\n query='<query model=\"genomic\" view=\"Gene.primaryIdentifier\n Gene.secondaryIdentifier Gene.symbol Gene.name Gene.source\n Gene.organism.shortName Gene.chromosome.primaryIdentifier\"\n sortOrder=\"Gene.primaryIdentifier ASC\" ><constraint\n path=\"Gene.organism.shortName\" op=\"=\" value=\"B. taurus\"\n /><constraint path=\"Gene.chromosome.primaryIdentifier\" op=\"=\"\n value=\"GK000028.2\" /></query>'\n\n results=runQuery(mine, query)\n\n head(results)\n`)),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Conclusion\")),mdx(\"p\",null,`The InterMineR package has a couple of nice features for getting\nInterMine data with a couple of functions for looking at templates. For\nmany use cases, copying the Query XML from a InterMine webpage and\npasting that into the runQuery function is sufficient and produces a\ndata frame that can be analyzed.`),mdx(\"p\",null,`PS it is not easy to post XML on tumblr after editing the post in\nmarkdown mode. You have to add the lt and gt shortcuts and even after\nthat it gets filtered?!`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"How to make your resume.json or resume-cli look great","date":"2016-04-23","slug":"2016-04-23","mdxSource":{"compiledSource":"var h=Object.defineProperty,d=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var m=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,i=Object.prototype.propertyIsEnumerable;var u=(e,t,r)=>t in e?h(e,t,{enumerable:!0,configurable:!0,writable:!0,value:r}):e[t]=r,o=(e,t)=>{for(var r in t||(t={}))n.call(t,r)&&u(e,r,t[r]);if(m)for(var r of m(t))i.call(t,r)&&u(e,r,t[r]);return e},p=(e,t)=>d(e,c(t));var a=(e,t)=>{var r={};for(var s in e)n.call(e,s)&&t.indexOf(s)<0&&(r[s]=e[s]);if(e!=null&&m)for(var s of m(e))t.indexOf(s)<0&&i.call(e,s)&&(r[s]=e[s]);return r};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(r){var s=r,{components:e}=s,t=a(s,[\"components\"]);return mdx(MDXLayout,p(o(o({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`There are a ton of themes for resume-cli that are not immediately\nobvious to find`),mdx(\"p\",null,\"To see all the great themes on the command line, check out\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`\\xA0 \\xA0 curl http://themes.jsonresume.org/themes.json |jq .\n`)),mdx(\"p\",null,\"I tried a bunch of them\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`\\xA0 \\xA04679 \\xA0resume export site/resume/index.html -t modern-freeland\n\\xA0 \\xA04680 \\xA0resume export site/resume/index.html -t modern-freelance\n\\xA0 \\xA04682 \\xA0resume export site/resume/index.html -t modern-with-projects-section\n\\xA0 \\xA04683 \\xA0resume export site/resume/index.html -t dangerflat\n\\xA0 \\xA04684 \\xA0resume export site/resume/index.html -t striking\n\\xA0 \\xA04685 \\xA0resume export site/resume/index.html -t crisp\n\\xA0 \\xA04686 \\xA0resume export site/resume/index.html -t semantic-ui\n\\xA0 \\xA04687 \\xA0resume export site/resume/index.html -t material\n\\xA0 \\xA04688 \\xA0resume export site/resume/index.html -t modern-extended\n\\xA0 \\xA04689 \\xA0resume export site/resume/index.html -t paper\n\\xA0 \\xA04690 \\xA0resume export site/resume/index.html -t smart\n\\xA0 \\xA04691 \\xA0resume export site/resume/index.html -t flat\n\n`)),mdx(\"p\",null,`Note: resume.json is setup to use HTML themes, so even though it has a\nPDF output option, it is inherently converting HTML first and then to\nPDF. The PDF conversion is done by a automated cloud service, which\ncurrently can fail sometimes. It is probably better to just choose HTML\nand convert to PDF if you need to.\nSee\\xA0`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://github.com/jsonresume/resume-cli/issues/94\"}),\"https://github.com/jsonresume/resume-cli/issues/94\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Creating a testing framework for JBrowse plugins","date":"2016-04-19","slug":"2016-04-19","mdxSource":{"compiledSource":"var h=Object.defineProperty,m=Object.defineProperties;var d=Object.getOwnPropertyDescriptors;var r=Object.getOwnPropertySymbols;var o=Object.prototype.hasOwnProperty,n=Object.prototype.propertyIsEnumerable;var p=(e,t,s)=>t in e?h(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s,a=(e,t)=>{for(var s in t||(t={}))o.call(t,s)&&p(e,s,t[s]);if(r)for(var s of r(t))n.call(t,s)&&p(e,s,t[s]);return e},c=(e,t)=>m(e,d(t));var l=(e,t)=>{var s={};for(var i in e)o.call(e,i)&&t.indexOf(i)<0&&(s[i]=e[i]);if(e!=null&&r)for(var i of r(e))t.indexOf(i)<0&&n.call(e,i)&&(s[i]=e[i]);return s};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(s){var i=s,{components:e}=i,t=l(i,[\"components\"]);return mdx(MDXLayout,c(a(a({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Testing client side apps requires a couple of tedious steps: Organizing\nthe git clone, the dependencies, wrangling up a web server, the test\nframework, etc.`),mdx(\"p\",null,`When testing a plugin for jbrowse, the dependency tree is interesting\nbecause the plugin \"depends\" on JBrowse to run, but we will use\ntravis-CI and bower inside the git repo for our plugin to accomplish\nthis.`),mdx(\"p\",null,\"In this scenario, we will\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Use bower to install jasmine and JBrowse (our platform that we write\nthe plugin for)`)),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},\"Use nginx to launch a webserver on travis-CI\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Use the phantomjs run-jasmine.js script to check jasmine test\nresults`))),mdx(\"p\",null,\"Without further ado\"),mdx(\"p\",null,\"Here is the .travis.yml\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),`sudo: false\naddons:\n  apt:\n    packages:\n    - nginx\ncache:\n  apt: true\n  directories:\n  - $HOME/.cache/bower\nbefore_install:\n  - npm install -g jshint bower\ninstall:\n  - bower install\nbefore_script:\n  - cat test/travis.conf | envsubst > test/travis-envsubst.conf\n  - nginx -c \\`pwd\\`/test/travis-envsubst.conf\nscript:\n  - phantomjs test/run-jasmine.js http://localhost:9000/test/\n  - jshint js\n`)),mdx(\"p\",null,`Refer to\n`,mdx(\"a\",a({parentName:\"p\"},{href:\"http://searchvoidstar.tumblr.com/post/141858047213/running-nginx-on-containerised-travis-ci-pt-2\"}),\"http://searchvoidstar.tumblr.com/post/141858047213/running-nginx-on-containerised-travis-ci-pt-2\"),`\nfor details on the nginx setup`),mdx(\"p\",null,\"Here is the bower.json\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),`{\n  \"name\": \"sashimiplot\",\n  \"homepage\": \"https://github.com/cmdcolin/sashimiplot\",\n  \"description\": \"Sashimi track type for jbrowse\",\n  \"main\": \"js/main.js\",\n  \"keywords\": [\n    \"bioinformatics\",\n    \"jbrowse\"\n  ],\n  \"license\": \"MIT\",\n  \"ignore\": [\n    \"**/.*\",\n    \"node_modules\",\n    \"bower_components\",\n    \"src\",\n    \"test\",\n    \"tests\"\n  ],\n  \"devDependencies\": {\n    \"jasmine-core\": \"jasmine#^2.4.1\",\n    \"jbrowse\": \"git://github.com/GMOD/jbrowse.git#master\"\n  }\n}\n`)),mdx(\"p\",null,`The key thing here is that it installs jasmine and JBrowse. I set\n.bowerrc to install both jasmine and JBrowse to the \"test\" directory`),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),`{\n    \"directory\": \"test\"\n}\n`)),mdx(\"p\",null,`With this setup, bower will make a \"flat dependency tree\" in the test\ndirectory, so it will look like this`),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),`$ ls -1 test\nFileSaver\ndbind\ndgrid\ndijit\ndojo\ndojox\n*index.html*\njDataView\njasmine-core\njbrowse\njson-schema\njszlib\nlazyload\nput-selector\n*run-jasmine.js*\n*spec*\n*travis.conf*\nutil\nxstyle\n`)),mdx(\"p\",null,`Here the asterisks indicate things that are part of our app, other's are\nautomatically installed by bower (jbrowse, jasmine-core, the dojo\ndependencies, and other things)`),mdx(\"p\",null,\"Then we can create the jasmine test/index.html to be something like this\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),`<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n  \"http://www.w3.org/TR/html4/loose.dtd\">\n\n\n  <meta>\n  Jasmine Spec Runner\n\n  <link rel=\"stylesheet\" href=\"jasmine-core/lib/jasmine-core/jasmine.css\"><script src=\"jasmine-core/lib/jasmine-core/jasmine.js\"><\\/script><script src=\"jasmine-core/lib/jasmine-core/boot.js\"><\\/script><script type=\"text/javascript\" src=\"dojo/dojo.js\" data-dojo-config=\"async: 1\"><\\/script><script type=\"text/javascript\">\n    require( { baseUrl: '.',\n               packages: [\n                   'dojo',\n                   'dijit',\n                   'dojox',\n                   'jszlib',\n                   { name: 'lazyload', location: 'lazyload', main: 'lazyload' },\n                   'dgrid',\n                   'xstyle',\n                   'put-selector',\n                   'FileSaver',\n                   { name: 'jDataView', location: 'jDataView/src', main: 'jdataview' },\n                   { name: 'JBrowse', location: 'jbrowse/src/JBrowse' },\n                   { name: 'SashimiPlot', location: '../js' }\n               ]\n    });\n  <\\/script><script type=\"text/javascript\" src=\"spec/SashimiPlot.spec.js\"><\\/script><div id=\"sandbox\" style=\"overflow:hidden; height:1px;\"></div>\n`)),mdx(\"p\",null,`The \"packages\" in the require statement puts all these packages in the\nright \"namespace\" for the AMD includes, and the \"specs\" are defined like\n`,mdx(\"inlineCode\",{parentName:\"p\"},'<script type=\"text/javascript\" src=\"spec/Projection.spec.js\"><\\/script>')),mdx(\"p\",null,`Finally, run-jasmine.js is used to check the results of the jasmine\ntests (it is run via phantomjs in the travis-CI script). It is a special\nversion for the most recent version of jasmine (2.4)\n`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://gist.github.com/vmeln/b6cbb319d9a0efc816be\"}),\"https://gist.github.com/vmeln/b6cbb319d9a0efc816be\")),mdx(\"p\",null,`For an example of the project using this, see\n`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://github.com/cmdcolin/sashimiplot\"}),\"https://github.com/cmdcolin/sashimiplot\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Creating a docker image","date":"2016-04-17","slug":"2016-04-17","mdxSource":{"compiledSource":"var p=Object.defineProperty,m=Object.defineProperties;var s=Object.getOwnPropertyDescriptors;var t=Object.getOwnPropertySymbols;var c=Object.prototype.hasOwnProperty,d=Object.prototype.propertyIsEnumerable;var u=(e,o,a)=>o in e?p(e,o,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[o]=a,n=(e,o)=>{for(var a in o||(o={}))c.call(o,a)&&u(e,a,o[a]);if(t)for(var a of t(o))d.call(o,a)&&u(e,a,o[a]);return e},i=(e,o)=>m(e,s(o));var l=(e,o)=>{var a={};for(var r in e)c.call(e,r)&&o.indexOf(r)<0&&(a[r]=e[r]);if(e!=null&&t)for(var r of t(e))o.indexOf(r)<0&&d.call(e,r)&&(a[r]=e[r]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var r=a,{components:e}=r,o=l(r,[\"components\"]);return mdx(MDXLayout,i(n(n({},layoutProps),o),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"Example\"),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`    brew install docker boot2docker docker-machine\n    docker-machine create --driver virtualbox default\n    docker-machine env default # will output some variables\n    eval \"$(docker-machine env default)\" # use those variables\n    # make dockerfile\n    docker build -t nameof-yourimage .\n`)))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Basic command line productivity tricks and learning experiences","date":"2016-04-06","slug":"2016-04-06","mdxSource":{"compiledSource":"var d=Object.defineProperty,c=Object.defineProperties;var h=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var l=(e,a,t)=>a in e?d(e,a,{enumerable:!0,configurable:!0,writable:!0,value:t}):e[a]=t,o=(e,a)=>{for(var t in a||(a={}))s.call(a,t)&&l(e,t,a[t]);if(n)for(var t of n(a))r.call(a,t)&&l(e,t,a[t]);return e},m=(e,a)=>c(e,h(a));var u=(e,a)=>{var t={};for(var i in e)s.call(e,i)&&a.indexOf(i)<0&&(t[i]=e[i]);if(e!=null&&n)for(var i of n(e))a.indexOf(i)<0&&r.call(e,i)&&(t[i]=e[i]);return t};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(t){var i=t,{components:e}=i,a=u(i,[\"components\"]);return mdx(MDXLayout,m(o(o({},layoutProps),a),{components:e,mdxType:\"MDXLayout\"}),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"dd deletes line in vim\"),mdx(\"li\",{parentName:\"ul\"},\"Ctrl+d scrolls down in vim\"),mdx(\"li\",{parentName:\"ul\"},`Learn to love your package manager. Homebrew, NPM, gem, cpanm,\ngvm/sdkman, etc. these all do amazing things`),mdx(\"li\",{parentName:\"ul\"},`Once you learn bash, try zsh and oh-my-zsh, they have things like\ncase-insensitive tab completion`),mdx(\"li\",{parentName:\"ul\"},`Don't make scripts that hardcode paths, make reusable command line\nscripts. Use bash as your\\xA0\"REPL\", not R.`),mdx(\"li\",{parentName:\"ul\"},`git log -p helps analyze your log files in full details (make sure\nautocoloring is turned on in your terminal)`),mdx(\"li\",{parentName:\"ul\"},`There are keys to jump forward and backwards on the command line\ntext editor, learn them...don't scroll one char at a time`),mdx(\"li\",{parentName:\"ul\"},`Learn how\\xA0\"PATH\" works. Generally it is just a set of directories\nconnected by\\xA0\":\" separators. You can add things to the path by\nsaying\\xA0\"export PATH=$PATH:/new/directory/to/add\" and you can add\nthis to ~/.bashrc for example`),mdx(\"li\",{parentName:\"ul\"},`When your install process for a command line tool seems like\nnonsense, try homebrew instead. barring that, learn PATH, and how to\nrun\\xA0\"make install\", etc. Most of your headbashing from installing\nprograms is 90% can be explained by not understanding how the\ndeveloper is intending it to be used, 10% of the tool's install\nprocess being wrong`),mdx(\"li\",{parentName:\"ul\"},`Get a static analyzer and basic tests going on your codebase and run\nit on travis-ci. Getting started with travis-ci is kind of a\nlearning curve, but it is worth it`),mdx(\"li\",{parentName:\"ul\"},\"Use cpanm instead of cpan for package management\"),mdx(\"li\",{parentName:\"ul\"},`Vocabulary learning curve: catalina is the same thing as tomcat.\nCATALINA_HOME is the same thing as the tomcat folder`),mdx(\"li\",{parentName:\"ul\"},'alias ll=\"ls -l\", because I type\\xA0\"ll\" hundreds of times a day.'),mdx(\"li\",{parentName:\"ul\"},`For irc productivity, run irssi on a server in a\\xA0\"screen\"\ne.g.\\xA0\"screen irssi\" and then you can come back to conversations\nlater by just logging into the server with ssh`),mdx(\"li\",{parentName:\"ul\"},`Edit ~/.ssh/config to include your hostnames so you don't have to type out\nlong ssh\ncommands\\xA0`,mdx(\"a\",o({parentName:\"li\"},{href:\"http://nerderati.com/2011/03/17/simplify-your-life-with-an-ssh-config-file/\"}),\"http://nerderati.com/2011/03/17/simplify-your-life-with-an-ssh-config-file/\")),mdx(\"li\",{parentName:\"ul\"},`Use spaces instead of tabs in your source code (>:( yes I think\nthis is the one true way)`),mdx(\"li\",{parentName:\"ul\"},`Try out nodejs and browserify in your spare time to make a\\xA0\"npm\"\nbased app in the browser. it's fun.`),mdx(\"li\",{parentName:\"ul\"},`Similarly, try making a simple \"api\" endpoint on the server side\nwith express.js or similar. can get started very quickly.`),mdx(\"li\",{parentName:\"ul\"},`Learn how to get a mindset of writing tests. You can write tests\nproactively (i.e. Test driven development), but you can also write\nthem\\xA0\"reactively\" too (i.e. if have a bug that you fix, you can make\na test to make sure this doesn't happen anymore)`),mdx(\"li\",{parentName:\"ul\"},`Similar to above, tests in this sense are more\\xA0\"sanity checks\" than\nthey are formal proofs. Take\\xA0\"assert\" logic and\\xA0\"debugging\" code out\nof main codebase and put them in tests`),mdx(\"li\",{parentName:\"ul\"},`Minimize comments in your code, and also don't comment out code and\nleave it present. Find a way to delete it and move on!`),mdx(\"li\",{parentName:\"ul\"},`When you have a bunch of .orig files after doing a git merge, just\nuse git clean -f to get rid of them. Similarly, to get rid of\neverythng, including things in your gitignore file (i.e. a super\nclean) use git clean -fdx. It has a --exclude argument too`)),mdx(\"p\",null,`::: {#footer}\n`,\"[ April 6th, 2016 4:23pm ]\",`{#timestamp}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Running nginx on containerised travis-CI pt 2","date":"2016-03-28","slug":"2016-03-28","mdxSource":{"compiledSource":"var c=Object.defineProperty,u=Object.defineProperties;var g=Object.getOwnPropertyDescriptors;var s=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,a=Object.prototype.propertyIsEnumerable;var p=(e,t,n)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:n}):e[t]=n,o=(e,t)=>{for(var n in t||(t={}))r.call(t,n)&&p(e,n,t[n]);if(s)for(var n of s(t))a.call(t,n)&&p(e,n,t[n]);return e},l=(e,t)=>u(e,g(t));var h=(e,t)=>{var n={};for(var i in e)r.call(e,i)&&t.indexOf(i)<0&&(n[i]=e[i]);if(e!=null&&s)for(var i of s(e))t.indexOf(i)<0&&a.call(e,i)&&(n[i]=e[i]);return n};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(n){var i=n,{components:e}=i,t=h(i,[\"components\"]);return mdx(MDXLayout,l(o(o({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`There are several guides out there about how to setup nginx on travis-CI\nbut I still found it to be a challenge, especially finding a modern one\nthat works with the containerized builds. I was frustrated that things\nlike `,mdx(\"inlineCode\",{parentName:\"p\"},\"SimpleHTTPServer\"),` from python and http-server from npm did not have\nfully enough features to run our app either (a complex \"static-site\ngenerator\" type thing you might say), and I was also too lazy to setup\n\"sauce labs\" (which I have not used, but presume has some better ability\nto run functional/browser tests).`),mdx(\"p\",null,`Essentially, the problem with running nginx under the containerized\nbuild is that it \"likes to be sudo\", with many logfiles by default going\nto different places that only sudo has access to.`),mdx(\"p\",null,`This link is probably the most similar to the technique I use here, but\nit is now gone (?) and must be accessed through the internet archive!`),mdx(\"p\",null,mdx(\"a\",o({parentName:\"p\"},{href:\"http://www.doublesignal.com/running-nginx-on-containerised-travis-ci\"})),mdx(\"a\",o({parentName:\"p\"},{href:\"https://web.archive.org/web/20150919050719/http://www.doublesignal.com/running-nginx-on-containerised-travis-ci\"}),\"https://web.archive.org/web/20150919050719/http://www.doublesignal.com/running-nginx-on-containerised-travis-ci\")),mdx(\"p\",null,`My technique is very similar, however I use an extra trick to set the\nfile root to the current directory (instead of /tmp/nowhere as in the\nlink) by using \"envsubst\" to replace variables in the nginx config file.`),mdx(\"p\",null,\"Without further ado, the .travis.yml can look like this\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`    sudo: false\n    addons:\n      apt:\n        packages:\n        - nginx\n    install:\n      - cat tests/travis.conf | envsubst > tests/travis-envsubst.conf\n      - nginx -c \\`pwd\\`/tests/travis-envsubst.conf\n    script:\n      - wget http://localhost:9000/yourfiles\n`)),mdx(\"p\",null,\"Then your nginx config file can look like this\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`    worker_processes 10;\n    pid /tmp/nginx.pid;\n\n    error_log /tmp/error.log;\n\n    events {\n        worker_connections 768;\n    }\n\n    http {\n        client_body_temp_path /tmp/nginx_client_body;\n        fastcgi_temp_path     /tmp/nginx_fastcgi_temp;\n        proxy_temp_path       /tmp/nginx_proxy_temp;\n        scgi_temp_path        /tmp/nginx_scgi_temp;\n        uwsgi_temp_path       /tmp/nginx_uwsgi_temp;\n\n        server {\n            listen 9000 default_server;\n\n            server_name localhost;\n            location / {\n                root $TRAVIS_BUILD_DIR;\n                index  index.html index.htm;\n            }\n            error_log /tmp/error.log;\n            access_log /tmp/access.log;\n        }\n    }\n\n`)),mdx(\"p\",null,`Then, when travis-CI is run, it uses envsubst to replace\n`,mdx(\"inlineCode\",{parentName:\"p\"},\"$TRAVIS_BUILD_DIR\"),` in the tests/travis.conf file, and then boots up\nnginx`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"On over-reproducibility","date":"2016-03-05","slug":"2016-03-05","mdxSource":{"compiledSource":"var p=Object.defineProperty,d=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var r=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,n=Object.prototype.propertyIsEnumerable;var l=(e,t,o)=>t in e?p(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,i=(e,t)=>{for(var o in t||(t={}))s.call(t,o)&&l(e,o,t[o]);if(r)for(var o of r(t))n.call(t,o)&&l(e,o,t[o]);return e},h=(e,t)=>d(e,c(t));var u=(e,t)=>{var o={};for(var a in e)s.call(e,a)&&t.indexOf(a)<0&&(o[a]=e[a]);if(e!=null&&r)for(var a of r(e))t.indexOf(a)<0&&n.call(e,a)&&(o[a]=e[a]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var a=o,{components:e}=a,t=u(a,[\"components\"]);return mdx(MDXLayout,h(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Recently, some posts were made by\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://twitter.com/arjunrajlab\"}),\"https://twitter.com/arjunrajlab\"),`\\xA0about how perhaps we are aiming at\n\"over-reproducibility\". I think this is interesting, and would generally\nagree that not everyone needs to achieve total automation of their whole\npipeline, but I think the post does a lot of \"blaming your tools\" and\ndisparaging good development practices with regards to version control\nand figure generation.`),mdx(\"p\",null,`I think that the complaint that version control and automated figures\nare not for everyone is probably true, but it is overgeneralizing a\ndifferent problem. For example, students are not \"trained\" to work with\nGit, and they are not \"trained\" to do software engineering. In fact,\neven computer science students are not generally \"trained\" to do any of\nthose things (computer science != software engineering). But that\ndoesn't mean that your lab needs to forego using all those tools.\nSoftware\\xA0development can be incredibly complex and sophisticated, but\nit's important to make sure things are\\xA0\"done right\"! High-quality and\neasy-to-reproduce software is really about process, and engineering.\\xA0But\nthat is also why there is no one-true-way for reproducibility.\\xA0Maybe\nArjun doesn't have a reproducible workflow right now, but what about 5\nyears down the road, where he suddenly has a great framework for such\nthings? This happens all the time in software development (for example,\nhow long ago was it that \"push to deploy\" did not exist? how often would\nyou just edit your files live on your site? now that is seen as bad\npractice!), but that said, processes for software quality can evolve\npretty organically, so even though some best practices exist, people can\ngrow their own quality environment.`),mdx(\"p\",null,`Even if we agree that software development+version control=good, there\nare still a lot of complaints about it in the blogpost. For example, the\ncomplaint that git is too hard is pretty silly, and the xkcd comic about\ncalling over graph theorist doesn't really help. As a software developer\nat work, I think that version control simply helps define a disciplined\nway of working. Version control makes you analyze your progress,\nsummarize it as a commit message, format the code properly, make sure it\npasses tests, and then talk to your collaborators about accepting it.\nDropbox might accomplish some of those things, but I would really doubt\nthat it is covering that full scope. Arjun seems to agree with using\nversion control for some of his labs software development, so again,\nthere is a spectrum of needs being met. Nevertheless, there are some\nweird comments about whether commit messages are like a \"lab notebook\",\nbut hint: they are not, write documentation for your project or keep a\nseparate journal or blog or wiki. Commit messages in my opinion should\nbe about one line, and the changes should be very self explanatory. But\nanother big argument in the blogpost is whether version control\\xA0works\nfor something like paper writing, and I believe that this underscores\nsomething else: that paper writing is really a pretty messy procedure.`),mdx(\"p\",null,`I think that perhaps the\\xA0\"google docs\" mode of writing is probably\npretty ok for many things, but it still needs a gatekeeper to\nincorporate the comments from coauthors and reviewers into the document\nin an organized way. In my experience as a \"gatekeeper\"\\xA0with writing my\nsenior thesis, I organized my paper using knitr, and I automated figures\nbeing generated by R wherever possible, and then I would convert the\npaper to .docx to share with my advisors. Then I would take their\ncomments on the .docx and incorporate it back into my paper. This could\nbe seen as burdensome (\"why not just use google docs\"), but I felt that\nit was a good way to incorporate review into a reproducible workflow.`),mdx(\"p\",null,`Now, my pipeline precludes your PI from having to learn git to make a\npull request on your paper. That's a good thing... and we still have\nreproducibility.\\xA0\\xA0But what about the figures themselves? I said I had\nknitr for reproducible figures, but what about everyone else? I think\nfigures have high value, and so people might want to have more\nreproducibility invested in them. In the blog post, it was claimed that\nmaking \"complex\" pub-quality figures was difficult\\xA0(i.e. the plea for\nAdobe Illustrator), but look at the annotation functions from ggplot2,\nand multifaceted images. I found these annotation functions to be very\neasy to pick up. There is also the on-going debate about ggplot2 vs base\ngraphics on the simplystatistics blog, which covers making publication\nquality figures, and last I checked, I think the ggplot2\\u2032ers were\nwinning. I don't know how it works in high profile journals like Nature,\nbecause it looks like they just re-do all the figures to make them have\nsome consistent style, but that doesn't mean your original figure should\nbe irreproducible.`),mdx(\"p\",null,`The debate about reproducible figures is pretty tangible too in things\nlike microscopy images. Simply look at the large amount of discussion\nfrom pubpeer about image fraud and possible duplications. The pubpeer\ncommunity obviously has some pretty sophisticated tools for hunting out\npossibly manipulated microscopy images. These types of things also lead\nto investigations, and you can see in the high-profile retraction case\nover STAP cells that it looks like the investigating committee were\nsimply asking how some figures were made, and upon finding that lab\nmembers don't know, a paper was retracted. The RetractionWatch blog\ncovers\\xA0these\ninvestigations\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/\"}),\"http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/\")),mdx(\"p\",null,`You can't depend on\\xA0other people to back your figure up, so you need to\ntake responsibility for making sure your papers and your work are\nreproducible (and, there is a spectrum for reproducibility, but I\nbelieve that version control is a great example of highly disciplined\nwork). I also think that just having folders on some hard drive is not a\ngood way to do things either. There is a saying in software development\nthat is\\xA0\"if it's not in version control, it doesn't exist\". That's not\nto say that version control is for everything, big data obviously has\ntrouble with being stored in git. But that shouldn't block you from\ncreating reproducible analyses.`),mdx(\"p\",null,`Another example from the over-reproducibility blogpost says that if you\nhave \"analysis1\\u2033 and\\xA0\"analysis2\\u2033, then version control advocates would\ntell you to delete analysis1 and just remember that it is in your\nhistory. I think that this is just a different issue. If you actually\ncare about both analyses, just make them separate repositories, with\nbasic README.md files explaining each them, and stop worrying about it.\nHaving one repository containing too many miscellaneous scripts is\nactually an anti-pattern. Stop making repositories\ncalled\\xA0\"bioinfo-scripts\" that just contain a mish-mash of analysis\nscripts! Make your work purpose driven and do tasks. Also, this is an\nargument against REPL tools: your R REPL history is not a reproducible\nscript. Make your code into a script that generates well defined\noutputs. Windows users: you might not understand this because the\ncommand line on windows is crippled, but you have to make things run on\nthe command line.`),mdx(\"p\",null,`Now I wish I could say that I live by my words, but having been involved\nin coauthoring several papers, I will just have to admit that it is\nreally a messy procedure despite my best intentions as an editor and\ncoauthor. I wish things would be better!`),mdx(\"p\",null,`On over-reproducibility: there is no such thing!\\xA0There are pretty good\narguments to really automate most of a process, especially if it is done\nrepeatedly, to remove human errors, because meat-machines genuinely do\nthings wrong all the time.`),mdx(\"p\",null,`And, as my parents would say around the dinner table:\\xA0\"you can always\nhave more, but you can never have less\"...so, you're not going to get to\na point of over-reproducibility. We shouldn't cargo cult it as the only\nway to do science but it's not a bad thing to have.`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Cheating in your computer science class by copying from stackoverflow","date":"2015-12-17","slug":"2015-12-17","mdxSource":{"compiledSource":"var p=Object.defineProperty,c=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var i=Object.getOwnPropertySymbols;var s=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var h=(e,t,a)=>t in e?p(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,n=(e,t)=>{for(var a in t||(t={}))s.call(t,a)&&h(e,a,t[a]);if(i)for(var a of i(t))r.call(t,a)&&h(e,a,t[a]);return e},l=(e,t)=>c(e,u(t));var d=(e,t)=>{var a={};for(var o in e)s.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&i)for(var o of i(e))t.indexOf(o)<0&&r.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=d(o,[\"components\"]);return mdx(MDXLayout,l(n(n({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I would like to tell a story about how I provided some personal tutoring\nhelp for a friend in a computer science class, and talk about a nagging\nfeeling that really felt wrong for me.`),mdx(\"p\",null,`So, a long time ago, in a land far far away, a friend took an\nintermediate class on C++. I was first updated on his progress when he\nemailed me to get some help with some compiler errors. I was happy to\nhelp the young padawan. Here was the error:`),mdx(\"pre\",null,mdx(\"code\",n({parentName:\"pre\"},{}),`         test.cpp:42:43: error: non-ASCII characters are not allowed outside of literals\n                and identifiers\n              for (startScan = 0; startScan < (size \\u2212 1); startScan++)\n                                                    ^~\n`)),mdx(\"p\",null,`Now, what does this say to you? For me, it was actually very clear what\nthe error meant. It simply meant that this code was taken from\nsomewhere, and copied and pasted into the compiler. I know that because\nif they had typed it themself, they definitely would not get this error,\nbecause it is the error that implies something was automatically\nconverted to a unicode dash, mostly something done during copying and\npasting. At this point, I just kind of laughed, and helped him fix that.\nI showed how the compiler is actually pretty smart and can help fix\nthese errors and then I said \"l8r dude\".`),mdx(\"p\",null,`The next week, I had another skype meeting with him, and this time I\nwanted to help a little more. It was pretty clear when we started that\nhe was using code that was copied and pasted again. I said, \"uh,\nok,....I'm not sure we need that now, but let's just keep going\", and\nthen I sat down and started helping. I wanted to help get all the\ndetails of the program working, so I helped guide the solution. Each\ntime we needed to test the program, it required repeating some input\nlines via `,mdx(\"inlineCode\",{parentName:\"p\"},\"cin >>\"),`, which is really annoying (obviously, you should test\nyour code with unit tests, but universities don't teach that, a rant for\nanother day). Anyways, it took awhile, because coding really does just\ntake time, but in the end he finally got it fixed and I said great job,\nand he turned it in!`),mdx(\"p\",null,`Now, on my friends last assignment, I got another call for help, and\nwhen we started skype, I found yet again that he had copied code from\nsomewhere, which included a C++ class and a main function for doing\nbinary trees. I just simply said \"dude, delete that, we don't need it\"\nand so he deleted it, but I think maybe he had worked on this copied\ncode for awhile, and maybe felt it was kind of his, so was apprehensive.\nI insisted though. Then we walked through the assignment again, very\nslowly. I spent probably 2-3 hours helping him out that night. During\nthose hours, I saw him continually making many programming mistakes such\nas just not knowing how to declare variable or a function properly, or\njust not knowing what to do next. This was kind of frustrating!!! But I\nwanted to absolutely teach him how to make it right! I was patient\nthough, and I wanted to teach a fun lesson, so I showed how you can do\nsome \"unit tests\" which avoids having to constantly re-enter your data\nvia `,mdx(\"inlineCode\",{parentName:\"p\"},\"cin >>\"),\"....\"),mdx(\"p\",null,`Now, the padawan completed his C++ class, and then we all were happy\never after....but a disturbance in the force was sensed...\n`,mdx(\"img\",n({parentName:\"p\"},{src:\"http://zelcs.com/wp-content/uploads/2013/02/stackoverflow-logo-dumpster.jpg\",alt:\"image\"})),`\nImage from `,mdx(\"a\",n({parentName:\"p\"},{href:\"http://zelcs.com/this-is-why-stackoverflow-sucks/\"}),\"http://zelcs.com/this-is-why-stackoverflow-sucks/\")),mdx(\"p\",null,\"I was reminded about all this due to seeing that \",mdx(\"a\",n({parentName:\"p\"},{href:\"http://meta.stackexchange.com/questions/271080/the-mit-license-clarity-on-using-code-on-stack-overflow-and-on-the-stack-excha\"}),`StackOverflow is now\nchanging their \"license\" over all the little snippets of\ncode`),`\nthat are posted on their site. It just makes me reflect on literally HOW\nOFTEN PEOPLE JUST COPY AND PASTE FROM THERE. They might understand what\nthey are doing, or they seriously might not!!! I think it is a real\nproblem that people sometimes do not understand, but I cannot deny that\nit can be helpful too.`),mdx(\"p\",null,`If I reflect on education in general, I recall when I took a University\nlevel physics class... it was really hard! We had to enter our validated\nsolutions for the math problems into a computerized website homework\nportal, and that involved being 100% correct about things. Now, what if\nthere was just a physicsoverflow, where they not only had Q&A, but they\nhad \"programs\" that gave you all the right answers to your homework\nproblems that you could just copy and paste and use as solutions to your\nhomework? This isn't even in the realm of asking for \"homework help\"\nanymore, this is just pure cheating if you can copy your answers from\nsomewhere. It is disappointing though because this is what people are\ndoing in computer science!! These students are missing out on basic\nunderstanding of code. !!thisIsNotOk();`),mdx(\"p\",null,`Now, at least when I was being a tutor for my friend, I felt like my\nadvice helped my friend learn some things, not just give answers. But\nwhat if I was not there? I guess there is a certain \"impersonal quality\"\nthat makes asking Google/StackOverflow for answers less like\nconventional \"cheating\", but that is still wrong. I think it would be\ngood if more expert knowledge was available for all people, and not just\ncopy and paste snippets. As a start, I thought that `,mdx(\"a\",n({parentName:\"p\"},{href:\"http://cacm.acm.org/magazines/2015/10/192385-life-after-moocs/fulltext\"}),`this post by Philip\nCompeau and Pavel\nPevzner`),`\n(who teach a Bioinformatics Algorithms MOOC on Coursera) was very\ninteresting, and I really liked their quote:`),mdx(\"p\",null,`\"Online education should move toward replicating the experience of\nreceiving one-on-one tutoring.\"`),mdx(\"p\",null,`That sounds great, but how can this be acheived? And how can it be done\nright? I think it really requires the student to \"learn how to learn\"`),mdx(\"p\",null,`If I think back to a long time ago, I remember being in 4th or 5th grade\nand I did a book report on World War 1, and I went to the library. I\nremember desperately flipping through pages of a 100 page book to try to\nfind some snippets of information to support some basic idea that I\nwanted to talk about. Maybe I wanted to know something specific, but the\nproblem was that I wasn't REALLY READING THE BOOK! I probably could have\nhad a better understanding of the topic if I had just read it, or even a\npart of it, and asked for help, but instead I just picked and chose\nsnippets from the book to \"sound smart\". I am very guilty of this type\nof error in many instances throughout my school career, so I am no\nsaint! I even have a phrase to describe this style of learning...I call\nit \"predatory learning\" and it is probably the worst kind of learning\nstyle. Predatory learners often pick and choose from scraps of info, but\nthey never get a full meal!`),mdx(\"p\",null,`::: {#footer}\n`,\"[ December 17th, 2015 3:05am ]\",\"{#timestamp} \",\"[learning]\",`{.tag}\n`,\"[education]\",\"{.tag} \",\"[computer science]\",\"{.tag} \",\"[stackoverflow]\",`{.tag}\n`,\"[fail]\",`{.tag}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Killing postgres the hard way","date":"2015-10-22","slug":"2015-10-22","mdxSource":{"compiledSource":"var c=Object.defineProperty,u=Object.defineProperties;var _=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,d=Object.prototype.propertyIsEnumerable;var r=(e,t,a)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,i=(e,t)=>{for(var a in t||(t={}))n.call(t,a)&&r(e,a,t[a]);if(o)for(var a of o(t))d.call(t,a)&&r(e,a,t[a]);return e},p=(e,t)=>u(e,_(t));var h=(e,t)=>{var a={};for(var s in e)n.call(e,s)&&t.indexOf(s)<0&&(a[s]=e[s]);if(e!=null&&o)for(var s of o(e))t.indexOf(s)<0&&d.call(e,s)&&(a[s]=e[s]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var s=a,{components:e}=s,t=h(s,[\"components\"]);return mdx(MDXLayout,p(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`So today, I finally decided to do something about a query that we saw\nhad been running for 25 DAYS on our server`),mdx(\"p\",null,`Note: If you find this post and you need to follow the hard way, backup\nyour data first if possible.`),mdx(\"p\",null,`First I could obviously see the culprit: each postgress query runs it's\nown process so I could see in \"htop\"\\xA0that there was this process that\nhad been running for 600 hours, or about 25 days`),mdx(\"p\",null,\"Next, I opened a psql console and ran this query:\"),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> SELECT datname,procpid,current_query FROM pg_stat_activity WHERE\n> datname='database_name' ORDER BY procpid ;\n`)),mdx(\"p\",null,`This returns which actual queries are being run on the database at any\ngiven time. \\xA0I could easily see the one problematic query being run,\nwhich was a badly constructed intermine template query that resulted in\na weird \"recursion\" essentially.`),mdx(\"p\",null,\"I wanted to try just terminating this query itself, so I ran this\"),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> SELECT pg_cancel_backend(29033);\n`)),mdx(\"p\",null,`Each time I ran it, it would say it returned one result but it did\nnothing.`),mdx(\"p\",null,`I also read that you can try to nicely\\xA0\"kill\" it from the command line\n(no kill -9) so I ran`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> kill\\xA029033\n`)),mdx(\"p\",null,\"This also did not work!\"),mdx(\"p\",null,`I thought perhaps all these problems were because tomcat was still\nactive, so we shut down tomcat, and retried killing the specific query,\nbut to no avail`),mdx(\"p\",null,`At this point, I just wanted to restart the whole database server. Kind\nof a risky move... but I am sort of a risky kind of guy...(that is not a\ngood thing with databases). If you are doing this, make backups! I\ndidn't. Luckily I suffered no data loss but what follows is kind of\nintense.`),mdx(\"p\",null,\"So first, I try and stop the database service\"),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> service postgresql-9.1 stop\n`)),mdx(\"p\",null,\"Unfortunately, this \",mdx(\"inlineCode\",{parentName:\"p\"},\"[FAILED]\"),` ! And of course, even though it failed,\nthe database is now unusable. No logging into it anymore, we have to go\nwith the hard way now...`),mdx(\"p\",null,`Looking at /etc/init.d/postgres-9.1 told me that the service stop\ncommand was effectively using something like this:`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> pg_ctl -D /db/postgres/data -m fast stop\n`)),mdx(\"p\",null,`After some reading, I learned that you can try using a slightly\ndifferent flag to restart it`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> pg_ctl -D /db/postgres/data -m immediate \\xA0stop\n`)),mdx(\"p\",null,`I ran this and to my horror/surprise, it actually worked! At this point\nI decided to start postgresql back up again!`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> service postgresql-9.1 start\n`)),mdx(\"p\",null,`The service start quickly returned a SUCCESS, which was great, but then\nI tried to start a psql console and the console froze on me! I could not\neven ctrl+c it!`),mdx(\"p\",null,`I got really worried at this point and I looked at the process manager,\nand saw that there was one postmaster process running but it was not\nclear what it was doing. I actually tried to shutdown the server again\nin a panic mode but at this point it said`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> /usr/pgsql-9.1/bin/pg_ctl stop -D /db/postgres/data/ -m immediate\n> waiting for server to shut\n> down...............................................................\n> failed\n`)),mdx(\"p\",null,`It was probably good that it didn't shut down, because I would quickly\nfind out that it was in recovery mode. \\xA0I looked at the postgresql logs\nand I saw this, reproduced here for full detail (from before the\nshutdown to the restart)`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> WARNING: \\xA0pgstat wait timeout\n> WARNING: \\xA0pgstat wait timeout\n> WARNING: \\xA0pgstat wait timeout\n> WARNING: \\xA0pgstat wait timeout\n> WARNING: \\xA0pgstat wait timeout\n> WARNING: \\xA0pgstat wait timeout\n> WARNING: \\xA0pgstat wait timeout\n> WARNING: \\xA0pgstat wait timeout\n>\n> ERROR: \\xA0canceling statement due to user request\n> STATEMENT: \\xA0CREATE TABLE precomp_90519 AS SELECT DISTINCT a1_.id AS\n> a1_id, a2_.id AS a2_id, a3_.id AS a3_id, a4_.id AS a4_id,\n> a5_.id AS a5_id, a6_.id AS a6_id, a12_.id AS a12_id, a10_.id AS\n> a10_id, a1_.id AS a13_, a1_.primaryIdentifier AS a14_,\n> a1_.secondaryIdentifier AS a15_, a2_.type AS a16_, a3_.name AS\n> a17_, a4_.primaryIdentifier AS a18_, a5_.primaryIdentifier AS\n> a19_, a6_.shortName AS a20_, a12_.identifier AS a21_, a10_.code\n> AS a22_ FROM Gene AS a1_, Homologue AS a2_, Organism AS a3_, Gene\n> AS a4_, Gene AS a5_, Organism AS a6_, GOAnnotation AS a7_,\n> GOEvidence AS a8_, OntologyTerm AS a9_, GOEvidenceCode AS a10_,\n> OntologyAnnotation AS a11_, OntologyTerm AS a12_, GeneGoAnnotation\n> AS indirect0, EvidenceGOAnnotation AS indirect1 WHERE a1_.id =\n> a2_.geneId AND a1_.organismId = a3_.id AND a2_.geneId = a4_.id\n> AND a2_.homologueId = a5_.id AND a5_.organismId = a6_.id AND\n> a1_.id = indirect0.Gene AND indirect0.GoAnnotation = a7_.id AND\n> a7_.id = indirect1.GOAnnotation AND indirect1.Evidence = a8_.id AND\n> a7_.ontologyTermId = a9_.id AND a8_.codeId = a10_.id AND a9_.id =\n> a11_.ontologyTermId AND a11_.ontologyTermId = a12_.id ORDER BY\n> a1_.primaryIdentifier, a1_.secondaryIdentifier, a2_.type,\n> a3_.name, a4_.primaryIdentifier, a5_.primaryIdentifier,\n> a6_.shortName, a12_.identifier, a10_.code, a1_.id, a2_.id,\n> a3_.id, a4_.id, a5_.id, a6_.id, a12_.id, a10_.id\n> LOG: \\xA0could not send data to client: Broken pipe\n> STATEMENT: \\xA0CREATE TABLE precomp_90519 AS SELECT DISTINCT a1_.id AS\n> a1_id, a2_.id AS a2_id, a3_.id AS a3_id, a4_.id AS a4_id,\n> a5_.id AS a5_id, a6_.id AS a6_id, a12_.id AS a12_id, a10_.id AS\n> a10_id, a1_.id AS a13_, a1_.primaryIdentifier AS a14_,\n> a1_.secondaryIdentifier AS a15_, a2_.type AS a16_, a3_.name AS\n> a17_, a4_.primaryIdentifier AS a18_, a5_.primaryIdentifier AS\n> a19_, a6_.shortName AS a20_, a12_.identifier AS a21_, a10_.code\n> AS a22_ FROM Gene AS a1_, Homologue AS a2_, Organism AS a3_, Gene\n> AS a4_, Gene AS a5_, Organism AS a6_, GOAnnotation AS a7_,\n> GOEvidence AS a8_, OntologyTerm AS a9_, GOEvidenceCode AS a10_,\n> OntologyAnnotation AS a11_, OntologyTerm AS a12_, GeneGoAnnotation\n> AS indirect0, EvidenceGOAnnotation AS indirect1 WHERE a1_.id =\n> a2_.geneId AND a1_.organismId = a3_.id AND a2_.geneId = a4_.id\n> AND a2_.homologueId = a5_.id AND a5_.organismId = a6_.id AND\n> a1_.id = indirect0.Gene AND indirect0.GoAnnotation = a7_.id AND\n> a7_.id = indirect1.GOAnnotation AND indirect1.Evidence = a8_.id AND\n> a7_.ontologyTermId = a9_.id AND a8_.codeId = a10_.id AND a9_.id =\n> a11_.ontologyTermId AND a11_.ontologyTermId = a12_.id ORDER BY\n> a1_.primaryIdentifier, a1_.secondaryIdentifier, a2_.type,\n> a3_.name, a4_.primaryIdentifier, a5_.primaryIdentifier,\n> a6_.shortName, a12_.identifier, a10_.code, a1_.id, a2_.id,\n> a3_.id, a4_.id, a5_.id, a6_.id, a12_.id, a10_.id\n> LOG: \\xA0unexpected EOF on client connection\n> LOG: \\xA0unexpected EOF on client connection\n> LOG: \\xA0unexpected EOF on client connection\n> LOG: \\xA0unexpected EOF on client connection\n> LOG: \\xA0received fast shutdown request\n> LOG: \\xA0aborting any active transactions\n> LOG: \\xA0autovacuum launcher shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> FATAL: \\xA0the database system is shutting down\n> LOG: \\xA0received immediate shutdown request\n> WARNING: \\xA0terminating connection because of crash of another server\n> process\n> DETAIL: \\xA0The postmaster has commanded this server process to roll back\n> the current transaction and exit, because another server process\n> exited abnormally and possibly corrupted shared memory.\n> HINT: \\xA0In a moment you should be able to reconnect to the database and\n> repeat your command.\n> LOG: \\xA0received fast shutdown request\n> LOG: \\xA0database system was interrupted; last known up at 2015-10-22\n> 15:47:43 CDT\n> LOG: \\xA0received immediate shutdown request\n> LOG: \\xA0database system was interrupted; last known up at 2015-10-22\n> 15:47:43 CDT\n> LOG: \\xA0database system was not properly shut down; automatic recovery\n> in progress\n> LOG: \\xA0record with zero length at BBD/1CC2F0C0\n> ...\n`)),mdx(\"p\",null,\"You can see all the weird activity that was done here\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},'first the attempt to \"canceling statement due to user request\" did not work'),mdx(\"li\",{parentName:\"ul\"},\"then the database stop using -m fast\"),mdx(\"li\",{parentName:\"ul\"},\"then the database stop using -m immediate\"),mdx(\"li\",{parentName:\"ul\"},\"the restart (with the HINT, should be ready soon)\"),mdx(\"li\",{parentName:\"ul\"},\"the panic mode where i tried to shut it again anyways\")),mdx(\"p\",null,`During the recovery period, I was still very concerned about the\ndatabase was doing, so I used \"strace\" to look at the main postmaster\nprocess.`),mdx(\"p\",null,`I was pleasantly surprised to see that the postmaster process was just\ncleaning up files in /db/postgres/data/base/pgsql_tmp/, I could see the\nfile system \"unlink\" command with successful status codes.`),mdx(\"p\",null,`There were about 150 large files in /db/postgres/data/base/pgsql_tmp/,\nand I waited about an hour for them to be deleted, and after that, the\npostgresql log file said it was ready, and indeed, it was perfect :)`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`> LOG: \\xA0redo is not required\n> LOG: \\xA0database system is ready to accept connections\n> LOG: \\xA0autovacuum launcher started\n`)),mdx(\"p\",null,\"What a relief!\"),mdx(\"p\",null,`I hope this might help any wayward stragglers to see how the postgresql\nrestart process works. Sometimes things don't shut down cleanly, but I\nthink it is still good to know some alternative steps to kill -9`),mdx(\"p\",null,`::: {#footer}\n`,\"[ October 22nd, 2015 7:29pm ]\",\"{#timestamp} \",\"[postgresql]\",\"{.tag} \",\"[dba]\",`{.tag}\n`,\"[databases]\",\"{.tag} \",\"[sql]\",\"{.tag} \",\"[troubleshooting]\",`{.tag}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Tomcat memory debugging","date":"2015-10-15","slug":"2015-10-15","mdxSource":{"compiledSource":"var c=Object.defineProperty,l=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var s=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,p=Object.prototype.propertyIsEnumerable;var m=(e,t,a)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,i=(e,t)=>{for(var a in t||(t={}))r.call(t,a)&&m(e,a,t[a]);if(s)for(var a of s(t))p.call(t,a)&&m(e,a,t[a]);return e},n=(e,t)=>l(e,u(t));var h=(e,t)=>{var a={};for(var o in e)r.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&s)for(var o of s(e))t.indexOf(o)<0&&p.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=h(o,[\"components\"]);return mdx(MDXLayout,n(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`In my previous posts, I speculated about the issues that were causing\nCPU usage spiking with\ntomcat:\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://searchvoidstar.tumblr.com/post/129241954103/fixing-spiky-cpu-issues-with-tomcat\"}),\"http://searchvoidstar.tumblr.com/post/129241954103/fixing-spiky-cpu-issues-with-tomcat\")),mdx(\"p\",null,`Unfortunately, I was completely wrong in my speculations, but we\nincreased tomcat memory limits so that the entire Lucene search index\ncould fit in memory, which was able to fix the spiky CPU problems.`),mdx(\"p\",null,`Luckily, fixing the memory issues had very good implications for our\nwebapp:`),mdx(\"p\",null,`I have a cron job uses a simple curl command to grab different pages on\nthe website, and then it logs the time taken to a output file. I charted\nthese output times, before and after we increased the memory limits of\ntomcat, and it turned out that the response time of the webapp was\ndramatically improved by this change.`),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"/media/131229569383_0.png\"}))),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/131229569383_0.png\",alt:null}))),mdx(\"p\",null,`Figure 1. The webapp response time was extremely variable before the\nredeploy on Oct 2nd where we increased tomcat's\\xA0memory allocation, which\nthereafter dramatically improved the response time.`),mdx(\"p\",null,`Clearly, the webapp response time was being severely compromised by the\nmemory issues.`),mdx(\"p\",null,`In response to all of these issues, I also added GC logging to the\ntomcat configuration so that I can see if the GC is correlated with\nthese webapp response time. Figure 2 shows how high GC activity is\ncorrelated with longer webapp response times, but note that this figure\nwas made after the other memory allocation problems were fixed, so it is\nstill much better than the problems we had in the past.`),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"/media/131229569383_1.png\"}))),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/131229569383_1.png\",alt:null}))),mdx(\"p\",null,`Figure 2. After increasing the memory, you can see webapp response time\nis much better, except if the GC activity becomes very high, and then\nthis increases the response time.`),mdx(\"p\",null,`Edit: Bonus screenshot, seemingly each friday we get a majoy activity\nburst that triggers GC activity!`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/131229569383_2.png\",alt:null}))),mdx(\"p\",null,`Figure 3. Crazy Java GC activity on a friday night, but the app seems to\nrecover from it`),mdx(\"p\",null,\"Conclusion\"),mdx(\"p\",null,`Increasing the memory allocation to java and tomcat allows the entire\nsystem to perform much better. If you can afford to get more memory to\nallocate to tomcat, then it's probably a good idea.`),mdx(\"p\",null,`Also, tracking your webapp response times will help you see if your\nchanges are having a good effect. I made this a script for graphing log\noutputs here\\xA0`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/cmdcolin/loggraph\"}),\"https://github.com/cmdcolin/loggraph\")),mdx(\"p\",null,\"PS:\"),mdx(\"p\",null,`If your tomcat is running as the tomcat user, then it can be difficult\nto debug the memory problems simply with the \"get heap dump\" from\njvisualvm, because the permissions will be wrong. To fix this, try using\na privileged user to run the jmap command:`),mdx(\"p\",null,`runuser -l tomcat -c \"/usr/java/latest/bin/jmap\n-dump:format=b,file=/db/tomcat/tomcat.dump 25543\"`),mdx(\"p\",null,`::: {#footer}\n`,\"[ October 15th, 2015 1:31pm ]\",`{#timestamp}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Weekend project - graphing tumblr reblogs using cytoscape.js","date":"2015-08-30","slug":"2015-08-30","mdxSource":{"compiledSource":"var u=Object.defineProperty,d=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var r=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,p=Object.prototype.propertyIsEnumerable;var s=(e,t,a)=>t in e?u(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,o=(e,t)=>{for(var a in t||(t={}))n.call(t,a)&&s(e,a,t[a]);if(r)for(var a of r(t))p.call(t,a)&&s(e,a,t[a]);return e},l=(e,t)=>d(e,m(t));var h=(e,t)=>{var a={};for(var i in e)n.call(e,i)&&t.indexOf(i)<0&&(a[i]=e[i]);if(e!=null&&r)for(var i of r(e))t.indexOf(i)<0&&p.call(e,i)&&(a[i]=e[i]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var i=a,{components:e}=i,t=h(i,[\"components\"]);return mdx(MDXLayout,l(o(o({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`In the past, I made an app that used RStudio's Shiny platform to plot\nnetwork graphs with RGraphviz. This worked, and gave some nice results,\nbut when I found out about cytoscape.js, I really wanted to try that\nout.`),mdx(\"p\",null,`The app is designed to plot tumblr reblogs, so it has a tree structure,\nbut simply plotting things as a tree is not very space efficient (as in,\nthe visualization takes up too much space). Therefore, using different\ntypes of layouts can really help.`),mdx(\"p\",null,`In my first app with graphviz\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://colindiesh.shinyapps.io/tumblrgraph\"}),\"https://colindiesh.shinyapps.io/tumblrgraph\"),`, there are several\nbuilt-in graph layouts including \"neato\"\\xA0\"twopi\",\\xA0\"circo\", and \"dot\"`),mdx(\"p\",null,`I made all of these available for users to try in the Shiny app. The\nnames of the layouts don't lend much to their behavior, but they are\nbuilt-in functions in Graphviz. There are both \"tree\" and\n\"force-directed\" style graph views. As I mentioned, the \"tree\" style\nview make a lot of sense for the tumblr reblogs, but the force directed\ngraphs are also a lot more compact, so offering both styles is useful.`),mdx(\"p\",null,mdx(\"img\",o({parentName:\"p\"},{src:\"../../media/128000908903_0.png\",alt:null}))),mdx(\"p\",null,\"Figure 1. My default example graph from graphviz using the twopi layout.\"),mdx(\"p\",null,`I wanted to replicate all the features that I had in the Graphviz app in\nCytoscape.js. Here is the breakdown of the basic components that needed\nreplicating:`),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},'Build the\\xA0\"graph\" representation of reblogs in memory')),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},\"Add user forms and configurability\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},\"Add color for distance from root using a breadth first search\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},\"Draw the graph\"))),mdx(\"p\",null,`As I went along, I was happy to learn that the concepts mapped very\neasily to javascript and cytoscape.js. The implementations are a little\ndifferent, but it worked out very nicely.`),mdx(\"p\",null,mdx(\"img\",o({parentName:\"p\"},{src:\"../../media/128000908903_1.png\",alt:null}))),mdx(\"p\",null,\"Figure 2. Same data plotted in Cytoscape.js with the springy layout.\"),mdx(\"p\",null,`In the new app, we enabled several different layouts similar to the\nGraphviz app too. In cytoscape.js, the layouts that are offered\ninclude\\xA0\"arbor\",\\xA0\"springy\",\\xA0\"cola\",\\xA0\"cose\", and\\xA0\"dagre\". I like \"cola\"\nbecause it really looks like bubbles moving around in a soda. Others are\nworth experimenting with too.`),mdx(\"p\",null,mdx(\"img\",o({parentName:\"p\"},{src:\"../../media/128000908903_2.png\",alt:null}))),mdx(\"p\",null,\"Figure 3. A Cytoscape.js springy layout for a larger tumblr reblog graph\"),mdx(\"p\",null,`The new cytoscape.js app also has a nice animation feature. The old\ngraphviz app offered animation too (using Yihui's animation library for\nR) but the new version can automatically encode HTML5 video on the\nclient side from individual picture frames in the browser using\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://github.com/antimatter15/whammy\"}),'\"Whammy\"'),`! This quite\nimpressive!`),mdx(\"p\",null,\"So to animate the graph, what is done is\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Add nodes/edges and layout the graph (the simulation time is\nconfigurable, because allowing the user to interact with the graph while\nthe simulation is running is useful)`)),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Once layout is complete, the user can save the graph as an\nanimation, which first hides all nodes by adding visibility: hidden to\nthe CSS.`)),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Then the nodes are re-shown one-by-one, preserving the layout, and a\nframe is saved by the renderer at each step (takes a snapshot of the\ncanvas).`))),mdx(\"p\",null,`This strategy for the animation is actually better than the original\ngraphviz version that I had because the layout is only done once, which\nis time saving and it is also more consistent (the layout changes a lot\nif you re run it on different sets of nodes).`),mdx(\"p\",null,\"Check out the app here\\xA0\",mdx(\"a\",o({parentName:\"p\"},{href:\"http://cmdcolin.github.io/tumblrgraph2/\"}),\"http://cmdcolin.github.io/tumblrgraph2/\")),mdx(\"p\",null,\"Future goals:\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},`Test out super large graphs (I have tested up to about 500 reblogs\nbut after this, around 1000 reblogs, it slows down a lot and produces\nbad layouts. Needs fixing)`),mdx(\"li\",{parentName:\"ul\"},`Test out ability to place importance on certain nodes by increasing\nnode size based on it's degree`)),mdx(\"p\",null,\"Check out an example of the HTML5 video here\"),mdx(\"p\",null,`::: {#footer}\n`,\"[ August 30th, 2015 11:49pm ]\",\"{#timestamp} \",\"[cytoscapejs]\",`{.tag}\n`,\"[cytoscape]\",\"{.tag} \",\"[javascript]\",`{.tag}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Creating high-resolution screenshots (of jbrowse) with phantomJS","date":"2015-03-02","slug":"2015-03-02","mdxSource":{"compiledSource":"var m=Object.defineProperty,g=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var i=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var p=(e,t,a)=>t in e?m(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,s=(e,t)=>{for(var a in t||(t={}))n.call(t,a)&&p(e,a,t[a]);if(i)for(var a of i(t))r.call(t,a)&&p(e,a,t[a]);return e},h=(e,t)=>g(e,c(t));var l=(e,t)=>{var a={};for(var o in e)n.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&i)for(var o of i(e))t.indexOf(o)<0&&r.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=l(o,[\"components\"]);return mdx(MDXLayout,h(s(s({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Generating screenshots that are of high quality can be a great benefit\nfor things like science publications. PhantomJS is great for automating\nthis in a reproducible way. While many HTML pages can be rendered in\nhigh resolution without modification, HTML5 canvas apps need special\nconsiderations (see this `,mdx(\"a\",s({parentName:\"p\"},{href:\"http://searchvoidstar.tumblr.com/post/86542847038/high-dpi-rendering-on-html5-canvas-some-problems\"}),`previous post on the\ntopic`),\").\"),mdx(\"p\",null,`One of the key things that we noticed when we developed the high\nresolution canvas rendering (see above link) is that the\n\"devicePixelRatio\" can increase based on the browser's zoom level, and\nit can also take fractional values. This was a difficult problem, to\nmake rendering 100% consistent under all devicePixelRatio values, so we\ncreated a config parameter called highResolutionMode to accept arbitrary\nresolutions.`),mdx(\"p\",null,`Later, we learned about PhantomJS and how it can be used for creating\nscreenshots, it was clear that our design for the settings arbitrary\nscaling factors for the HTML5 canvas was very helpful, as we can set\nhighResolutionMode=4 along with the phantomJS variable\npage.zoomFactor=4, which matches the resolutions and creates high-res\ncanvas screenshots.`),mdx(\"p\",null,`One of the reasons that this is important is that it doesn't look like\nPhantomJS allows \"devicePixelRatio\" to be emulated, so the\npage.zoomFactor doesn't necessarily set the devicePixelRatio to a higher\nnumber, so being able to set the the arbitrary high resolution canvas\nscalings ourselves is a good solution. Reference: issue open Jan 2013\n`,mdx(\"a\",s({parentName:\"p\"},{href:\"https://github.com/ariya/phantomjs/issues/10964\"}),\"https://github.com/ariya/phantomjs/issues/10964\"),` and we are now in Aug\n2015`),mdx(\"p\",null,\"Here are some examples of the rendering process.\"),mdx(\"h2\",null,\"Examples\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},\"Rendering screenshots to PNG\"),mdx(\"p\",{parentName:\"li\"},`phantomjs rasterize.js\n\"`,mdx(\"a\",s({parentName:\"p\"},{href:\"http://localhost/jbrowse/?data=sample_data/json/volvox&tracklist=0\"}),\"http://localhost/jbrowse/?data=sample_data/json/volvox&tracklist=0\"),`\"\noutput.png \"3800px`,\"*\",'1600px\" 2'),mdx(\"p\",{parentName:\"li\"},mdx(\"a\",s({parentName:\"p\"},{href:\"http://i.imgur.com/ABLo6WJ.png\"}),mdx(\"img\",s({parentName:\"a\"},{src:\"http://i.imgur.com/ABLo6WJ.png\",alt:null})))),mdx(\"p\",{parentName:\"li\"},`Figure 1. A basic image output from phantomJS. It uses a\nzoomFactor=2 on the command line to match highResolutionMode=2 in\nthe config file. `,\"`\")),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Rendering screenshots to PDF. In JBrowse, this requires PhantomJS\n2.0. Also see footnote.`),mdx(\"p\",{parentName:\"li\"},`phantomjs rasterize.js\n\"http://localhost/jbrowse/?data=sample_data/json/volvox&tracklist=0\"\noutput.pdf \"16in`,\"*\",'8in\"'),mdx(\"p\",{parentName:\"li\"},mdx(\"a\",s({parentName:\"p\"},{href:\"https://www.dropbox.com/s/7pceo4o406dys8s/output.pdf?dl=0\"}),`Dropbox PDF\n906kb`)),mdx(\"p\",{parentName:\"li\"},`Figure 2. Outputted PDF from phantomJS. This still requires setting\nthe configuration such as highResolutionMode=2 too`),mdx(\"h2\",{parentName:\"li\"},\"Conclusion\"),mdx(\"p\",{parentName:\"li\"},`In the future, we want to consider adding highResolutionMode to be\nspecified via the URL so that it doesn't need to be changed\nmanually, although, setting highResolutionMode=2 by default is not a\nbad strategy.`),mdx(\"p\",{parentName:\"li\"},mdx(\"strong\",{parentName:\"p\"},\"Footnote\")),mdx(\"p\",{parentName:\"li\"},`I used the following patch for rasterize.js to help \"fill out\" the\npage space in PDF renderings (otherwise, it is a square page, not\nsuper pretty for a widescreen app). I guess rasterize.js is really\njust a template and not meant to be super multi-purposed, so this\ncustom modification helps for our case.`))),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{className:\"language-{=html}\"}),`<!-- -->\n`)),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),`    diff --git a/examples/rasterize.js b/examples/rasterize.js\n    index b0e0f67..3b0b6e4 100644\n    --- a/examples/rasterize.js\n    +++ b/examples/rasterize.js\n    _@@ -14,6 +14,7 @@ if (system.args.length < 3 || system.args.length > 5) {\n        page.viewportSize = { width: 600, height: 600 };\n        if (system.args.length > 3 && system.args[2].substr(-4) === \".pdf\") {\n            size = system.args[3].split('_');\n\n    +       page.viewportSize.width *= parseInt(size[0])/parseInt(size[1]);\n            page.paperSize = size.length === 2 ? { width: size[0], height: size[1], margin: '0px' }\n`)),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Reference\")),mdx(\"p\",null,\"gmod.org/wiki/JBrowse_Configuration_Guide\",\"#\",\"Rendering_high_resolution_screenshots_using_PhantomJS\"),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Comparison\")),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/112494997473_0.png\",alt:\"image\"}))),mdx(\"p\",null,\"Big improvement on font rendering\"),mdx(\"p\",null,`::: {#footer}\n`,\"[ March 2nd, 2015 1:52am ]\",\"{#timestamp} \",\"[javascript]\",`{.tag}\n`,\"[phantomjs]\",\"{.tag} \",\"[html5]\",\"{.tag} \",\"[canvas]\",`{.tag}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Post graduation survey","date":"2015-02-01","slug":"2015-02-01","mdxSource":{"compiledSource":"var d=Object.defineProperty,h=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var i=Object.prototype.hasOwnProperty,n=Object.prototype.propertyIsEnumerable;var l=(a,e,s)=>e in a?d(a,e,{enumerable:!0,configurable:!0,writable:!0,value:s}):a[e]=s,r=(a,e)=>{for(var s in e||(e={}))i.call(e,s)&&l(a,s,e[s]);if(o)for(var s of o(e))n.call(e,s)&&l(a,s,e[s]);return a},p=(a,e)=>h(a,u(e));var g=(a,e)=>{var s={};for(var t in a)i.call(a,t)&&e.indexOf(t)<0&&(s[t]=a[t]);if(a!=null&&o)for(var t of o(a))e.indexOf(t)<0&&n.call(a,t)&&(s[t]=a[t]);return s};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(s){var t=s,{components:a}=t,e=g(t,[\"components\"]);return mdx(MDXLayout,p(r(r({},layoutProps),e),{components:a,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I recently received some post-graduation survey results from my class of\n2013 about salaries, job satisfaction, and other things. I thought I'd\ntry to visualize the data using R and ggplot2 as an exercise.`),mdx(\"p\",null,mdx(\"a\",r({parentName:\"p\"},{href:\"http://i.imgur.com/5rVnQHC.png\"}))),mdx(\"p\",null,mdx(\"img\",r({parentName:\"p\"},{src:\"/media/109823235838_0.png\",alt:null}))),mdx(\"p\",null,`Figure 1. The fancy ggplot2 graph of salaries with standard deviation\nbars comparing salaries of BS/MS grads (red) with BS grads (blue).`),mdx(\"p\",null,`As a CS grad, I suppose I'm happy to see that we have the a highest\naverage salary right out of the gate. CS also has a high standard\ndeviation which I thought was interesting. Perhaps CS majors work in a\nmyriad of fields that demand computational skills where other\nengineering majors may be more focused on certain types of fields,\ngiving less deviation.`),mdx(\"p\",null,`In the process of making this graph, I was looking for how to do the\nside-by-side bar charts in ggplot and ended up supplying a \"correction\"\nto a answer on crossvalidated, a stackexchange site. The correction\nentailed how the syntax for using reshape2 vs reshape has changed\nslightly, so hopefully that helps other people searching for the same\nissue.`),mdx(\"p\",null,\"Here is the code for processing\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-R\"}),` library(xlsx)\n library(ggplot2)\n library(reshape2)\n\n salaries=read.xlsx(\"workbook.xlsx\",1)\n df=melt(salaries,measure.vars = c(\"BS.MS.annual.salary\",\n \"BS.annual.salary\"))\n #awkward step to merge standard deviations\n df[df$variable==\"BS.MS.annual.salary\",\"stdev\"]=df[df$variable==\"BS.MS.annual.salary\",\"stdev.1\"]\n ggplot(df, aes(NA., value, fill=variable)) +\n \\xA0\\xA0\\xA0\\xA0 geom_bar(position=\"dodge\",stat=\"identity\") +\n \\xA0\\xA0\\xA0\\xA0 geom_errorbar(aes(ymin=value-stdev, ymax=value+stdev),\n position=position_dodge(width=0.9)) +\n \\xA0\\xA0\\xA0\\xA0 ggtitle(\"Salary for 2013 class of Engineering (2014 survey)\") +\n \\xA0\\xA0\\xA0\\xA0 xlab(\"Major\") +\n \\xA0\\xA0\\xA0\\xA0 ylab(\"Salary w/ stddev\")\n`)),mdx(\"p\",null,\"Table pictured\"),mdx(\"p\",null,mdx(\"img\",r({parentName:\"p\"},{src:\"/media/109823235838_1.png\",alt:null}))),mdx(\"p\",null,`::: {#footer}\n`,\"[ February 1st, 2015 7:05pm ]\",\"{#timestamp} \",\"[rstats]\",\"{.tag} \",\"[ggplot2]\",`{.tag}\n`,\"[college]\",\"{.tag} \",\"[salary]\",`{.tag}\n:::`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"High DPI rendering on HTML5 canvas - some problems and solutions","date":"2014-05-22","slug":"2014-05-22","mdxSource":{"compiledSource":"var c=Object.defineProperty,d=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var h=(e,t,a)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,i=(e,t)=>{for(var a in t||(t={}))r.call(t,a)&&h(e,a,t[a]);if(n)for(var a of n(t))s.call(t,a)&&h(e,a,t[a]);return e},l=(e,t)=>d(e,m(t));var p=(e,t)=>{var a={};for(var o in e)r.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&n)for(var o of n(e))t.indexOf(o)<0&&s.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=p(o,[\"components\"]);return mdx(MDXLayout,l(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`Recently our code has been moving towards the use of HTML5 canvas, as it has\nmany benefits. I felt that if we were going to keep this going towards canvas,\nthe rendering needed to match the quality of regular HTML based tracks.\nUnfortunately, the HTML5 canvas by default looks very \"fuzzy\" on a high\nresolution display (Figure 1).`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/86542847038_0.jpg\",alt:null}))),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Figure 1.\"),` An example of really bad font rendering before and after enabling\nhigh resolution on the HTML5 canvas.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Background \")),mdx(\"p\",null,`Major credit goes to the tutorial at\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://www.html5rocks.com/en/tutorials/canvas/hidpi/\"}),\"http://www.html5rocks.com/en/tutorials/canvas/hidpi/\"),` for pioneering this!\n\\xA0The html5rocks tutorial, written in 2010 it still remains relevant. The major\nthing it introduces is these browser variables called devicePixelRatio and\nbackingStoreRatio that can be used to adjust your canvas drawing. In my\ninterpretation, these two variables have the following purpose:`),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"devicePixelRatio\")),mdx(\"p\",null,`On high DPI displays, screen pixels are actually abstracted away from the\nphysical pixels, so, when you create some HTML element with width 100, height\n100, that element actually takes up a larger number of pixels than 100x100. The\nactual ratio of the pixels that it takes up is 100`,mdx(\"em\",{parentName:\"p\"},`devicePixelRatio x\n100`),`devicePixelRatio. On a high DPI platform like Retina, the devicePixelRatio\nis normally 2 at 100% zoom.`),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"backingStoreRatio\")),mdx(\"p\",null,`The backing store ratio doesn't seem to change as much from platform to\nplatform, but my interpretation of this value is that it essentially gives the\nsize of the memory buffer for the canvas. On my platform, the backingStoreRatio\nis \"1\". I think this value had more historical use, but it may not really be\nused anymore (update aug 7th, 2015 deprecated?\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://stackoverflow.com/questions/24332639/why-context2d-backingstorepixelratio-deprecated\"}),\"http://stackoverflow.com/questions/24332639/why-context2d-backingstorepixelratio-deprecated\"),\")\"),mdx(\"p\",null,`So, what are the consequences of the backing store ratio and the device pixel\nratio? If the backing store ratio equals the device pixel ratio, then no\nscaling takes place, but what we often see is that they are not equal, so the\nimage is up-scaled from the backing store to the screen, and then it is\nstretched and blurred.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"So, how do you enable the high DPI mode?\")),mdx(\"p\",null,`The solution to properly scale your HTML5 canvas content involves a couple of\nsteps that are described in the tutorial here\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://www.html5rocks.com/en/tutorials/canvas/hidpi/\"}),\"http://www.html5rocks.com/en/tutorials/canvas/hidpi/\"),`, but here is the\nessence:`),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Use the canvas.scale method, which tells the canvas's drawing area to become\nbigger, but keeps drawing operations consistent.`)),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`The scaling factor for the canvas.scale method is\ndevicePixelRatio/backingStoreRatio. This will be 2 for instance on a Retina\nscreen at a typical 100% zoom level. The zoom level is relevant which will be\ndiscussed later in this post...`)),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Multiply the width and height attributes of the canvas by\ndevicePixelRatio/backingStoreRatio, so that the\\xA0\"canvas object\" is as big as\nthe scaled size.`)),mdx(\"li\",{parentName:\"ol\"},mdx(\"p\",{parentName:\"li\"},`Here's the tricky part: set the CSS width and height attributes to be the\nUNSCALED size that you want.`))),mdx(\"p\",null,`Note: you can also set CSS width:100% or something and then the canvas will be\nsized appropriately. Normally though, what you will have is something like\n`,mdx(\"inlineCode\",{parentName:\"p\"},'<canvas width=640 height=480 style=\"width:320px;height:240px\">'),` so you can see\nthat the canvas size is larger than what the CSS actually resizes it to be.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Issues: Browser zoom and fractional devicePixelRatios \")),mdx(\"p\",null,`When I first started this project, the benefit of this high resolution\nrendering seemed limited to the fancy people who had Retina or other High DPI\nscreens. However, what I didn't even realize is that the devicePixelRatio value\nchanges depending on browser zoom settings, so even people with a regular\nscreen can have improved rendering of the HTML5 canvas. (Update: we even saw\nthat if you have customized canvas renderings, then you an generate good\nscreenshots of the canvas with PhantomJS too. See `,mdx(\"a\",i({parentName:\"p\"},{href:\"http://searchvoidstar.tumblr.com/post/112494997473/creating-high-resolution-screenshots-of-jbrowse\"}),`my other more recent\narticle`),\")\"),mdx(\"p\",null,`The issue with these zoom settings though is that when you change the zoom\nlevel, especially on chrome and firefox browsers, the devicePixelRatio can end\nup being a fractional value e.g. 2.223277 which can result in sub-pixel\nrendering problems.`),mdx(\"p\",null,`Remember that when we scaled the canvas, it also scales the drawing functions\nto be consistent, so that essentially if you draw a 1 pixel width line on a\nscaled canvas, it might draw a 2.223277 pixel width line. Hence, we can get\nfuzzy rendering issues.`),mdx(\"p\",null,`This issue is very noticeable if you draw many 1px wide lines right next to\neach other. In this case, there will be noticeable gaps between the lines due\nto the imperfect rendering (see green box below).`),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"http://i.imgur.com/THsfjX4.png\"}))),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"http://i.imgur.com/THsfjX4.png\"}))),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"http://i.imgur.com/THsfjX4.png\"}))),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/86542847038_1.png\",alt:null}))),mdx(\"p\",null,mdx(\"em\",{parentName:\"p\"},\"Figure 2.\"),` Examples of 1px wide lines rendered next to each other when there\nis fractional devicePixelRatio.`),mdx(\"p\",null,`Bottom Green box: 1px wide lines drawn 1px apart. (note: bad rendering! tiny\ngaps)\\xA0 Middle Blue box: 1px wide line rendered every 2 px (intentional gaps for\ndemonstration).\\xA0 Top Red box: 1.3px wide lines (a fudge factor is used to make\neliminate the tiny gaps).`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"My solution: The Red Box -- add a fudge factor \")),mdx(\"p\",null,`As you can see in the above figure, my solution to the sub-pixel rendering is\nto add a \"fudge factor\" to the line width to make it render lines that are\n1.3px wide instead of 1px wide when the devicePixelRatio is not a whole number,\nwhich effectively eliminates any gaps due to the sub-pixel rendering problem.`),mdx(\"p\",null,`I heuristically determined the value 1.3px to be sufficient, as testing values\nlike 1.1px, 1.2px and even 1.25px were too small. I'd love to see a proof of\ndetermining this value empirically, or even better, something that isn't this\nbig of a hack, but for now that's what I have.`),mdx(\"p\",null,`You can see the effect of the fudge factor (red box) vs the bad rendering\n(green box) in Figure 2. You can also try this out yourself here\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://jsfiddle.net/4xe4d/\"}),\"http://jsfiddle.net/4xe4d/\"),`, just zoom your browser and then refresh (zooming\nand not refreshing doesn't modify device pixel ratio) to test out different\nvalues of devicePixelRatio.`),mdx(\"p\",null,mdx(\"strong\",{parentName:\"p\"},\"Conclusion\")),mdx(\"p\",null,`In conclusion...we now have high resolution rendering on canvas! The solution\nfor drawing lots of lines right next to each other is sort of suboptimal, so\nthe question continues...what shall be done in this case?`),mdx(\"p\",null,`Maybe someone could implement some sort of library that replaces the\ncanvas.scale method to do better layout and obtain more pixel perfect\nrendering. Alternatively, you could force the scaling factor to always round to\na whole number. This is actually not a bad solution, because the canvas is\nalready being resized, and\\xA0then you can control your rendering better.`),mdx(\"p\",null,\"Thanks for reading\"),mdx(\"p\",null,\"::: {#footer} \",\"[ May 22nd, 2014 7:03pm ]\",\"{#timestamp} \",\"[html5]\",`{.tag}\n`,\"[canvas]\",\"{.tag} \",\"[javascript]\",\"{.tag} :::\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}}]},"__N_SSG":true}