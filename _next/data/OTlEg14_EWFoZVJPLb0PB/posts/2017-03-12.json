{"pageProps":{"post":{"title":"How I learned to hate ORM (especially for data import scripts)","date":"2017-03-12","slug":"2017-03-12","mdxSource":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      p: \"p\",\n      img: \"img\",\n      strong: \"strong\",\n      ul: \"ul\",\n      li: \"li\"\n    }, _provideComponents(), props.components);\n    return _jsxs(_Fragment, {\n      children: [_jsx(_components.p, {\n        children: \"When I was tasked with making a new application for our websites, I was\\ngiven several CSV files with some expectation that these files could\\nbasically be just loaded into a database and jumped into production really\\nquickly. If you are using R and Shiny to make a data visualization dashboard,\\nespecially if it is read only, this can actually be a reality for you: load\\nthose CSVs and just pretend you're a full featured database. I had to actually\\ncreate some read write functionality though. This was sort of experimental for\\nme and I'm not that well versed in databases, but I wanted to share my\\nexperience\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"When I started, I chose grails/groovy/hibernate/GORM as a platform to\\nuse. This quickly turned into pain when I tried to make a data importer\\nusing grails also.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Each CSV row from the source file would have to be turned into many\\ndifferent rows in the database because it represented multiple\\nrelationships, example:\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.img, {\n          src: \"/media/158300473458_0.png\",\n          alt: \"\"\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Initially I made my data importer in grails, and was hardcoding column\\nnames knowing full well this was really inflexible. At the same time I\\nwas also trying to \\\"iterate\\\" on my database schema, and I'd want to\\nre-import my data to test it out, but it was really really slow. I tried\\nmany different approaches to try to speed this up such as cleanUpGorm,\\nStatelessSessions, and other tricks, but it would take 10-20 minutes for\\nimports on a 100KB input file.\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"What I basically realised is that for bulk data import\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.strong, {\n          children: \"1) Using the ORM is really painful for bulk import.\"\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.strong, {\n          children: \"2) If you can pre-process your data so that it is already in the\\nformat the database expects, then you can use the CSV COPY command which\\nis very fast\"\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: _jsx(_components.strong, {\n          children: \"3) If you can then abandon the ORM mentality and even ignore it as\\na convenience factor, then you can embrace my database system itself\"\n        })\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"Overall, after all this work, it just seemed like ORM treats the\\ndatabase as a danger and something to be heavily abstracted over, but I\\nactually found joy in learning how to treat my database as a first class\\ncitizen. Soon I started gaining appreciation of\"\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"using plain SQL queries\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"learning about full text search in postgres with ts_query\"\n        }), \"\\n\", _jsx(_components.li, {\n          children: \"learning about triggers to make a \\\"last updated\\\" field get updated\\nautomatically\"\n        }), \"\\n\"]\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"I am pretty happy this way, and although I miss some things like\\ncriteria queries which are very powerful, I am happy that I can interact\\nwith my database as a friend\"\n      }), \"\\n\", _jsx(_components.p, {\n        children: \"At the very least, due to the fact that I now pre-process the data\\nbefore database loading, I can now import large amounts of data super\\nfast with the CSV COPY command\"\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}}},"__N_SSG":true}