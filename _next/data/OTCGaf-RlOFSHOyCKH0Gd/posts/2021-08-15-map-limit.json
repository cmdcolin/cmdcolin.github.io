{"pageProps":{"post":{"title":"An amazing error message if you put more than 2^24 items in a JS Map object","date":"2021-08-15","slug":"2021-08-15-map-limit","content":"<p>One of the fun things about working with big data is that you can often hit\nweird limits with a system.</p>\n<p>I was personally trying to load every 'common' single nucleotide polymorphism\nfor the human genome into memory (dbSNP), of which there are over 37 million\nentries (there are many more uncommon ones) for the purposes of making a custom\nsearch index for them [1].</p>\n<p>Turns out, you may run into some hard limits. Note that these are all V8-isms\nand may not apply to all browsers or engines (I was using node.js for this)</p>\n<pre><code>const myObject = new Map();\nfor (let i = 0; i &#x3C;= 50_000_000; i++) {\n  myObject.set(i,i);\n  if(i%100000==0) { console.log(i) }\n}\n</code></pre>\n<p>This will crash after adding approx 16.7M elements and say</p>\n<pre><code>0\n100000\n200000\n...\n16400000\n16500000\n16600000\n16700000\n\nUncaught RangeError: Value undefined out of range for undefined options\nproperty undefined\n</code></pre>\n<p>That is a very weird error message. It says “undefined” three times! Much\nbetter than your usual “TypeError: Can’t find property ‘lol’ of undefined”. See\nhttps://bugs.chromium.org/p/v8/issues/detail?id=11852 for a bug filed to help\nimprove the error message perhaps.</p>\n<p>Now, also interestingly enough, if you use an Object instead of a Map</p>\n<pre><code>const myObject = {};\nfor (let i = 0; i &#x3C;= 50_000_000; i++) {\n  myObject['myobj_’+i]=i;\n  if(i%100000==0) { console.log(i) }\n}\n</code></pre>\n<p>Then it will print….</p>\n<pre><code>0\n100000\n200000\n...\n8000000\n8100000\n8200000\n8300000\n</code></pre>\n<p>And it will actually just hang there…frozen…no error message though! And it is\nfailing at ~8.3M elements. Weird right? This is roughly half the amount of\nelements as the 16.7M case</p>\n<p>Turns out there is a precise hard limit for the Map case</p>\n<p>For the Map: 2^24=16,777,216</p>\n<p>For the Object it is around 2^23=8,388,608 HOWEVER, I can actually add more\nthan this, e.g. I can add 8,388,609 or 8,388,610 or even more, but the\noperations start taking forever to run, e.g. 8,388,999 was taking many minutes</p>\n<p>Very weird stuff! If you expected me to dig into this and explain it in deep\ntechnical detail, well, you’d be wrong. I am lazy. However, this helpful post\non stackoverflow by a V8 js engine developer clarifies the Map case!!\nhttps://stackoverflow.com/questions/54452896/maximum-number-of-entries-in-node-js-map</p>\n<pre><code>V8 developer here. I can confirm that 2^24 is the maximum number of entries in\na Map. That’s not a bug, it’s just the implementation-defined limit.\n\nThe limit is determined by:\n\nThe FixedArray backing store of the Map has a maximum size of 1GB (independent\nof the overall heap size limit) On a 64-bit system that means 1GB / 8B = 2^30 /\n2^3 = 2^27 ~= 134M maximum elements per FixedArray A Map needs 3 elements per\nentry (key, value, next bucket link), and has a maximum load factor of 50% (to\navoid the slowdown caused by many bucket collisions), and its capacity must be\na power of 2. 2^27 / (3 * 2) rounded down to the next power of 2 is 2^24, which\nis the limit you observe.  FWIW, there are limits to everything: besides the\nmaximum heap size, there’s a maximum String length, a maximum Array length, a\nmaximum ArrayBuffer length, a maximum BigInt size, a maximum stack size, etc.\nAny one of those limits is potentially debatable, and sometimes it makes sense\nto raise them, but the limits as such will remain. Off the top of my head I\ndon’t know what it would take to bump this particular limit by, say, a factor\nof two – and I also don’t know whether a factor of two would be enough to\nsatisfy your expectations.\n\n</code></pre>\n<p>Great details there. It would also be good to know what the behavior is for the\nObject, which has those 100% CPU stalls after ~8.3M, but not the same error\nmessage...</p>\n<p>Another fun note: if I modify the Object code to use only “integer IDs” the\ncode actually works fine, does not hit any errors, and is “blazingly fast” as\nthe kids call it</p>\n<pre><code>const myObject = {}\nfor (let i = 0; i &#x3C;= 50_000_000; i++) {\n  myObject[i] = i\n  if (i % 100000 == 0) {\n    console.log(i)\n  }\n}\n</code></pre>\n<p>I presume that this code works because it detects that I’m using it like an\narray and it decides to transform how it is working internally and not use a\nhash-map-style data structure, so does not hit a limit. There is a slightly\nhigher limit though, e.g. 1 billion elements gives “Uncaught RangeError:\nInvalid array length”</p>\n<pre><code>const myObject = {}\nfor (let i = 0; i &#x3C;= 1_000_000_000; i++) {\n  myObject[i] = i\n  if (i % 100000 == 0) {\n    console.log(i)\n  }\n}\n</code></pre>\n<p>This has been another episode of ....the twilight zone (other episodes\ncatalogued here) https://github.com/cmdcolin/technical_oddities/</p>\n<p>[1] The final product of this adventure was this, to create a search index for\na large number of elements https://github.com/GMOD/ixixx-js</p>\n"}},"__N_SSG":true}