{"pageProps":{"allPosts":[{"title":"A spooky error when you have a string bigger than 512MB in Chrome","date":"2021-10-30","slug":"2021-10-30-spooky","mdxSource":{"compiledSource":"var h=Object.defineProperty,d=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var p=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,i=Object.prototype.propertyIsEnumerable;var s=(e,t,o)=>t in e?h(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,a=(e,t)=>{for(var o in t||(t={}))r.call(t,o)&&s(e,o,t[o]);if(p)for(var o of p(t))i.call(t,o)&&s(e,o,t[o]);return e},l=(e,t)=>d(e,u(t));var c=(e,t)=>{var o={};for(var n in e)r.call(e,n)&&t.indexOf(n)<0&&(o[n]=e[n]);if(e!=null&&p)for(var n of p(e))t.indexOf(n)<0&&i.call(e,n)&&(o[n]=e[n]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var n=o,{components:e}=n,t=c(n,[\"components\"]);return mdx(MDXLayout,l(a(a({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"Now gather round for a spooky story\"),mdx(\"p\",null,`Late one night... in the haunted office space castle (hindenbugs cackling in\nthe background amongst the dusty technical books) the midnight candles were\nburning bright and we entered data for a user file`),mdx(\"p\",null,`A simple 52MB gzipped datafile that we want to process in the browser. We unzip\nit, decode it, and ...an error`),mdx(\"p\",null,\"ERROR: data not found\"),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"/media/pumpkin-dark.jpg\",alt:null}))),mdx(\"p\",null,'But... our code is so simple (we of course abide by the religion of writing \"simple code\" you know)...what could be happening?'),mdx(\"p\",null,\"The code looks like this\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`const buf = unzip(file)\nconst str = new TextDecoder().decode(buf)\n`)),mdx(\"p\",null,\"We trace it back and run a console.log(str)\"),mdx(\"p\",null,\"It looks empty. We try running console.log(str.length) ... it prints out 0\"),mdx(\"p\",null,\"But if we console.log(buffer.length) we get 546,483,710 bytes...\"),mdx(\"p\",null,\"What could be happening?\"),mdx(\"p\",null,'We see in the TextDecoder documentation that it has a note called \"fatal\". We try'),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`const buf = unzip(file)\nconst str = new TextDecoder('utf8', { fatal: true }).decode(buf)\n`)),mdx(\"p\",null,\"This doesn't change the results though\"),mdx(\"p\",null,`Then it dawns on us while the lightning hits and the thunderclap booms and the\nwind blows through the rattly windows`),mdx(\"p\",null,\"We have hit...the maximum string length in Chrome\"),mdx(\"p\",null,\"BWAHAHAHAHA\"),mdx(\"p\",null,\"The maximum string length!!! Nooooooo\"),mdx(\"p\",null,\"It is 512MB on the dot... 536,870,888 bytes. We test this to be sure\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`const len = 536_870_888\nconst buf = new Uint8Array(len)\nfor (let i = 0; i < len; i++) {\n  buf[i] = 'a'.charCodeAt(0)\n}\nconst str = new TextDecoder().decode(buf)\nconsole.log(str.length)\n`)),mdx(\"p\",null,\"This is correct, outputs 536,870,888\"),mdx(\"p\",null,\"With anything, even one byte more, it fails and outputs 0\"),mdx(\"p\",null,\"happy halloween!!\"),mdx(\"p\",null,\"pumpkin photo source: \",mdx(\"a\",a({parentName:\"p\"},{href:\"http://mountainbikerak.blogspot.com/2010/11/google-chrome-pumpkin.html\"}),\"http://mountainbikerak.blogspot.com/2010/11/google-chrome-pumpkin.html\")),mdx(\"p\",null,\"chrome 95 tested\"),mdx(\"p\",null,\"nodejs 15 - at 512MB+1 bytes it prints an error message \",mdx(\"inlineCode\",{parentName:\"p\"},\"Error: Cannot create a string longer than 0x1fffffe8 characters\"),` for significantly greater than 512MB\ne.g. 600MB it actually prints a different error `,mdx(\"inlineCode\",{parentName:\"p\"},\"TypeError [ERR_ENCODING_INVALID_ENCODED_DATA]: The encoded data was not valid for encoding utf-8\"),\")\"),mdx(\"p\",null,'firefox 93 - goes up to ~1GB but then gives Exception { name: \"NS_ERROR_OUT_OF_MEMORY\", message: \"\", result: 2147942414'),mdx(\"p\",null,\"midori 6 (safari-alike/webkit) - goes up to ~2GB fine! will have to test more\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Jest parallelization, globals, mocks, and squawkless tests","date":"2021-10-05","slug":"2021-10-05-jest","mdxSource":{"compiledSource":"var p=Object.defineProperty,h=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var a=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,l=Object.prototype.propertyIsEnumerable;var i=(e,t,o)=>t in e?p(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,r=(e,t)=>{for(var o in t||(t={}))n.call(t,o)&&i(e,o,t[o]);if(a)for(var o of a(t))l.call(t,o)&&i(e,o,t[o]);return e},c=(e,t)=>h(e,m(t));var u=(e,t)=>{var o={};for(var s in e)n.call(e,s)&&t.indexOf(s)<0&&(o[s]=e[s]);if(e!=null&&a)for(var s of a(e))t.indexOf(s)<0&&l.call(e,s)&&(o[s]=e[s]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var s=o,{components:e}=s,t=u(s,[\"components\"]);return mdx(MDXLayout,c(r(r({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I found that there is a little bit of confusion and misunderstanding around how\nthings like parallelization work in jest, which sometimes leads to additional\nhacking around problems that may not exist or speculating incorrectly about\ntest failure. This is also of course a point of concern when you have code that\nfor some reason or another uses global variables. Here are a short summary of\nthings that may cause confusion.`),mdx(\"h2\",null,\"Tests in a single file are NOT run in parallel\"),mdx(\"p\",null,`Simple example, the global variable r is included in the test condition, but it\nis accurately run in all cases because the tests are not run in parallel.`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`let r = 0\n\nfunction timeout(ms) {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n\ndescribe('tests', () => {\n  it('t1', async () => {\n    await timeout(1000)\n    expect(r).toBe(0)\n    r++\n  })\n  it('t2', async () => {\n    await timeout(1000)\n    expect(r).toBe(1)\n    r++\n  })\n  it('t3', async () => {\n    await timeout(1000)\n    expect(r).toBe(2)\n    r++\n  })\n})\n`)),mdx(\"p\",null,`This test will take 3 seconds, and will accurately count the global variable.\nIf it was in parallel, it may only take 1 second, and would inaccurately count\nthe global variable due to race conditions`),mdx(\"h2\",null,\"Tests in different files ARE run in parallel\"),mdx(\"p\",null,`Let's take another example where we use a global variable, and then two\ndifferent tests use the global variable.`),mdx(\"p\",null,\"file_using_some_globals.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`let myGlobal = 0\n\nexport function doStuff() {\n  myGlobal++\n  return myGlobal\n}\n\nexport function resetMyGlobal() {\n  myGlobal = 0\n}\n\nexport function timeout(ms) {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n`)),mdx(\"p\",null,\"test_global_vars1.test.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`import { doStuff, timeout } from './dostuff'\ntest('file1', async () => {\n  doStuff()\n  await timeout(1000)\n  expect(doStuff()).toEqual(2)\n})\n`)),mdx(\"p\",null,\"test_global_vars2.test.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`import { doStuff, timeout } from './dostuff'\n\ntest('file1', async () => {\n  await timeout(1000)\n  expect(doStuff()).toEqual(1)\n})\n`)),mdx(\"p\",null,`This test completes in less than 2 seconds, and these tests are run in\nparallel. They use different instances of the global state, and therefore have\nno worries with colliding their state.`),mdx(\"h2\",null,\"Does a mock from one test affect another test?\"),mdx(\"p\",null,`While seeking the fabled \"squawk-less\" test, it is often useful to mock console\nso that tests that produce an expected error don't actually print an error\nmessage. However, if not done carefully, you will remove errors across tests`),mdx(\"p\",null,`So, could a mock from one test affect another test? If it's in the same file,\nyes!`),mdx(\"p\",null,\"mock_console.test.js\"),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`test('test1', () => {\n  console.error = jest.fn()\n  console.error('wow')\n  expect(console.error).toHaveBeenCalled()\n})\n\ntest('test2', () => {\n  // this console.error will not appear because test1 mocked away console.error\n  // without restoring it\n  console.error(\"Help I can't see!\")\n})\n`)),mdx(\"p\",null,`To properly mock these, you should restore the console mock at the end of your\nfunction`),mdx(\"pre\",null,mdx(\"code\",r({parentName:\"pre\"},{className:\"language-js\"}),`test('test1', () => {\n  const orig = console.error\n  console.error = jest.fn()\n  console.error('I should not see this!')\n  expect(console.error).toHaveBeenCalled()\n  console.error = orig\n})\n\ntest('test2', () => {\n  const consoleMock = jest.spyOn(console, 'error').mockImplementation()\n  console.error('I should not see this!')\n  consoleMock.mockRestore()\n})\n\ntest('test3', () => {\n  console.error('I should see this error!')\n})\n`)),mdx(\"h2\",null,\"Add-on: Achieve squawkless tests!\"),mdx(\"p\",null,`Your test output should just be a big list of PASS statements, not interleaved\nwith console.error outputs from when you are testing error conditions of your\ncode`),mdx(\"p\",null,`\"Squawkless tests\" is a term I made up, but it means that if you have code\nunder test that prints some errors to the console, then mock the console.error\nfunction, as in the previous section. Don't stand for having a bunch of verbose\nerrors in your CI logs! However, I also suggest only mocking out console.error\nfor tests that are `,mdx(\"strong\",{parentName:\"p\"},\"expected\"),` to have errors, lest you paper over unexpected\nerrors.`),mdx(\"p\",null,mdx(\"img\",r({parentName:\"p\"},{src:\"/media/squawkless_tests.png\",alt:null}))),mdx(\"p\",null,\"Figure: a nice clean test suite without a bunch of crazy console.error outputs\"),mdx(\"h2\",null,\"Conclusion\"),mdx(\"p\",null,`Getting better at testing requires exercise, and understanding the basics of\nyour tools can help! Hopefully this helps you achieve a better understanding\nand write cleaner jest tests.`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Decrease your idle CPU usage when developing typescript apps with this one weird environment variable","date":"2021-09-05","slug":"2021-09-05-typescript","mdxSource":{"compiledSource":"var l=Object.defineProperty,u=Object.defineProperties;var m=Object.getOwnPropertyDescriptors;var o=Object.getOwnPropertySymbols;var n=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var p=(e,t,s)=>t in e?l(e,t,{enumerable:!0,configurable:!0,writable:!0,value:s}):e[t]=s,i=(e,t)=>{for(var s in t||(t={}))n.call(t,s)&&p(e,s,t[s]);if(o)for(var s of o(t))r.call(t,s)&&p(e,s,t[s]);return e},h=(e,t)=>u(e,m(t));var c=(e,t)=>{var s={};for(var a in e)n.call(e,a)&&t.indexOf(a)<0&&(s[a]=e[a]);if(e!=null&&o)for(var a of o(e))t.indexOf(a)<0&&r.call(e,a)&&(s[a]=e[a]);return s};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(s){var a=s,{components:e}=a,t=c(a,[\"components\"]);return mdx(MDXLayout,h(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,\"TL;DR:\"),mdx(\"p\",null,\"add this to your bashrc\"),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`export TSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling\n`)),mdx(\"hr\",null),mdx(\"p\",null,`By default, the typescript watcher configuration e.g. tsc --watch or whatever\nis run internally to a create-react-app typescript app (I see it in the process\nmanager as fork-ts-checker-webpack-plugin cpu usage) can have high idling\n(doing nothing...) CPU usage`),mdx(\"p\",null,`This is because the default configuration polls for file changes (constantly\nasks the computer if there are changes every 250ms or so). There is an\nalternative configuration for this to change it to a file watcher so it\nreceives file system notifications on file change. There is discussion here on\nthis.`),mdx(\"p\",null,`The main summary is that a env variable set to\nTSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling allows this`),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/microsoft/TypeScript/issues/31048\"}),\"https://github.com/microsoft/TypeScript/issues/31048\")),mdx(\"p\",null,`The issue thread shows that it can go from roughly ~7% idle CPU usage to 0.2%.\nThis corresponds with what I see too after applying this! Detailed docs for\ntypescript discuss some of the reasoning behing not making this the default`),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/microsoft/TypeScript-Handbook/blob/master/pages/Configuring%20Watch.md#background\"}),\"https://github.com/microsoft/TypeScript-Handbook/blob/master/pages/Configuring%20Watch.md#background\")),mdx(\"p\",null,`It claims that some OS specific behaviors of file watching could be harmful to\nmaking it the default. For example, that (maybe?) on linux, it may use a large\nnumber of file watchers which can exceed notify handles (this is a setting I\ncommonly have to increase in linux, guide here\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://dev.to/rubiin/ubuntu-increase-inotify-watcher-file-watch-limit-kf4\"}),\"https://dev.to/rubiin/ubuntu-increase-inotify-watcher-file-watch-limit-kf4\"),\")\"),mdx(\"p\",null,\"PS: if you have a package.json of a \",mdx(\"inlineCode\",{parentName:\"p\"},\"create-react-app --template typescript\"),` or\nsomething like this then you can edit the package.json to apply this\nautomatically`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`-\"start\": \"react-scripts start\"\n+\"start\": \"cross-env TSC_WATCHFILE=UseFsEventsWithFallbackDynamicPolling react-scripts start\"\n`)),mdx(\"p\",null,`Phew. I can already feel my laptop running cooler...or at least I can sleep\nmore soundly knowing that my readers adopt this and save some CPU cycles for\nplanet earth...and hopefully don't run into any of the caveats`),mdx(\"p\",null,`Edit: It may be worth it to note, the 'UseFsEvents' part of this uses the\nnode.js fs.watch API and the polling based API is based on fs.watchFile`),mdx(\"p\",null,`Fun table of how the watchers are implemented on different OSs\n[`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://github.com/microsoft/TypeScript/issues/31048#issuecomment-495483957\"}),\"1\"),\"]\"),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),`On Linux systems, this uses inotify(7).\nOn BSD systems, this uses kqueue(2).\nOn macOS, this uses kqueue(2) for files and FSEvents for directories.\nOn SunOS systems (including Solaris and SmartOS), this uses event ports.\nOn Windows systems, this feature depends on ReadDirectoryChangesW.\nOn Aix systems, this feature depends on AHAFS, which must be enabled.\n`)),mdx(\"p\",null,`And in general, these should all respond more or less the same, but there are\nsmall corner cases that are discussed\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://nodejs.org/docs/latest/api/fs.html#fs_availability\"}),\"https://nodejs.org/docs/latest/api/fs.html#fs_availability\")),mdx(\"p\",null,`Disclaimer: it may be worth reading the reasons that typescript does not have\nthis enabled by default before pushing this into your dev environment and all\nyour teammates, but as far as I could tell, it seems ok!`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"An amazing error message if you put more than 2^24 items in a JS Map object","date":"2021-08-15","slug":"2021-08-15-map-limit","mdxSource":{"compiledSource":"var l=Object.defineProperty,d=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var s=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,n=Object.prototype.propertyIsEnumerable;var m=(e,t,a)=>t in e?l(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,o=(e,t)=>{for(var a in t||(t={}))r.call(t,a)&&m(e,a,t[a]);if(s)for(var a of s(t))n.call(t,a)&&m(e,a,t[a]);return e},h=(e,t)=>d(e,u(t));var p=(e,t)=>{var a={};for(var i in e)r.call(e,i)&&t.indexOf(i)<0&&(a[i]=e[i]);if(e!=null&&s)for(var i of s(e))t.indexOf(i)<0&&n.call(e,i)&&(a[i]=e[i]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var i=a,{components:e}=i,t=p(i,[\"components\"]);return mdx(MDXLayout,h(o(o({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`One of the fun things about working with big data is that you can often hit\nweird limits with a system.`),mdx(\"p\",null,`I was personally trying to load every 'common' single nucleotide polymorphism\nfor the human genome into memory (dbSNP), of which there are over 37 million\nentries (there are many more uncommon ones) for the purposes of making a custom\nsearch index for them `,\"[1]\",\".\"),mdx(\"p\",null,`Turns out, you may run into some hard limits. Note that these are all V8-isms\nand may not apply to all browsers or engines (I was using node.js for this)`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`const myObject = new Map();\nfor (let i = 0; i <= 50_000_000; i++) {\n  myObject.set(i,i);\n  if(i%100000==0) { console.log(i) }\n}\n`)),mdx(\"p\",null,\"This will crash after adding approx 16.7M elements and say\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`0\n100000\n200000\n...\n16400000\n16500000\n16600000\n16700000\n\nUncaught RangeError: Value undefined out of range for undefined options\nproperty undefined\n`)),mdx(\"p\",null,`That is a very weird error message. It says \\u201Cundefined\\u201D three times! Much\nbetter than your usual \\u201CTypeError: Can\\u2019t find property \\u2018lol\\u2019 of undefined\\u201D. See\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://bugs.chromium.org/p/v8/issues/detail?id=11852\"}),\"https://bugs.chromium.org/p/v8/issues/detail?id=11852\"),` for a bug filed to help\nimprove the error message perhaps.`),mdx(\"p\",null,\"Now, also interestingly enough, if you use an Object instead of a Map\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-js\"}),`const myObject = {};\nfor (let i = 0; i <= 50_000_000; i++) {\n  myObject['myobj_\\u2019+i]=i;\n  if(i%100000==0) { console.log(i) }\n}\n`)),mdx(\"p\",null,\"Then it will print\\u2026.\"),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`0\n100000\n200000\n...\n8000000\n8100000\n8200000\n8300000\n`)),mdx(\"p\",null,`And it will actually just hang there\\u2026frozen\\u2026no error message though! And it is\nfailing at ~8.3M elements. Weird right? This is roughly half the amount of\nelements as the 16.7M case`),mdx(\"p\",null,\"Turns out there is a precise hard limit for the Map case\"),mdx(\"p\",null,\"For the Map: 2^24=16,777,216\"),mdx(\"p\",null,`For the Object it is around 2^23=8,388,608 HOWEVER, I can actually add more\nthan this, e.g. I can add 8,388,609 or 8,388,610 or even more, but the\noperations start taking forever to run, e.g. 8,388,999 was taking many minutes`),mdx(\"p\",null,`Very weird stuff! If you expected me to dig into this and explain it in deep\ntechnical detail, well, you\\u2019d be wrong. I am lazy. However, this helpful post\non stackoverflow by a V8 js engine developer clarifies the Map case!!\n`,mdx(\"a\",o({parentName:\"p\"},{href:\"https://stackoverflow.com/questions/54452896/maximum-number-of-entries-in-node-js-map\"}),\"https://stackoverflow.com/questions/54452896/maximum-number-of-entries-in-node-js-map\")),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{}),`V8 developer here. I can confirm that 2^24 is the maximum number of entries in\na Map. That\\u2019s not a bug, it\\u2019s just the implementation-defined limit.\n\nThe limit is determined by:\n\nThe FixedArray backing store of the Map has a maximum size of 1GB (independent\nof the overall heap size limit) On a 64-bit system that means 1GB / 8B = 2^30 /\n2^3 = 2^27 ~= 134M maximum elements per FixedArray A Map needs 3 elements per\nentry (key, value, next bucket link), and has a maximum load factor of 50% (to\navoid the slowdown caused by many bucket collisions), and its capacity must be\na power of 2. 2^27 / (3 * 2) rounded down to the next power of 2 is 2^24, which\nis the limit you observe.  FWIW, there are limits to everything: besides the\nmaximum heap size, there\\u2019s a maximum String length, a maximum Array length, a\nmaximum ArrayBuffer length, a maximum BigInt size, a maximum stack size, etc.\nAny one of those limits is potentially debatable, and sometimes it makes sense\nto raise them, but the limits as such will remain. Off the top of my head I\ndon\\u2019t know what it would take to bump this particular limit by, say, a factor\nof two \\u2013 and I also don\\u2019t know whether a factor of two would be enough to\nsatisfy your expectations.\n\n`)),mdx(\"p\",null,`Great details there. It would also be good to know what the behavior is for the\nObject, which has those 100% CPU stalls after ~8.3M, but not the same error\nmessage...`),mdx(\"p\",null,`Another fun note: if I modify the Object code to use only \\u201Cinteger IDs\\u201D the\ncode actually works fine, does not hit any errors, and is \\u201Cblazingly fast\\u201D as\nthe kids call it`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-js\"}),`const myObject = {}\nfor (let i = 0; i <= 50_000_000; i++) {\n  myObject[i] = i\n  if (i % 100000 == 0) {\n    console.log(i)\n  }\n}\n`)),mdx(\"p\",null,`I presume that this code works because it detects that I\\u2019m using it like an\narray and it decides to transform how it is working internally and not use a\nhash-map-style data structure, so does not hit a limit. There is a slightly\nhigher limit though, e.g. 1 billion elements gives \\u201CUncaught RangeError:\nInvalid array length\\u201D`),mdx(\"pre\",null,mdx(\"code\",o({parentName:\"pre\"},{className:\"language-js\"}),`const myObject = {}\nfor (let i = 0; i <= 1_000_000_000; i++) {\n  myObject[i] = i\n  if (i % 100000 == 0) {\n    console.log(i)\n  }\n}\n`)),mdx(\"p\",null,`This has been another episode of ....the twilight zone (other episodes\ncatalogued here) `,mdx(\"a\",o({parentName:\"p\"},{href:\"https://github.com/cmdcolin/technical_oddities/\"}),\"https://github.com/cmdcolin/technical_oddities/\")),mdx(\"p\",null,\"[1]\",` The final product of this adventure was this, to create a search index for\na large number of elements `,mdx(\"a\",o({parentName:\"p\"},{href:\"https://github.com/GMOD/ixixx-js\"}),\"https://github.com/GMOD/ixixx-js\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Do you understand your NPM dependencies?","date":"2021-07-27","slug":"2021-07-27-npm-dependencies","mdxSource":{"compiledSource":"var y=Object.defineProperty,m=Object.defineProperties;var d=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var t=Object.prototype.hasOwnProperty,l=Object.prototype.propertyIsEnumerable;var u=(e,a,o)=>a in e?y(e,a,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[a]=o,r=(e,a)=>{for(var o in a||(a={}))t.call(a,o)&&u(e,o,a[o]);if(n)for(var o of n(a))l.call(a,o)&&u(e,o,a[o]);return e},s=(e,a)=>m(e,d(a));var p=(e,a)=>{var o={};for(var i in e)t.call(e,i)&&a.indexOf(i)<0&&(o[i]=e[i]);if(e!=null&&n)for(var i of n(e))a.indexOf(i)<0&&l.call(e,i)&&(o[i]=e[i]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var i=o,{components:e}=i,a=p(i,[\"components\"]);return mdx(MDXLayout,s(r(r({},layoutProps),a),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`You are writing a library...or your writing an app and you want to publish some\nof the components of it as a library...`),mdx(\"p\",null,\"Here are some questions in the form of comments\"),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you realize that your yarn.lock will be ignored for anyone who installs\nyour libraries?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you realize this means that your perfectly running test suite with your\nyarn.lock could be a failing case for consumers of your app unless you don\\u2019t\nuse semver strings like ^1.0.0 and just hardcode it to 1.0.0?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you realize the default of ^1.0.0 automatically gets minor version bumps\nwhich are often fairly substantial changes, e.g. even breaking possibly?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},`Did you know that larger libraries like @material-ui/core don\\u2019t like to bump\ntheir major version all the time for example so large changes are often made\nto the minor version?`)),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"Did you know if you run \",mdx(\"inlineCode\",{parentName:\"p\"},\"yarn upgrade\"),\", it may update what is in your yarn.lock file but will not update what is in your package.json?\")),mdx(\"li\",{parentName:\"ul\"},mdx(\"p\",{parentName:\"li\"},\"Did you realize that this means that if you depend on the results of running \",mdx(\"inlineCode\",{parentName:\"p\"},\"yarn upgrade\"),\" e.g. it gave you a bugfix, you will be shipping buggy code to consumers of your library?\"))),mdx(\"p\",null,`Just something to be aware of! You can always ride the dragon and accept these\nminor breakages from semver bumps, but it can introduce some issues for your\nconsumers`),mdx(\"p\",null,`Random fun thing: Adding a yarn package can even downgrade some other packages.\nFor example if you have ^6.0.0 in your package.json, you yarn upgrade it up to\n^6.1.0 but then later install another library that requires a hard 6.0.1, yarn\nwill decide to downgrade you to 6.0.1`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Making a HTTPS accessible S3 powered static site with CloudFront+route 53","date":"2020-12-26","slug":"2020-12-26-pt2","mdxSource":{"compiledSource":"var l=Object.defineProperty,m=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var r=Object.prototype.hasOwnProperty,s=Object.prototype.propertyIsEnumerable;var p=(e,t,o)=>t in e?l(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,i=(e,t)=>{for(var o in t||(t={}))r.call(t,o)&&p(e,o,t[o]);if(n)for(var o of n(t))s.call(t,o)&&p(e,o,t[o]);return e},u=(e,t)=>m(e,c(t));var d=(e,t)=>{var o={};for(var a in e)r.call(e,a)&&t.indexOf(a)<0&&(o[a]=e[a]);if(e!=null&&n)for(var a of n(e))t.indexOf(a)<0&&s.call(e,a)&&(o[a]=e[a]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var a=o,{components:e}=a,t=d(a,[\"components\"]);return mdx(MDXLayout,u(i(i({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`This is not a very authoritative post because I stumbled though this but\nI think I got it working now on my website :)`),mdx(\"h2\",null,\"Setup your S3 bucket\"),mdx(\"p\",null,`First setup your S3 bucket, your bucket must be named yourdomain.com\ne.g. named after your domain`),mdx(\"p\",null,`Then if you have a create-react-app setup I add a script in package.json\nthat runs`),mdx(\"pre\",null,mdx(\"code\",i({parentName:\"pre\"},{}),` \"predeploy\": \"npm run build\",\n \"deploy\": \"aws sync --delete build s3://yourdomain.com\"\n`)),mdx(\"p\",null,`Then we can run \"yarn deploy\" and it will automatically upload our\ncreate-react-app website to our S3 static site bucket.`),mdx(\"p\",null,`Then make sure your bucket has public permissions enabled\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\"}),\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\"),`Then\nmake sure your bucket has \"static site hosting\" enabled too`),mdx(\"h2\",null,\"Setup route 53, and make your NS entries in domains.google.com\"),mdx(\"p\",null,\"I bought a domain with domains.google.com\"),mdx(\"p\",null,\"Google then emailed me to validate my ownership\"),mdx(\"p\",null,\"Then I went to aws.amazon.com route 53\\xA0and I created a hosted zone\"),mdx(\"p\",null,`This generated 4 name server entries and I added those to the\ndomains.google.com site`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/638618421776515072_0.png\",alt:null}))),mdx(\"p\",null,`Screenshot shows copying the NS values from route 53 to the name servers\narea of domains.google.com`),mdx(\"h2\",null,\"Setup your Amazon certificate for making SSL work on CloudFront\"),mdx(\"p\",null,`To properly setup However, this does not work so you need to go to\nAmazon Certificates->Provision certificates`),mdx(\"p\",null,\"We request the certificate for\"),mdx(\"p\",null,mdx(\"a\",i({parentName:\"p\"},{href:\"http://www.yourdomain.com\"}),\"www.yourdomain.com\"),`\nyourdomain.com`),mdx(\"p\",null,`Then it generates some codes for a CNAME value for each of those two\nentries, and has a button to autoimport those CNAME values to route53`),mdx(\"p\",null,`Then it will say\\xA0\"Pending validation\"...I waited like an hour and then\nit changed to\\xA0\"Success\".`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/638618421776515072_1.png\",alt:null}))),mdx(\"p\",null,`Screenshot shows the now successful Amazon Certificate. After you get\nthis, you can proceed to finishing your cloudfront`),mdx(\"h2\",null,'Create a CloudFront distribution and add \"Alternative CNAME\" entries for your domain'),mdx(\"p\",null,`Then we can update our CloudFront distribution and add these to\nthe\\xA0\"Alternative CNAME\" input box`),mdx(\"p\",null,`yourdomain.com\n`,mdx(\"a\",i({parentName:\"p\"},{href:\"http://www.yourdomain.com\"}),\"www.yourdomain.com\")),mdx(\"p\",null,`Note also that I first generated my certificate in us-east-2 but the\n\"Import certificate form\" in cloudfront said I had to create it in\nus-east-1`),mdx(\"p\",null,mdx(\"img\",i({parentName:\"p\"},{src:\"/media/638618421776515072_2.png\",alt:null}))),mdx(\"h2\",null,\"Add a default object index.html to the CloudFront setting\"),mdx(\"p\",null,'Make your CloudFront\\xA0\"default object\" is index.html'),mdx(\"p\",null,\"You have to manually type this in :)\"),mdx(\"h2\",null,\"Add the CloudFront distribution to your Route 53\"),mdx(\"p\",null,`Add a Route 53 \"A\" record that points to the CloudFront domain name e.g.\nd897d897d87d98dd.cloudfront.net`),mdx(\"h2\",null,\"Summary of steps needed\"),mdx(\"p\",null,\"The general hindsight 20/20 procedure is\"),mdx(\"ol\",null,mdx(\"li\",{parentName:\"ol\"},`Upload your static content to an S3 bucket called yoursite.com (must\nbe your domain name)`),mdx(\"li\",{parentName:\"ol\"},`Make your S3 bucket have the \"static website\" setting on in the\nproperties menu and add a permissions policy that supports getObject\ne.g.\\xA0`,mdx(\"a\",i({parentName:\"li\"},{href:\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\"}),\"https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html#example-bucket-policies-use-case-2\")),mdx(\"li\",{parentName:\"ol\"},\"Create a CloudFront distribution for your website\"),mdx(\"li\",{parentName:\"ol\"},\"Make the CloudFront default object index.html\"),mdx(\"li\",{parentName:\"ol\"},\"Create your domain with domains.google.com or similar\"),mdx(\"li\",{parentName:\"ol\"},\"Point the google domain's name server to Route 53 NS list from AWS\"),mdx(\"li\",{parentName:\"ol\"},`Add Route 53 A records that point to the CloudFront domain name e.g.\nd897d897d87d98dd.cloudfront.net`),mdx(\"li\",{parentName:\"ol\"},`Create Amazon issued certificate for yourdomain.com, which can\nauto-import a validation CNAME to your Route 53`),mdx(\"li\",{parentName:\"ol\"},`Make your CloudFront domain support your Alternative CNAME's e.g.\nyourdomain.com which requires importing (e.g. selecting from a list\nthat they auto-populate) your Amazon-issued-certificate`)),mdx(\"h2\",null,\"Troubleshooting and notes\"),mdx(\"p\",null,`Problem: Your website gives 403 CloudFlare error\nSolution: You have to get the Alternateive CNAME configuration setup\n(pre-step involves the certificate request and validation)`),mdx(\"p\",null,`Problem: Your website gives an object not found error\nSolution: Set the CloudFront \"default object\" to index.html`),mdx(\"h2\",null,\"Random comment\"),mdx(\"p\",null,`This is one of those processes (creating the cloudfront/route 53) that\nprobably could have done with the aws-sam CLI and it would have possibly\nbeen easier, it is quite fiddly doing all these steps in the web\ninterface`))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Making a serverless website for photo and video upload pt. 2","date":"2020-12-26","slug":"2020-12-26","mdxSource":{"compiledSource":"var c=Object.defineProperty,m=Object.defineProperties;var u=Object.getOwnPropertyDescriptors;var n=Object.getOwnPropertySymbols;var i=Object.prototype.hasOwnProperty,r=Object.prototype.propertyIsEnumerable;var l=(e,t,o)=>t in e?c(e,t,{enumerable:!0,configurable:!0,writable:!0,value:o}):e[t]=o,a=(e,t)=>{for(var o in t||(t={}))i.call(t,o)&&l(e,o,t[o]);if(n)for(var o of n(t))r.call(t,o)&&l(e,o,t[o]);return e},p=(e,t)=>m(e,u(t));var d=(e,t)=>{var o={};for(var s in e)i.call(e,s)&&t.indexOf(s)<0&&(o[s]=e[s]);if(e!=null&&n)for(var s of n(e))t.indexOf(s)<0&&r.call(e,s)&&(o[s]=e[s]);return o};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(o){var s=o,{components:e}=s,t=d(s,[\"components\"]);return mdx(MDXLayout,p(a(a({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`This post follows\non\\xA0`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://cmdcolin.github.io/2020-12-24.html\"}),\"https://cmdcolin.github.io/2020-12-24.html\")),mdx(\"p\",null,`It is possible I zoomed ahead too fast to make this a continuous\ntutorial, but overall I just wanted to post an update`),mdx(\"p\",null,\"In pt. 1 I learned how to use the \",mdx(\"inlineCode\",{parentName:\"p\"},\"aws-sam\"),` CLI tool. This was a great\ninsight for me about automating deployments. I can now simply run `,mdx(\"inlineCode\",{parentName:\"p\"},\"sam deploy\"),\" and it will create new dynamodb tables, lambda functions, etc.\"),mdx(\"p\",null,`After writing pt 1. I converted the existing vue-js app that was in the\naws tutorial and converted it to react. Then I extended the app to allow`),mdx(\"ul\",null,mdx(\"li\",{parentName:\"ul\"},\"Posting comments on photos\"),mdx(\"li\",{parentName:\"ul\"},\"Uploading multiple files\"),mdx(\"li\",{parentName:\"ul\"},`Uploading videos\netc.`)),mdx(\"p\",null,`It will be hard to summarize all the changes since now the app has taken\noff a little bit but it looks like this:`),mdx(\"p\",null,\"Repo structure\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` ./frontend # created using npx create-react-app frontend --template\n typescript\n ./frontend/src/App.tsx # main frontend app code in react\n ./lambdas/\n ./lambdas/postFile # post a file to the lambda, this uploads a row to\n dynamodb and returns a pre-signed URL for uploading (note that if the\n client failed it's upload, that row in the lambda DB might be in a bad\n state...)\n ./lambdas/getFiles # get all files that were ever posted\n ./lambdas/postComment # post a comment on a picture with POST\n request\n ./lambdas/getComments?file=filename.jpg # get comments on a\n picture/video with GET request\n`)),mdx(\"p\",null,`Here is a detailed code for uploading the file. We upload one file at a\ntime, but the client code post to the lambda endpoint individually for\neach file`),mdx(\"p\",null,`This generates a pre-signed URL to allow the client-side JS (not the\nlambda itself) to directly upload to S3, and also posts a row in the S3\nto the filename that will. It is very similar code in\nto\\xA0`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://cmdcolin.github.io/2020-12-24.html\"}),\"https://cmdcolin.github.io/2020-12-24.html\")),mdx(\"p\",null,\"./lambdas/postFile/app.js\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`'use strict'\n\nconst AWS = require('aws-sdk')\nconst multipart = require('./multipart')\nAWS.config.update({ region: process.env.AWS_REGION })\nconst s3 = new AWS.S3()\n\n// Change this value to adjust the signed URL's expiration\nconst URL_EXPIRATION_SECONDS = 300\n\n// Main Lambda entry point\nexports.handler = async event => {\n  return await getUploadURL(event)\n}\n\nconst { AWS_REGION: region } = process.env\n\nconst dynamodb = new AWS.DynamoDB({ apiVersion: '2012-08-10', region })\n\nasync function uploadPic({\n  timestamp,\n  filename,\n  message,\n  user,\n  date,\n  contentType,\n}) {\n  const params = {\n    Item: {\n      timestamp: {\n        N: \\`\\${timestamp}\\`,\n      },\n      filename: {\n        S: filename,\n      },\n      message: {\n        S: message,\n      },\n      user: {\n        S: user,\n      },\n      date: {\n        S: date,\n      },\n      contentType: {\n        S: contentType,\n      },\n    },\n    TableName: 'files',\n  }\n  return dynamodb.putItem(params).promise()\n}\n\nconst getUploadURL = async function (event) {\n  try {\n    const data = multipart.parse(event)\n    const { filename, contentType, user, message, date } = data\n    const timestamp = +Date.now()\n    const Key = \\`\\${timestamp}-\\${filename}\\` // Get signed URL from S3\n\n    const s3Params = {\n      Bucket: process.env.UploadBucket,\n      Key,\n      Expires: URL_EXPIRATION_SECONDS,\n      ContentType: contentType, // This ACL makes the uploaded object publicly readable. You must also uncomment // the extra permission for the Lambda function in the SAM template.\n\n      ACL: 'public-read',\n    }\n\n    const uploadURL = await s3.getSignedUrlPromise('putObject', s3Params)\n\n    await uploadPic({\n      timestamp,\n      filename: Key,\n      message,\n      user,\n      date,\n      contentType,\n    })\n\n    return JSON.stringify({\n      uploadURL,\n      Key,\n    })\n  } catch (e) {\n    const response = {\n      statusCode: 500,\n      body: JSON.stringify({ message: \\`\\${e}\\` }),\n    }\n    return response\n  }\n}\n`)),mdx(\"p\",null,\"./lambdas/getFiles/app.js\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-js\"}),`// eslint-disable-next-line import/no-unresolved\nconst AWS = require('aws-sdk')\n\nconst { AWS_REGION: region } = process.env\n\nconst docClient = new AWS.DynamoDB.DocumentClient()\n\nconst getItems = function () {\n  const params = {\n    TableName: 'files',\n  }\n\n  return docClient.scan(params).promise()\n}\n\nexports.handler = async event => {\n  try {\n    const result = await getItems()\n    return {\n      statusCode: 200,\n      body: JSON.stringify(result),\n    }\n  } catch (e) {\n    return {\n      statusCode: 400,\n      body: JSON.stringify({ message: \\`\\${e}\\` }),\n    }\n  }\n}\n`)),mdx(\"p\",null,\"./frontend/src/App.tsx (excerpt)\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{className:\"language-tsx\"}),`async function myfetch(params: string, opts?: any) {\n  const response = await fetch(params, opts)\n  if (!response.ok) {\n    throw new Error(\\`HTTP \\${response.status}\n \\${response.statusText}\\`)\n  }\n  return response.json()\n}\n\nfunction UploadDialog({\n  open,\n  onClose,\n}: {\n  open: boolean\n  onClose: () => void\n}) {\n  const [images, setImages] = useState<FileList>()\n  const [error, setError] = useState<Error>()\n  const [loading, setLoading] = useState(false)\n  const [total, setTotal] = useState(0)\n  const [completed, setCompleted] = useState(0)\n  const [user, setUser] = useState('')\n  const [message, setMessage] = useState('')\n  const classes = useStyles()\n\n  const handleClose = () => {\n    setError(undefined)\n    setLoading(false)\n    setImages(undefined)\n    setCompleted(0)\n    setTotal(0)\n    setMessage('')\n    onClose()\n  }\n\n  return (\n    <Dialog onClose={handleClose} open={open}>\n      \\xA0 \\xA0 \\xA0<DialogTitle>upload a file (supports picture or video)</DialogTitle>\\xA0\n      \\xA0 \\xA0<DialogContent>\n        \\xA0 \\xA0 \\xA0 \\xA0<label htmlFor=\"user\">name (optional) </label>\n        \\xA0 \\xA0 \\xA0 \\xA0<input\n          type=\"text\"\n          value={user}\n          onChange={event => setUser(event.target.value)}\n          id=\"user\"\n        />\n        \\xA0 \\xA0 \\xA0 \\xA0<br />\\xA0 \\xA0 \\xA0 \\xA0<label htmlFor=\"user\">message (optional) </label>\n        \\xA0 \\xA0 \\xA0 \\xA0\n        <input\n          type=\"text\"\n          value={message}\n          onChange={event => setMessage(event.target.value)}\n          id=\"message\"\n        />\n        \\xA0 \\xA0 \\xA0 \\xA0<br />\n        \\xA0 \\xA0 \\xA0 \\xA0\n        <input\n          multiple\n          type=\"file\"\n          onChange={e => {\n            let files = e.target.files\n            if (files && files.length) {\n              setImages(files)\n            }\n          }}\n        />\n        \\xA0 \\xA0 \\xA0 \\xA0{error ? (\n          <div className={classes.error}>{\\`\\${error}\\`}</div>\n        ) : loading ? (\n          \\`Uploading...\\${completed}/\\${total}\\`\n        ) : completed ? (\n          <h2>Uploaded </h2>\n        ) : null}\\xA0 \\xA0 \\xA0 \\xA0\n        <DialogActions>\n          \\xA0 \\xA0 \\xA0 \\xA0 \\xA0\n          <Button\n            style={{ textTransform: 'none' }}\n            onClick={async () => {\n              try {\n                if (images) {\n                  setLoading(true)\n                  setError(undefined)\n                  setCompleted(0)\n                  setTotal(images.length)\n                  await Promise.all(\n                    Array.from(images).map(async image => {\n                      const data = new FormData()\n                      data.append('message', message)\n                      data.append('user', user)\n                      data.append('date', new Date().toLocaleString())\n                      data.append('filename', image.name)\n                      data.append('contentType', image.type)\n                      const res = await myfetch(API_ENDPOINT + '/postFile', {\n                        method: 'POST',\n                        body: data,\n                      })\n\n                      await myfetch(res.uploadURL, {\n                        method: 'PUT',\n                        body: image,\n                      })\n\n                      setCompleted(completed => completed + 1)\n                    }),\n                  )\n                  setTimeout(() => {\n                    handleClose()\n                  }, 500)\n                }\n              } catch (e) {\n                setError(e)\n              }\n            }}\n            color=\"primary\"\n          >\n            \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0upload \\xA0 \\xA0 \\xA0 \\xA0 \\xA0\n          </Button>\n          \\xA0 \\xA0 \\xA0 \\xA0 \\xA0<Button\n            onClick={handleClose}\n            color=\"primary\"\n            style={{ textTransform: 'none' }}\n          >\n            \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0cancel \\xA0 \\xA0 \\xA0 \\xA0 \\xA0\n          </Button>\\xA0 \\xA0 \\xA0 \\xA0\n        </DialogActions>\n        \\xA0 \\xA0 \\xA0\n      </DialogContent>\\xA0 \\xA0\n    </Dialog>\n  )\n}\n`)),mdx(\"p\",null,\"template.yaml for AWS\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` AWSTemplateFormatVersion: 2010-09-09\n Transform: AWS::Serverless-2016-10-31\n Description: S3 Uploader\n\n Resources:\n \\xA0filesDynamoDBTable:\n \\xA0 \\xA0Type: AWS::DynamoDB::Table\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0AttributeDefinitions:\n \\xA0 \\xA0 \\xA0 \\xA0- AttributeName: \"timestamp\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0AttributeType: \"N\"\n \\xA0 \\xA0 \\xA0KeySchema:\n \\xA0 \\xA0 \\xA0 \\xA0- AttributeName: \"timestamp\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0KeyType: \"HASH\"\n \\xA0 \\xA0 \\xA0ProvisionedThroughput:\n \\xA0 \\xA0 \\xA0 \\xA0ReadCapacityUnits: \"5\"\n \\xA0 \\xA0 \\xA0 \\xA0WriteCapacityUnits: \"5\"\n \\xA0 \\xA0 \\xA0TableName: \"files\"\n\n \\xA0# HTTP API\n \\xA0MyApi:\n \\xA0 \\xA0Type: AWS::Serverless::HttpApi\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0# CORS configuration - this is open for development only and\n should be restricted in prod.\n \\xA0 \\xA0 \\xA0# See\n <https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-property-httpapi-httpapicorsconfiguration.html>\n \\xA0 \\xA0 \\xA0CorsConfiguration:\n \\xA0 \\xA0 \\xA0 \\xA0AllowMethods:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- GET\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- POST\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- DELETE\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- OPTIONS\n \\xA0 \\xA0 \\xA0 \\xA0AllowHeaders:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n \\xA0 \\xA0 \\xA0 \\xA0AllowOrigins:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n\n \\xA0UploadRequestFunction:\n \\xA0 \\xA0Type: AWS::Serverless::Function\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0CodeUri: lambdas/postFile/\n \\xA0 \\xA0 \\xA0Handler: app.handler\n \\xA0 \\xA0 \\xA0Runtime: nodejs12.x\n \\xA0 \\xA0 \\xA0Timeout: 3\n \\xA0 \\xA0 \\xA0MemorySize: 128\n \\xA0 \\xA0 \\xA0Environment:\n \\xA0 \\xA0 \\xA0 \\xA0Variables:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0UploadBucket: !Ref S3UploadBucket\n \\xA0 \\xA0 \\xA0Policies:\n \\xA0 \\xA0 \\xA0 \\xA0- AmazonDynamoDBFullAccess\n \\xA0 \\xA0 \\xA0 \\xA0- S3WritePolicy:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0BucketName: !Ref S3UploadBucket\n \\xA0 \\xA0 \\xA0 \\xA0- Statement:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- Effect: Allow\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Resource: !Sub \"arn:aws:s3:::\\${S3UploadBucket}/\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Action:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- s3:putObjectAcl\n \\xA0 \\xA0 \\xA0Events:\n \\xA0 \\xA0 \\xA0 \\xA0UploadAssetAPI:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Type: HttpApi\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Path: /postFile\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Method: post\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0ApiId: !Ref MyApi\n\n\n \\xA0FileReadFunction:\n \\xA0 \\xA0Type: AWS::Serverless::Function\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0CodeUri: lambdas/getFiles/\n \\xA0 \\xA0 \\xA0Handler: app.handler\n \\xA0 \\xA0 \\xA0Runtime: nodejs12.x\n \\xA0 \\xA0 \\xA0Timeout: 3\n \\xA0 \\xA0 \\xA0MemorySize: 128\n \\xA0 \\xA0 \\xA0Policies:\n \\xA0 \\xA0 \\xA0 \\xA0- AmazonDynamoDBFullAccess\n \\xA0 \\xA0 \\xA0Events:\n \\xA0 \\xA0 \\xA0 \\xA0UploadAssetAPI:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Type: HttpApi\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Path: /getFiles\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0Method: get\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0ApiId: !Ref MyApi\n\n \\xA0## S3 bucket\n \\xA0S3UploadBucket:\n \\xA0 \\xA0Type: AWS::S3::Bucket\n \\xA0 \\xA0Properties:\n \\xA0 \\xA0 \\xA0CorsConfiguration:\n \\xA0 \\xA0 \\xA0 \\xA0CorsRules:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- AllowedHeaders:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0AllowedMethods:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- GET\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- PUT\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- HEAD\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0AllowedOrigins:\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0 \\xA0- \"*\"\n\n\n ## Take a note of the outputs for deploying the workflow templates\n in this sample application\n Outputs:\n \\xA0APIendpoint:\n \\xA0 \\xA0Description: \"HTTP API endpoint URL\"\n \\xA0 \\xA0Value: !Sub\n \"https://\\${MyApi}.execute-api.\\${AWS::Region}.amazonaws.com\"\n \\xA0S3UploadBucketName:\n \\xA0 \\xA0Description: \"S3 bucket for application uploads\"\n \\xA0 \\xA0Value: !Ref \"S3UploadBucket\"\n\n`)),mdx(\"p\",null,`To display all the pictures I use a switch from video or img tag based\non contentType.startsWith('video'). I also use the\\xA0\"figcaption\" HTML tag\nto have a little caption on the pics/videos`),mdx(\"p\",null,\"./frontend/src/App.tsx\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` function Media({\n \\xA0file,\n \\xA0style,\n \\xA0onClick,\n \\xA0children,\n }: {\n \\xA0file: File;\n \\xA0onClick?: Function;\n \\xA0style?: React.CSSProperties;\n \\xA0children?: React.ReactNode;\n }) {\n \\xA0const { filename, contentType } = file;\n \\xA0const src = \\`\\${BUCKET}/\\${filename}\\`;\n \\xA0return (\n \\xA0 \\xA0<figure style={{ display: \"inline-block\" }}>\n \\xA0 \\xA0 \\xA0<picture>\n \\xA0 \\xA0 \\xA0 \\xA0{contentType.startsWith(\"video\") ? (\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0<video style={style} src={src} controls onClick={onClick as\n any} />\n \\xA0 \\xA0 \\xA0 \\xA0) : (\n \\xA0 \\xA0 \\xA0 \\xA0 \\xA0<img style={style} src={src} onClick={onClick as any} />\n \\xA0 \\xA0 \\xA0 \\xA0)}\n \\xA0 \\xA0 \\xA0</picture>\n \\xA0 \\xA0 \\xA0<figcaption>{children}</figcaption>\n \\xA0 \\xA0</figure>\n \\xA0);\n }\n`)),mdx(\"p\",null,`Now the really fun part: if you get an image of a picture frame\nlike\\xA0`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://www.amazon.com/Paintings-Frames-Antique-Shatterproof-Osafs2-Gld-A3/dp/B06XNQ8W9T\"}),\"https://www.amazon.com/Paintings-Frames-Antique-Shatterproof-Osafs2-Gld-A3/dp/B06XNQ8W9T\")),mdx(\"p\",null,\"You can make it a border for any image or video using border-image CSS\"),mdx(\"pre\",null,mdx(\"code\",a({parentName:\"pre\"},{}),` \\xA0 \\xA0 style = {\n \\xA0 \\xA0 \\xA0 \\xA0 border: \"30px solid\",\n \\xA0 \\xA0 \\xA0 \\xA0 borderImage: \\`url(borders/\\${border}) 30 round\\`\n \\xA0 \\xA0 }\n`)),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"/media/638602799897329664_0.png\",alt:null}))),mdx(\"p\",null,\"Summary\"),mdx(\"p\",null,`The template.yaml automatically deploys the lambdas for postFile/getFile\nand the files table in dynamoDB`),mdx(\"p\",null,\"The React app uses postFile for each file in an \",mdx(\"inlineCode\",{parentName:\"p\"},'<input type=\"file\"/>'),`,\nthe code uses React hooks and functional components but is hopefully not\ntoo complex`),mdx(\"p\",null,`I also added commenting on photos. The code is not shown here but you\ncan look in the source code for details`),mdx(\"p\",null,mdx(\"img\",a({parentName:\"p\"},{src:\"/media/638602799897329664_1.png\",alt:null}))),mdx(\"p\",null,`Overall this has been a good experience learning to develop this app and\nlearning to automate the cloud deployment is really good for ensuring\nreliability and fast iteration.`),mdx(\"p\",null,`Also quick note on serverless CLI vs aws-sam. I had tried a serverless\nCLI tutorial from another user but it didn't click with me, while the\naws-sam tutorial from\n`,mdx(\"a\",a({parentName:\"p\"},{href:\"https://searchvoidstar.tumblr.com/post/638408397901987840/making-a-serverless-website-for-photo-upload-pt-1\"}),\"https://searchvoidstar.tumblr.com/post/638408397901987840/making-a-serverless-website-for-photo-upload-pt-1\"),`\\xA0was\na great kick start for me. I am sure the serverless CLI is great too and\nit ensures a bit less vendor lock in, but then is also a little bit\nremoved from the native aws config schemas. Probably fine though`),mdx(\"p\",null,\"Source code\\xA0\",mdx(\"a\",a({parentName:\"p\"},{href:\"https://github.com/cmdcolin/aws_photo_gallery/\"}),\"https://github.com/cmdcolin/aws_photo_gallery/\")))}MDXContent.isMDXComponent=!0;\n","scope":{}}},{"title":"Making a serverless website for photo upload pt. 1","date":"2020-12-24","slug":"2020-12-24","mdxSource":{"compiledSource":"var u=Object.defineProperty,m=Object.defineProperties;var c=Object.getOwnPropertyDescriptors;var i=Object.getOwnPropertySymbols;var p=Object.prototype.hasOwnProperty,n=Object.prototype.propertyIsEnumerable;var l=(e,t,a)=>t in e?u(e,t,{enumerable:!0,configurable:!0,writable:!0,value:a}):e[t]=a,s=(e,t)=>{for(var a in t||(t={}))p.call(t,a)&&l(e,a,t[a]);if(i)for(var a of i(t))n.call(t,a)&&l(e,a,t[a]);return e},r=(e,t)=>m(e,c(t));var d=(e,t)=>{var a={};for(var o in e)p.call(e,o)&&t.indexOf(o)<0&&(a[o]=e[o]);if(e!=null&&i)for(var o of i(e))t.indexOf(o)<0&&n.call(e,o)&&(a[o]=e[o]);return a};const layoutProps={},MDXLayout=\"wrapper\";function MDXContent(a){var o=a,{components:e}=o,t=d(o,[\"components\"]);return mdx(MDXLayout,r(s(s({},layoutProps),t),{components:e,mdxType:\"MDXLayout\"}),mdx(\"p\",null,`I set out to make a serverless website for photo uploads. Our dearly\ndeparted dixie dog needed a place to have photo uploads.`),mdx(\"p\",null,`I didn't want to get charged dollars per month for a running ec2\ninstance, so I wanted something that was lightweight e.g. serverless,\nand easy`),mdx(\"p\",null,\"I decided to follow this tutorial\"),mdx(\"p\",null,mdx(\"a\",s({parentName:\"p\"},{href:\"https://aws.amazon.com/blogs/compute/uploading-to-amazon-s3-directly-from-a-web-or-mobile-application/\"}),\"https://aws.amazon.com/blogs/compute/uploading-to-amazon-s3-directly-from-a-web-or-mobile-application/\")),mdx(\"p\",null,`I really liked the command line deployment (aws-sam) because fiddling\naround with the AWS web based control panel is ridiculously complicated`),mdx(\"p\",null,`For example I also tried following this tutorial which uses the web\nbased UI (`,mdx(\"a\",s({parentName:\"p\"},{href:\"https://www.youtube.com/watch?v=mw_-0iCVpUc\"}),\"https://www.youtube.com/watch?v=mw_-0iCVpUc\"),`) and it just did\nnot work for me....I couldn't stay focused (blame ADHD or just my CLI\nobsession?) and certain things like\\xA0\"Execution role\" that they say to\nmodify are not there in the web UI anymore, so I just gave up (I did try\nthough!)`),mdx(\"p\",null,\"To install aws-sam I used homebrew\"),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),` brew tap aws/tap\n brew install aws-sam-cli\n brew install aws-sam-cli # I had to run the install command twice ref\\xA0https://github.com/aws/aws-sam-cli/issues/2320#issuecomment-721414971\n\n git clone https://github.com/aws-samples/amazon-s3-presigned-urls-aws-sam\n cd amazon-s3-presigned-urls-aws-sam\n sam deploy --guided\n\n # proceeeds with a guided installation, I used all defaults except I\n made\\xA0\"UploadRequestFunction may not have authorization defined, Is\n this okay? [y/N]: y\"\n`)),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_0.png\",alt:null}))),mdx(\"p\",null,\"They then in the tutorial describe trying to use postman to test\"),mdx(\"p\",null,\"I test with \",mdx(\"inlineCode\",{parentName:\"p\"},\"curl\"),\" instead\"),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),`curl 'https://fjgbqj5436.execute-api.us-east-2.amazonaws.com/uploads' {\"uploadURL\":\"https://sam-app-s3uploadbucket-1653634.s3.us-east-2.amazonaws.com/112162.jpg?Content-Type=image%2Fjpeg&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAU6CQBER6YBNCDDMJ%2F20201224%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20201224T174804Z&X-Amz-Expires=300&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDIaCXVzLWVhc3QtMiJGMEQCIH65IvgJsofUpIX46lTaG3Pi5WC85ti1lukM3iICh%2BB%2BAiAJEyynPNPhZN8%2Bg1ylO7wthqud9cBcNIChIp2H%2F%2BR7mCryAQjb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDMzOTQ3MDI2MzQyMSIMLqPo1IYyH7udCGZuKsYBSEF3c50YXkmPeSWcLsEzq%2BFBTpeOIrwZTyCUjbJ7fgJUakhM1YRX40jExstN8eJcMXqw00Xd5lYHvZDbU9ajwWPLRAxcEN5BQ0utqn0NGTLyJhibzJUj8cjgm5RguIEKe9GUtMVWa9mi7C5%2FlFpS0i9jK5BSVf74JyPSLETV5mzMMzy5kHBQMGjw1dR66E3MG8PjIqfgKjhVtZmlaicf5OmeqNI2%2F8T5ye%2FICRsH4d7KNEmj4FELa8buW8U%2Fn97ThfH3P7XmMNOok%2F8FOuEBDj1EHluCT4DfZ1jIXjvrJsVv1WtV4POQDn2Dah%2BWosBn%2BFNTtQtw841ACDarYR1ZVbuwcpTjfBPlGuSOncPsbzOhzDy7wYyumsPKsXoPdxTncMWbx4BQkbU5SeF9hjpfIKRMSOqkJBN7%2BtgHXwuW1rfYMDN2OAlQZpTj7uWMPWojUMbvMzyHvI2pfgcRAlrBdGGYDigyjWl9QXP%2Bdi6WiR7XCSXbWcIAJDZh%2Beb%2BIH1asmMJtpAK6nMP8gWczaYh7PMeYyVOIs2B20xQBy%2Bz7oe%2BYQ2GfdEr2hgqPH3jd%2B7c&X-Amz-Signature=11b8cd524c25ef51193e3b3fc4816760ebcde8bfc74bd52f3f91d8bf409620f5&X-Amz-SignedHeaders=host\",\"Key\":\"112162.jpg\"}%\\xA0\n\n`)),mdx(\"p\",null,`The premise of this is you make a request, and then the response from\nthe API is a pre-signed URL that then allows you to upload directly to\nS3. You can use `,mdx(\"inlineCode\",{parentName:\"p\"},\"curl <url> --upload-file yourfile.jpg\"),`. This\nautomatically does a PUT request to the s3 bucket (yes, this is talking\ndirectly to s3 now, not the lambda! the lambda is just for generating\nthe \"pre-signed URL\" to let you upload). Careful to copy it exactly as\nis`),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),` curl \"https://sam-app-s3uploadbucket-1653634.s3.us-east-2.amazonaws.com/112162.jpg?Content-Type=image%2Fjpeg&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAU6CQBER6YBNCDDMJ%2F20201224%2Fus-east-2%2Fs3%2Faws4_request&X-Amz-Date=20201224T174804Z&X-Amz-Expires=300&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDIaCXVzLWVhc3QtMiJGMEQCIH65IvgJsofUpIX46lTaG3Pi5WC85ti1lukM3iICh%2BB%2BAiAJEyynPNPhZN8%2Bg1ylO7wthqud9cBcNIChIp2H%2F%2BR7mCryAQjb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDMzOTQ3MDI2MzQyMSIMLqPo1IYyH7udCGZuKsYBSEF3c50YXkmPeSWcLsEzq%2BFBTpeOIrwZTyCUjbJ7fgJUakhM1YRX40jExstN8eJcMXqw00Xd5lYHvZDbU9ajwWPLRAxcEN5BQ0utqn0NGTLyJhibzJUj8cjgm5RguIEKe9GUtMVWa9mi7C5%2FlFpS0i9jK5BSVf74JyPSLETV5mzMMzy5kHBQMGjw1dR66E3MG8PjIqfgKjhVtZmlaicf5OmeqNI2%2F8T5ye%2FICRsH4d7KNEmj4FELa8buW8U%2Fn97ThfH3P7XmMNOok%2F8FOuEBDj1EHluCT4DfZ1jIXjvrJsVv1WtV4POQDn2Dah%2BWosBn%2BFNTtQtw841ACDarYR1ZVbuwcpTjfBPlGuSOncPsbzOhzDy7wYyumsPKsXoPdxTncMWbx4BQkbU5SeF9hjpfIKRMSOqkJBN7%2BtgHXwuW1rfYMDN2OAlQZpTj7uWMPWojUMbvMzyHvI2pfgcRAlrBdGGYDigyjWl9QXP%2Bdi6WiR7XCSXbWcIAJDZh%2Beb%2BIH1asmMJtpAK6nMP8gWczaYh7PMeYyVOIs2B20xQBy%2Bz7oe%2BYQ2GfdEr2hgqPH3jd%2B7c&X-Amz-Signature=11b8cd524c25ef51193e3b3fc4816760ebcde8bfc74bd52f3f91d8bf409620f5&X-Amz-SignedHeaders=host\" --upload-file test.jpg\n`)),mdx(\"p\",null,`There is no response, but I can then check the s3 console and see the\nfile upload is successful (all files are renamed)`),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_1.png\",alt:null}))),mdx(\"p\",null,\"Figure shows that the file upload is successful :)\"),mdx(\"p\",null,`Then we can edit the file frontend/index.html from the repo we cloned to\ncontain the lambda with the /uploads/ suffix`),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_2.png\",alt:null}))),mdx(\"p\",null,\"Figure shows editing the index.html with the lambda endpoint\"),mdx(\"p\",null,`Then we manually upload this file to another s3 bucket or test it\nlocally`),mdx(\"pre\",null,mdx(\"code\",s({parentName:\"pre\"},{}),` aws s3 cp index.html s3://mybucket/\n\n\n# then ...visit that in the browser\n`)),mdx(\"p\",null,`At this point the files are getting uploaded but not publically\naccessible. To make them publically accessible we uncomment the\nACL:\\xA0'public-read' in the getSignedURL/app.js folder in the github repo`),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_3.png\",alt:null}))),mdx(\"p\",null,\"Figure showing the public-read uncommented\"),mdx(\"p\",null,mdx(\"img\",s({parentName:\"p\"},{src:\"/media/638408397901987840_4.png\",alt:null}))),mdx(\"p\",null,`Figure showing the lines that need uncommenting in template.yaml in the\nroot of the github repo that allows putObject in s3 with the public-read\nACL`),mdx(\"p\",null,\"Re-run \",mdx(\"inlineCode\",{parentName:\"p\"},\"sam deploy --guided\"),\", same thing as at the start\"),mdx(\"p\",null,\"Now the objects are publicly accessible!\"))}MDXContent.isMDXComponent=!0;\n","scope":{}}}]},"__N_SSG":true}