<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="Astro description"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/x-icon" href="/favicon.ico"><meta name="generator" content="Astro v6.0.0-beta.1"><title>Are your optimizations making any improvement? A simple setup to benchmark two branches</title><style>.container[data-astro-cid-4oxc2zqz]{max-width:800px;margin:0 auto;padding:0 1rem}article[data-astro-cid-lvjzyg5v]{max-width:100%}.post-content[data-astro-cid-lvjzyg5v]{margin:2rem 0;line-height:1.6}
</style>
<link rel="stylesheet" href="/_astro/Layout.Ca4IH_rv.css"></head> <body> <div class="mb-8"> <a href="/">Misc scribbles</a> </div>  <div class="container" data-astro-cid-4oxc2zqz>  <article data-astro-cid-lvjzyg5v> <div data-astro-cid-lvjzyg5v> <h1 data-astro-cid-lvjzyg5v>Are your optimizations making any improvement? A simple setup to benchmark two branches</h1> <h4 data-astro-cid-lvjzyg5v>2025-11-25</h4> </div> <div class="post-content" data-astro-cid-lvjzyg5v> <p><img src="/media/doggo3.png" alt=""></p>
<h2 id="background">Background</h2>
<p>So, you spend all day making “performance improvements” to make your code go
faster</p>
<p>But are you really making a difference? You might ‘feel like it’ but how can you
really tell? Ultimately systematically measuring the difference using a
benchmark is needed [3]. When you are doing optimization work, it is a level of
proof that is nearly as important as proving correctness of your code with
tests.</p>
<p>And, just like tests, you can have different levels of benchmarks</p>
<ul>
<li>unit benchmarks</li>
<li>end-to-end benchmarks</li>
</ul>
<p>Let’s evaluate both of these scenarios. We are going to use javascript for
practical purposes, but you should find a way to take this lesson to any
language or scenario</p>
<h2 id="part-1-creating-unit-benchmarks-using-vitest-bench">Part 1. Creating ‘unit benchmarks’ using <code>vitest bench</code></h2>
<p>If you are already using vitest (it is a very popular test library), you might
be happy to know that there is a subtool called <code>vitest bench</code> that is built-in.</p>
<p>Simply make a file like <code>file.bench.ts</code> and it will be invoked by
<code>vitest bench</code>. API ref <a href="https://vitest.dev/api/#bench">https://vitest.dev/api/#bench</a></p>
<p>But how do you create a <code>vitest bench</code> setup to compare two branches?</p>
<h3 id="a-simple-bash-script-to-help">A simple bash script to help</h3>
<p>We can create a script to run the build process on two branches, defaulting to
current branch and main branch. I used bash, and it assumes that <code>yarn build</code>
outputs to a folder called “dist” [1] [2].</p>
<p>Then it renames the built output to <code>dist_branch1</code> and <code>dist_branch2</code> for each
branch. Then we can add these folders to our .gitignore easily.</p>
<p>It also puts the actual branchname in a .txt file in each folder, allowing the
benchmark itself to report the branchname in the report output.</p>
<pre><code class="language-bash"><a-c>#!/bin/bash</a-c>

<a-f>set</a-f> <a-co>-e</a-co>

<a-pr>CURRENT_BRANCH</a-pr>=<a-eb>$(</a-eb><a-f>git</a-f><a-eb> branch </a-eb><a-co>--show-current</a-co><a-eb>)</a-eb>
<a-pr>BRANCH1</a-pr>=<a-s>"</a-s><a-eb>${</a-eb><a-pr>1</a-pr><a-eb>:-master}</a-eb><a-s>"</a-s>
<a-pr>BRANCH2</a-pr>=<a-s>"</a-s><a-eb>${</a-eb><a-pr>2</a-pr><a-eb>:-</a-eb><a-o>$</a-o><a-pr>CURRENT_BRANCH</a-pr><a-eb>}</a-eb><a-s>"</a-s>

<a-k>if</a-k> ! <a-f>git</a-f> diff <a-co>--quiet</a-co> || ! <a-f>git</a-f> diff <a-co>--cached</a-co> <a-co>--quiet</a-co>; <a-k>then</a-k>
  <a-f>echo</a-f> <a-s>"Error: Uncommitted changes detected. Please commit or stash your changes first."</a-s>
  <a-f>exit</a-f> 1
<a-k>fi</a-k>

<a-f>rm</a-f> <a-co>-rf</a-co> dist_branch1 dist_branch2

<a-f>echo</a-f> <a-s>"Building </a-s><a-o>$</a-o><a-pr>BRANCH1</a-pr><a-s> branch..."</a-s>
<a-f>git</a-f> checkout <a-s>"</a-s><a-o>$</a-o><a-pr>BRANCH1</a-pr><a-s>"</a-s>
<a-f>yarn</a-f>
<a-f>yarn</a-f> build
<a-f>mv</a-f> dist dist_branch1
<a-f>echo</a-f> <a-s>"</a-s><a-o>$</a-o><a-pr>BRANCH1</a-pr><a-s>"</a-s> <a-o>></a-o>dist_branch1/branchname.txt

<a-f>echo</a-f> <a-s>"Building </a-s><a-o>$</a-o><a-pr>BRANCH2</a-pr><a-s> branch..."</a-s>
<a-f>git</a-f> checkout <a-s>"</a-s><a-o>$</a-o><a-pr>BRANCH2</a-pr><a-s>"</a-s>
<a-f>yarn</a-f>
<a-f>yarn</a-f> build
<a-f>mv</a-f> dist dist_branch2
<a-f>echo</a-f> <a-s>"</a-s><a-o>$</a-o><a-pr>BRANCH2</a-pr><a-s>"</a-s> <a-o>></a-o>dist_branch2/branchname.txt

<a-f>echo</a-f> <a-s>"Build complete!"</a-s>
<a-f>echo</a-f> <a-s>"</a-s><a-o>$</a-o><a-pr>BRANCH1</a-pr><a-s> build: dist_branch1/index.js"</a-s>
<a-f>echo</a-f> <a-s>"</a-s><a-o>$</a-o><a-pr>BRANCH2</a-pr><a-s> build: dist_branch2/index.js"</a-s>
</code></pre>
<p>Then in your package.json you can have</p>
<pre><code class="language-json">{
  <a-s>"name"</a-s>: <a-s>"yourpackage"</a-s>,
  <a-s>"version"</a-s>: <a-s>"0.0.0"</a-s>,
  <a-s>"scripts"</a-s>: {
    <a-s>"build"</a-s>: <a-s>"yourbuild that outputs to a folder named dist"</a-s>,
    <a-s>"prebench"</a-s>: <a-s>"./scripts/build-both-branches.sh $BRANCH1 $BRANCH2"</a-s>
    <a-s>"bench"</a-s>: <a-s>"vitest bench"</a-s>
  }
}
</code></pre>
<p>Finally, you can run your benchmark like this:</p>
<pre><code class="language-sh"><a-c># default: compare current branch against main</a-c>
<a-f>yarn</a-f> bench

<a-c># or, set custom env variables to compare two arbitrary branches, branch1 and branch2</a-c>
<a-pr>BRANCH1</a-pr>=branch1 <a-pr>BRANCH2</a-pr>=branch2 <a-f>yarn</a-f> bench
</code></pre>
<p>Then if you have a function in your code that you want to optimize, like this…</p>
<pre><code class="language-typescript"><a-c>// src/index.ts</a-c>
<a-k>export</a-k> <a-k>function</a-k> <a-f>pow</a-f><a-p>(</a-p><a-v>n</a-v>: <a-t>number</a-t><a-p>,</a-p> <a-v>exp</a-v>: <a-t>number</a-t><a-p>)</a-p> <a-p>{</a-p>
  <a-k>return</a-k> <a-t>Math</a-t><a-p>.</a-p><a-f>pow</a-f><a-p>(</a-p><a-v>n</a-v><a-p>,</a-p> <a-v>exp</a-v><a-p>)</a-p>
<a-p>}</a-p>
</code></pre>
<p>Then you can make a new branch with a genius idea that plain multiplying in a
loop would be better</p>
<pre><code class="language-typescript"><a-c>// src/index.ts</a-c>
<a-k>export</a-k> <a-k>function</a-k> <a-f>pow</a-f><a-p>(</a-p><a-v>n</a-v>: <a-t>number</a-t><a-p>,</a-p> <a-v>exp</a-v>: <a-t>number</a-t><a-p>)</a-p> <a-p>{</a-p>
  <a-k>let</a-k> <a-v>total</a-v> <a-o>=</a-o> <a-v>n</a-v>
  <a-k>for</a-k> <a-p>(</a-p><a-k>let</a-k> <a-v>i</a-v> <a-o>=</a-o> <a-n>1</a-n><a-p>;</a-p> <a-v>i</a-v> <a-o>&#x3C;</a-o> <a-v>exp</a-v><a-p>;</a-p> <a-v>i</a-v><a-o>++</a-o><a-p>)</a-p> <a-p>{</a-p>
    <a-v>total</a-v> <a-o>*=</a-o> <a-v>n</a-v>
  <a-p>}</a-p>
<a-p>}</a-p>
</code></pre>
<p>Then you can make a benchmark like this</p>
<pre><code class="language-typescript"><a-k>import</a-k> <a-p>{</a-p> <a-v>readFileSync</a-v> <a-p>}</a-p> <a-k>from</a-k> <a-s>'fs'</a-s>
<a-k>import</a-k> <a-p>{</a-p> <a-v>bench</a-v><a-p>,</a-p> <a-v>describe</a-v> <a-p>}</a-p> <a-k>from</a-k> <a-s>'vitest'</a-s>

<a-k>import</a-k> <a-p>{</a-p> <a-v>pow</a-v> <a-k>as</a-k> <a-v>pow1</a-v> <a-p>}</a-p> <a-k>from</a-k> <a-s>'../dist_branch1/index.js'</a-s>
<a-k>import</a-k> <a-p>{</a-p> <a-v>pow</a-v> <a-k>as</a-k> <a-v>pow2</a-v> <a-p>}</a-p> <a-k>from</a-k> <a-s>'../dist_branch2/index.js'</a-s>

<a-k>const</a-k> <a-v>branch1Name</a-v> <a-o>=</a-o> <a-f>readFileSync</a-f><a-p>(</a-p><a-s>'dist_branch1/branchname.txt'</a-s><a-p>,</a-p> <a-s>'utf8'</a-s><a-p>).</a-p><a-f>trim</a-f><a-p>()</a-p>
<a-k>const</a-k> <a-v>branch2Name</a-v> <a-o>=</a-o> <a-f>readFileSync</a-f><a-p>(</a-p><a-s>'dist_branch2/branchname.txt'</a-s><a-p>,</a-p> <a-s>'utf8'</a-s><a-p>).</a-p><a-f>trim</a-f><a-p>()</a-p>

<a-k>function</a-k> <a-f>benchPow</a-f><a-p>({</a-p>
  n<a-p>,</a-p>
  exp<a-p>,</a-p>
  name<a-p>,</a-p>
  opts<a-p>,</a-p>
<a-p>}</a-p>: <a-p>{</a-p>
  <a-pr>n</a-pr>: <a-t>number</a-t>
  <a-pr>exp</a-pr>: <a-t>number</a-t>
  <a-pr>name</a-pr>: <a-t>string</a-t>
  <a-pr>opts</a-pr>: <a-p>{</a-p>
    <a-pr>iterations</a-pr>?: <a-t>number</a-t>
    <a-pr>warmupIterations</a-pr>?: <a-t>number</a-t>
  <a-p>}</a-p>
<a-p>})</a-p> <a-p>{</a-p>
  <a-f>describe</a-f><a-p>(</a-p><a-v>name</a-v><a-p>,</a-p> <a-p>()</a-p> <a-o>=></a-o> <a-p>{</a-p>
    <a-f>bench</a-f><a-p>(</a-p>
      <a-v>branch1Name</a-v><a-p>,</a-p>
      <a-p>()</a-p> <a-o>=></a-o> <a-p>{</a-p>
        <a-f>pow1</a-f><a-p>(</a-p><a-v>n</a-v><a-p>,</a-p> <a-v>exp</a-v><a-p>)</a-p>
      <a-p>},</a-p>
      <a-v>opts</a-v><a-p>,</a-p>
    <a-p>)</a-p>

    <a-f>bench</a-f><a-p>(</a-p>
      <a-v>branch2Name</a-v><a-p>,</a-p>
      <a-p>()</a-p> <a-o>=></a-o> <a-p>{</a-p>
        <a-f>pow2</a-f><a-p>(</a-p><a-v>n</a-v><a-p>,</a-p> <a-v>exp</a-v><a-p>)</a-p>
      <a-p>},</a-p>
      <a-v>opts</a-v><a-p>,</a-p>
    <a-p>)</a-p>
  <a-p>})</a-p>
<a-p>}</a-p>

<a-f>benchPow</a-f><a-p>({</a-p>
  <a-pr>name</a-pr>: <a-s>'pow'</a-s><a-p>,</a-p>
  <a-pr>n</a-pr>: <a-n>2</a-n><a-p>,</a-p>
  <a-pr>exp</a-pr>: <a-n>10</a-n><a-p>,</a-p>
  <a-pr>opts</a-pr>: <a-p>{</a-p>
    <a-pr>warmupIterations</a-pr>: <a-n>100</a-n><a-p>,</a-p>
    <a-pr>iterations</a-pr>: <a-n>1000</a-n><a-p>,</a-p>
  <a-p>},</a-p>
<a-p>})</a-p>
</code></pre>
<p>That benchmark code is a little more verbose than it needs to be, but it is
quite re-usable across projects</p>
<p>The resulting benchmark report clearly prints the branchname that is the fastest
with some nice statistics</p>
<p>An example of this is here <a href="https://github.com/cmdcolin/simple_benchmark_example">https://github.com/cmdcolin/simple_benchmark_example</a></p>
<h2 id="part-2-creating-end-to-end-benchmarks-using-puppeteer">Part 2. Creating ‘end-to-end’ benchmarks using Puppeteer</h2>
<p>Creating end-to-end benchmarks are really IMO where the rubber hits the road.
You have spent all day making microoptimizations, now it’s time to confirm it
makes an impact.</p>
<p>With puppeteer, you can test against live real builds of your webapp. I
recommend using production builds (not a dev server) and using localhost only
stuff to avoid network variability. Note that I also said ‘simple’ but this
setup is a little more involved generally</p>
<p>Here is an example setup I have used:</p>
<ul>
<li>You create multiple builds of your (web-) app</li>
<li>Store each build in a separate sub-directory in the <code>builds/</code> folder</li>
<li>Create this bash script, which runs hyperfine to measure the total time taken
by the puppeteer script</li>
</ul>
<pre><code class="language-bash"><a-c>#!/bin/bash</a-c>


<a-pr>BASE_PORT</a-pr>=8000

<a-f>rm</a-f> <a-co>-rf</a-co> results
<a-f>mkdir</a-f> <a-co>-p</a-co> results
<a-f>mkdir</a-f> <a-co>-p</a-co> screenshots

<a-c>## kill background scripts after finished</a-c>
<a-c>## https://spin.atomicobject.com/2017/08/24/start-stop-bash-background-process/</a-c>
<a-f>trap</a-f> <a-s>"exit"</a-s> INT TERM
<a-f>trap</a-f> <a-s>"kill 0"</a-s> EXIT

<a-pr>X</a-pr>=<a-o>$</a-o><a-pr>BASE_PORT</a-pr>
<a-k>for</a-k> <a-pr>i</a-pr> <a-k>in</a-k> builds/*; <a-k>do</a-k>
  <a-f>npx</a-f> http-server <a-s>"</a-s><a-o>$</a-o><a-pr>i</a-pr><a-s>"</a-s> <a-co>-p</a-co> <a-s>"</a-s><a-o>$</a-o><a-pr>X</a-pr><a-s>"</a-s> <a-co>-s</a-co> &#x26;
  <a-f>echo</a-f> <a-s>"</a-s><a-o>$</a-o><a-pr>X</a-pr><a-s>"</a-s> <a-s>"</a-s><a-o>$</a-o><a-pr>i</a-pr><a-s>"</a-s>
  <a-pr>X</a-pr>=$((<a-pr>X</a-pr> + 1))
<a-k>done</a-k>



declare -a <a-pr>commands</a-pr>=()
declare -a <a-pr>names</a-pr>=()
<a-pr>X</a-pr>=<a-o>$</a-o><a-pr>BASE_PORT</a-pr>
<a-k>for</a-k> <a-pr>i</a-pr> <a-k>in</a-k> builds/*; <a-k>do</a-k>
  <a-pr>build_name</a-pr>=<a-eb>$(</a-eb><a-f>basename</a-f><a-eb> </a-eb><a-s>"</a-s><a-o>$</a-o><a-pr>i</a-pr><a-s>"</a-s><a-eb>)</a-eb>
  <a-pr>screenshot_path</a-pr>=<a-s>"screenshots/</a-s><a-o>$</a-o><a-pr>build_name</a-pr><a-s>"</a-s>
  <a-pr>commands</a-pr>+=(<a-s>"node scripts/profile_app.ts \"http://localhost:</a-s><a-o>$</a-o><a-pr>X</a-pr><a-s>/\" \"</a-s><a-o>$</a-o><a-pr>screenshot_path</a-pr><a-s>\""</a-s>)
  <a-pr>names</a-pr>+=(<a-s>"-n"</a-s> <a-s>"</a-s><a-o>$</a-o><a-pr>build_name</a-pr><a-s>"</a-s>)
  <a-pr>X</a-pr>=$((<a-pr>X</a-pr> + 1))
<a-k>done</a-k>

<a-f>echo</a-f> <a-s>"Running hyperfine with the following commands:"</a-s>
<a-k>for</a-k> <a-pr>cmd</a-pr> <a-k>in</a-k> <a-s>"</a-s><a-eb>${</a-eb><a-pr>commands</a-pr><a-eb>[@]}</a-eb><a-s>"</a-s>; <a-k>do</a-k>
  <a-f>echo</a-f> <a-s>"  - </a-s><a-o>$</a-o><a-pr>cmd</a-pr><a-s>"</a-s>
<a-k>done</a-k>

<a-f>hyperfine</a-f> <a-co>-i</a-co> <a-co>--export-json</a-co> <a-s>"</a-s><a-o>$</a-o><a-pr>output_json</a-pr><a-s>.json"</a-s> <a-co>--warmup</a-co> 1 <a-co>--runs</a-co> 8 <a-s>"</a-s><a-eb>${</a-eb><a-pr>names</a-pr><a-eb>[@]}</a-eb><a-s>"</a-s> <a-s>"</a-s><a-eb>${</a-eb><a-pr>commands</a-pr><a-eb>[@]}</a-eb><a-s>"</a-s>
<a-f>echo</a-f> <a-co>-e</a-co> <a-s>"\n"</a-s>
</code></pre>
<p>Then you can have your puppeteer script</p>
<pre><code class="language-typescript"><a-c>// profile_app.ts</a-c>
<a-k>import</a-k> <a-v>puppeteer</a-v> <a-k>from</a-k> <a-s>'puppeteer'</a-s>

<a-k>const</a-k> <a-t>WAIT_TIMEOUT</a-t> <a-o>=</a-o> <a-n>30_000</a-n> <a-c>// 30 seconds</a-c>

<a-k>const</a-k> <a-v>url</a-v> <a-o>=</a-o> <a-v>process</a-v><a-p>.</a-p><a-pr>argv</a-pr><a-p>[</a-p><a-n>2</a-n><a-p>]</a-p>
<a-k>const</a-k> <a-v>screenshotPath</a-v> <a-o>=</a-o> <a-v>process</a-v><a-p>.</a-p><a-pr>argv</a-pr><a-p>[</a-p><a-n>3</a-n><a-p>]</a-p>
<a-k>const</a-k> <a-v>browser</a-v> <a-o>=</a-o> <a-k>await</a-k> <a-v>puppeteer</a-v><a-p>.</a-p><a-f>launch</a-f><a-p>({</a-p>
  <a-pr>args</a-pr>: <a-p>[</a-p><a-s>'--no-sandbox'</a-s><a-p>],</a-p> <a-c>// needed on my linux setup, not ideal probably</a-c>
<a-p>})</a-p>
<a-k>const</a-k> <a-v>page</a-v> <a-o>=</a-o> <a-k>await</a-k> <a-v>browser</a-v><a-p>.</a-p><a-f>newPage</a-f><a-p>()</a-p>
<a-k>await</a-k> <a-v>page</a-v><a-p>.</a-p><a-f>goto</a-f><a-p>(</a-p><a-v>url</a-v><a-p>)</a-p>

<a-k>const</a-k> <a-v>params</a-v> <a-o>=</a-o> <a-k>new</a-k> <a-t>URL</a-t><a-p>(</a-p><a-v>url</a-v><a-p>).</a-p><a-pr>searchParams</a-pr>
<a-k>await</a-k> <a-v>page</a-v><a-p>.</a-p><a-f>waitForFunction</a-f><a-p>(</a-p>
  <a-p>()</a-p> <a-o>=></a-o>
    <a-v>document</a-v><a-p>.</a-p><a-f>querySelectorAll</a-f><a-p>(</a-p><a-s>'[data-testid="thing_to_wait_for"]'</a-s><a-p>).</a-p><a-pr>length</a-pr> <a-o>===</a-o> <a-n>1</a-n><a-p>,</a-p>
  <a-p>{</a-p>
    <a-pr>timeout</a-pr>: <a-t>WAIT_TIMEOUT</a-t><a-p>,</a-p>
  <a-p>},</a-p>
<a-p>)</a-p>
<a-c>// create screenshots to confirm visually</a-c>
<a-k>await</a-k> <a-v>page</a-v><a-p>.</a-p><a-f>screenshot</a-f><a-p>({</a-p>
  <a-pr>path</a-pr>: <a-v>screenshotPath</a-v> <a-o>+</a-o> <a-s>'.png'</a-s><a-p>,</a-p>
<a-p>})</a-p>

<a-k>await</a-k> <a-v>browser</a-v><a-p>.</a-p><a-f>close</a-f><a-p>()</a-p>
</code></pre>
<p>This can be invoked directly as a .ts file with <code>node file.ts</code> (since node.js
automatically strips types now)! Optionally you can make puppeteer do user
actions like click around, etc. to test realistic scenarios. It is good to
confirm that you are visually testing the right thing by checking the outputted
screenshots.</p>
<h2 id="sidenote-agentically-optimizing-your-code">Sidenote: Agentically optimizing your code</h2>
<p>Formulating tests and benchmarks like this can allow AI to start automatically
or agentically iterating to find faster solutions.</p>
<p>You can just ask Claude code to “find optimizations”, and see if it comes up
with anything that actually works. It’s not always that good at finding very
impactful optimizations, but with a human in the loop you can guide it towards
some interesting solutions.</p>
<p>You can even tell Claude to look at a screenshot of a flamegraph or analyze
.cpuprofile files that are generated from <code>node --cpu-prof script.ts</code>. See
footnote here
<a href="https://github.com/cmdcolin/simple_benchmark_example?tab=readme-ov-file#analyze-cpuprofile">https://github.com/cmdcolin/simple_benchmark_example?tab=readme-ov-file#analyze-cpuprofile</a></p>
<h2 id="happy-thanksgiving">Happy thanksgiving</h2>
<p><img src="/media/turkey.jpg" alt=""></p>
<p>Wild turkeys can run up to 25 miles per hour</p>
<p>[1] It is probably not absolutely required to use the compiled artifacts to run
the benchmarks. The benchmarks by default for example can just read from the
‘src’ folder. However, using the compiled artifacts is a fairly ‘simple’ way to
avoid collisions otherwise encountered from checking out the code from each
branch.</p>
<p>[2] You might get errors if different sets of e.g. package.json libraries are
used on the branch and main. In that case, you can install the union of the
libraries on your branch temporarily (should only be needed on your “BRANCH2”)</p>
<p>[3] I say this as someone that has superstitiously implemented hundreds of
microptimizations for it to have absolutely zero effect in a end-to-end
benchmark. Conversely, these branch comparison tests have allowed me to ratchet
back-to-back 5-10% improvements to achieve significant gains</p>
<p>[4] This is not strictly related but some good ideas here by some people who are
smarter than me <a href="https://abseil.io/fast/hints.html">https://abseil.io/fast/hints.html</a></p> </div> <div id="giscus"></div> <script>
  const script = document.createElement('script');
  script.src = 'https://giscus.app/client.js';
  script.setAttribute('data-repo', 'cmdcolin/cmdcolin.github.io');
  script.setAttribute('data-repo-id', 'MDEwOlJlcG9zaXRvcnkyNjE0OTY3Nw==');
  script.setAttribute('data-category', 'General');
  script.setAttribute('data-category-id', 'DIC_kwDOAY8DLc4CO-L9');
  script.setAttribute('data-mapping', 'pathname');
  script.setAttribute('data-strict', '0');
  script.setAttribute('data-reactions-enabled', '1');
  script.setAttribute('data-emit-metadata', '0');
  script.setAttribute('data-input-position', 'bottom');
  script.setAttribute('data-theme', 'light');
  script.setAttribute('data-lang', 'en');
  script.setAttribute('crossorigin', 'anonymous');
  script.async = true;
  document.getElementById('giscus').appendChild(script);
</script> </article>  </div>   <footer class="footer-style" data-astro-cid-k2f5zb5c> <a class="footer-link" href="/" data-astro-cid-k2f5zb5c>Home</a> <a class="footer-link" href="/archive" data-astro-cid-k2f5zb5c>Blog archive</a> <a class="footer-link" href="https://github.com/cmdcolin/" data-astro-cid-k2f5zb5c>Github</a> <a class="footer-link" href="/projects" data-astro-cid-k2f5zb5c>Projects</a> <a class="footer-link" href="/about" data-astro-cid-k2f5zb5c>About</a> </footer> </body></html> 