<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>On over-reproducibility</title><meta name="next-head-count" content="3"/><link rel="shortcut icon" href="favicon.ico"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><meta name="description" content="Blogging for the future"/><link rel="preload" href="/_next/static/css/97dc5fe527f5d592.css" as="style"/><link rel="stylesheet" href="/_next/static/css/97dc5fe527f5d592.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-8c0202d61bc61a66.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-731659734a610bcb.js" defer=""></script><script src="/_next/static/chunks/pages/_app-577aa7b9aa74ad1d.js" defer=""></script><script src="/_next/static/chunks/996-d948af01b202b8dc.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-59c11154d2baa387.js" defer=""></script><script src="/_next/static/8xLami-UgrSJKWelXZWlN/_buildManifest.js" defer=""></script><script src="/_next/static/8xLami-UgrSJKWelXZWlN/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div><main><div><div style="margin-bottom:100px"><a href="/">Misc scribbles</a></div><article><div><h1>On over-reproducibility</h1><h4>2016-03-05</h4></div><div><p>Recently, some posts were made by <a href="https://twitter.com/arjunrajlab">https://twitter.com/arjunrajlab</a> about how
perhaps we are aiming at "over-reproducibility". I think this is interesting,
and would generally agree that not everyone needs to achieve total automation of
their whole pipeline, but I think the post does a lot of "blaming your tools"
and disparaging good development practices with regards to version control and
figure generation.</p>
<p>I think that the complaint that version control and automated figures are not
for everyone is probably true, but it is overgeneralizing a different problem.
For example, students are not "trained" to work with Git, and they are not
"trained" to do software engineering. In fact, even computer science students
are not generally "trained" to do any of those things (computer science !=
software engineering). But that doesn't mean that your lab needs to forego using
all those tools. Software development can be incredibly complex and
sophisticated, but it's important to make sure things are "done right"!
High-quality and easy-to-reproduce software is really about process, and
engineering. But that is also why there is no one-true-way for reproducibility.
Maybe Arjun doesn't have a reproducible workflow right now, but what about 5
years down the road, where he suddenly has a great framework for such things?
This happens all the time in software development (for example, how long ago was
it that "push to deploy" did not exist? how often would you just edit your files
live on your site? now that is seen as bad practice!), but that said, processes
for software quality can evolve pretty organically, so even though some best
practices exist, people can grow their own quality environment.</p>
<p>Even if we agree that software development+version control=good, there are still
a lot of complaints about it in the blogpost. For example, the complaint that
git is too hard is pretty silly, and the xkcd comic about calling over graph
theorist doesn't really help. As a software developer at work, I think that
version control simply helps define a disciplined way of working. Version
control makes you analyze your progress, summarize it as a commit message,
format the code properly, make sure it passes tests, and then talk to your
collaborators about accepting it. Dropbox might accomplish some of those things,
but I would really doubt that it is covering that full scope. Arjun seems to
agree with using version control for some of his labs software development, so
again, there is a spectrum of needs being met. Nevertheless, there are some
weird comments about whether commit messages are like a "lab notebook", but
hint: they are not, write documentation for your project or keep a separate
journal or blog or wiki. Commit messages in my opinion should be about one line,
and the changes should be very self explanatory. But another big argument in the
blogpost is whether version control works for something like paper writing, and
I believe that this underscores something else: that paper writing is really a
pretty messy procedure.</p>
<p>I think that perhaps the "google docs" mode of writing is probably pretty ok for
many things, but it still needs a gatekeeper to incorporate the comments from
coauthors and reviewers into the document in an organized way. In my experience
as a "gatekeeper" with writing my senior thesis, I organized my paper using
knitr, and I automated figures being generated by R wherever possible, and then
I would convert the paper to .docx to share with my advisors. Then I would take
their comments on the .docx and incorporate it back into my paper. This could be
seen as burdensome ("why not just use google docs"), but I felt that it was a
good way to incorporate review into a reproducible workflow.</p>
<p>Now, my pipeline precludes your PI from having to learn git to make a pull
request on your paper. That's a good thing... and we still have reproducibility.
But what about the figures themselves? I said I had knitr for reproducible
figures, but what about everyone else? I think figures have high value, and so
people might want to have more reproducibility invested in them. In the blog
post, it was claimed that making "complex" pub-quality figures was difficult
(i.e. the plea for Adobe Illustrator), but look at the annotation functions from
ggplot2, and multifaceted images. I found these annotation functions to be very
easy to pick up. There is also the on-going debate about ggplot2 vs base
graphics on the simplystatistics blog, which covers making publication quality
figures, and last I checked, I think the ggplot2â€²ers were winning. I don't know
how it works in high profile journals like Nature, because it looks like they
just re-do all the figures to make them have some consistent style, but that
doesn't mean your original figure should be irreproducible.</p>
<p>The debate about reproducible figures is pretty tangible too in things like
microscopy images. Simply look at the large amount of discussion from pubpeer
about image fraud and possible duplications. The pubpeer community obviously has
some pretty sophisticated tools for hunting out possibly manipulated microscopy
images. These types of things also lead to investigations, and you can see in
the high-profile retraction case over STAP cells that it looks like the
investigating committee were simply asking how some figures were made, and upon
finding that lab members don't know, a paper was retracted. The RetractionWatch
blog covers these investigations
<a href="http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/">http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/</a></p>
<p>You can't depend on other people to back your figure up, so you need to take
responsibility for making sure your papers and your work are reproducible (and,
there is a spectrum for reproducibility, but I believe that version control is a
great example of highly disciplined work). I also think that just having folders
on some hard drive is not a good way to do things either. There is a saying in
software development that is "if it's not in version control, it doesn't exist".
That's not to say that version control is for everything, big data obviously has
trouble with being stored in git. But that shouldn't block you from creating
reproducible analyses.</p>
<p>Another example from the over-reproducibility blogpost says that if you have
"analysis1" and "analysis2", then version control advocates would tell you to
delete analysis1 and just remember that it is in your history. I think that this
is just a different issue. If you actually care about both analyses, just make
them separate repositories, with basic README.md files explaining each them, and
stop worrying about it. Having one repository containing too many miscellaneous
scripts is actually an anti-pattern. Stop making repositories called
"bioinfo-scripts" that just contain a mish-mash of analysis scripts! Make your
work purpose driven and do tasks. Also, this is an argument against REPL tools:
your R REPL history is not a reproducible script. Make your code into a script
that generates well defined outputs. Windows users: you might not understand
this because the command line on windows is crippled, but you have to make
things run on the command line.</p>
<p>Now I wish I could say that I live by my words, but having been involved in
coauthoring several papers, I will just have to admit that it is really a messy
procedure despite my best intentions as an editor and coauthor. I wish things
would be better!</p>
<p>On over-reproducibility: there is no such thing! There are pretty good arguments
to really automate most of a process, especially if it is done repeatedly, to
remove human errors, because meat-machines genuinely do things wrong all the
time.</p>
<p>And, as my parents would say around the dinner table: "you can always have more,
but you can never have less"...so, you're not going to get to a point of
over-reproducibility. We shouldn't cargo cult it as the only way to do science
but it's not a bad thing to have.</p></div><div style="margin-top:200px"></div></article></div></main></div><footer style="margin-top:100px"><a href="/">Home</a> <a href="/archive">Blog archive</a> <a href="https://github.com/cmdcolin/">Github</a> <a href="https://twitter.com/cmdcolin">Twitter</a> <a href="/projects">Projects</a><a href="/photos">Photos</a> <a href="/rss.xml">RSS</a><a href="/about">About</a></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"On over-reproducibility","date":"2016-03-05","slug":"2016-03-05","html":"\u003cp\u003eRecently, some posts were made by \u003ca href=\"https://twitter.com/arjunrajlab\"\u003ehttps://twitter.com/arjunrajlab\u003c/a\u003e about how\nperhaps we are aiming at \"over-reproducibility\". I think this is interesting,\nand would generally agree that not everyone needs to achieve total automation of\ntheir whole pipeline, but I think the post does a lot of \"blaming your tools\"\nand disparaging good development practices with regards to version control and\nfigure generation.\u003c/p\u003e\n\u003cp\u003eI think that the complaint that version control and automated figures are not\nfor everyone is probably true, but it is overgeneralizing a different problem.\nFor example, students are not \"trained\" to work with Git, and they are not\n\"trained\" to do software engineering. In fact, even computer science students\nare not generally \"trained\" to do any of those things (computer science !=\nsoftware engineering). But that doesn't mean that your lab needs to forego using\nall those tools. Software development can be incredibly complex and\nsophisticated, but it's important to make sure things are \"done right\"!\nHigh-quality and easy-to-reproduce software is really about process, and\nengineering. But that is also why there is no one-true-way for reproducibility.\nMaybe Arjun doesn't have a reproducible workflow right now, but what about 5\nyears down the road, where he suddenly has a great framework for such things?\nThis happens all the time in software development (for example, how long ago was\nit that \"push to deploy\" did not exist? how often would you just edit your files\nlive on your site? now that is seen as bad practice!), but that said, processes\nfor software quality can evolve pretty organically, so even though some best\npractices exist, people can grow their own quality environment.\u003c/p\u003e\n\u003cp\u003eEven if we agree that software development+version control=good, there are still\na lot of complaints about it in the blogpost. For example, the complaint that\ngit is too hard is pretty silly, and the xkcd comic about calling over graph\ntheorist doesn't really help. As a software developer at work, I think that\nversion control simply helps define a disciplined way of working. Version\ncontrol makes you analyze your progress, summarize it as a commit message,\nformat the code properly, make sure it passes tests, and then talk to your\ncollaborators about accepting it. Dropbox might accomplish some of those things,\nbut I would really doubt that it is covering that full scope. Arjun seems to\nagree with using version control for some of his labs software development, so\nagain, there is a spectrum of needs being met. Nevertheless, there are some\nweird comments about whether commit messages are like a \"lab notebook\", but\nhint: they are not, write documentation for your project or keep a separate\njournal or blog or wiki. Commit messages in my opinion should be about one line,\nand the changes should be very self explanatory. But another big argument in the\nblogpost is whether version control works for something like paper writing, and\nI believe that this underscores something else: that paper writing is really a\npretty messy procedure.\u003c/p\u003e\n\u003cp\u003eI think that perhaps the \"google docs\" mode of writing is probably pretty ok for\nmany things, but it still needs a gatekeeper to incorporate the comments from\ncoauthors and reviewers into the document in an organized way. In my experience\nas a \"gatekeeper\" with writing my senior thesis, I organized my paper using\nknitr, and I automated figures being generated by R wherever possible, and then\nI would convert the paper to .docx to share with my advisors. Then I would take\ntheir comments on the .docx and incorporate it back into my paper. This could be\nseen as burdensome (\"why not just use google docs\"), but I felt that it was a\ngood way to incorporate review into a reproducible workflow.\u003c/p\u003e\n\u003cp\u003eNow, my pipeline precludes your PI from having to learn git to make a pull\nrequest on your paper. That's a good thing... and we still have reproducibility.\nBut what about the figures themselves? I said I had knitr for reproducible\nfigures, but what about everyone else? I think figures have high value, and so\npeople might want to have more reproducibility invested in them. In the blog\npost, it was claimed that making \"complex\" pub-quality figures was difficult\n(i.e. the plea for Adobe Illustrator), but look at the annotation functions from\nggplot2, and multifaceted images. I found these annotation functions to be very\neasy to pick up. There is also the on-going debate about ggplot2 vs base\ngraphics on the simplystatistics blog, which covers making publication quality\nfigures, and last I checked, I think the ggplot2â€²ers were winning. I don't know\nhow it works in high profile journals like Nature, because it looks like they\njust re-do all the figures to make them have some consistent style, but that\ndoesn't mean your original figure should be irreproducible.\u003c/p\u003e\n\u003cp\u003eThe debate about reproducible figures is pretty tangible too in things like\nmicroscopy images. Simply look at the large amount of discussion from pubpeer\nabout image fraud and possible duplications. The pubpeer community obviously has\nsome pretty sophisticated tools for hunting out possibly manipulated microscopy\nimages. These types of things also lead to investigations, and you can see in\nthe high-profile retraction case over STAP cells that it looks like the\ninvestigating committee were simply asking how some figures were made, and upon\nfinding that lab members don't know, a paper was retracted. The RetractionWatch\nblog covers these investigations\n\u003ca href=\"http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/\"\u003ehttp://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou can't depend on other people to back your figure up, so you need to take\nresponsibility for making sure your papers and your work are reproducible (and,\nthere is a spectrum for reproducibility, but I believe that version control is a\ngreat example of highly disciplined work). I also think that just having folders\non some hard drive is not a good way to do things either. There is a saying in\nsoftware development that is \"if it's not in version control, it doesn't exist\".\nThat's not to say that version control is for everything, big data obviously has\ntrouble with being stored in git. But that shouldn't block you from creating\nreproducible analyses.\u003c/p\u003e\n\u003cp\u003eAnother example from the over-reproducibility blogpost says that if you have\n\"analysis1\" and \"analysis2\", then version control advocates would tell you to\ndelete analysis1 and just remember that it is in your history. I think that this\nis just a different issue. If you actually care about both analyses, just make\nthem separate repositories, with basic README.md files explaining each them, and\nstop worrying about it. Having one repository containing too many miscellaneous\nscripts is actually an anti-pattern. Stop making repositories called\n\"bioinfo-scripts\" that just contain a mish-mash of analysis scripts! Make your\nwork purpose driven and do tasks. Also, this is an argument against REPL tools:\nyour R REPL history is not a reproducible script. Make your code into a script\nthat generates well defined outputs. Windows users: you might not understand\nthis because the command line on windows is crippled, but you have to make\nthings run on the command line.\u003c/p\u003e\n\u003cp\u003eNow I wish I could say that I live by my words, but having been involved in\ncoauthoring several papers, I will just have to admit that it is really a messy\nprocedure despite my best intentions as an editor and coauthor. I wish things\nwould be better!\u003c/p\u003e\n\u003cp\u003eOn over-reproducibility: there is no such thing! There are pretty good arguments\nto really automate most of a process, especially if it is done repeatedly, to\nremove human errors, because meat-machines genuinely do things wrong all the\ntime.\u003c/p\u003e\n\u003cp\u003eAnd, as my parents would say around the dinner table: \"you can always have more,\nbut you can never have less\"...so, you're not going to get to a point of\nover-reproducibility. We shouldn't cargo cult it as the only way to do science\nbut it's not a bad thing to have.\u003c/p\u003e"}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"2016-03-05"},"buildId":"8xLami-UgrSJKWelXZWlN","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>