<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>On over-reproducibility</title><meta name="next-head-count" content="3"/><link rel="shortcut icon" href="favicon.ico"/><link rel="alternate" type="application/rss+xml" href="/rss.xml"/><meta name="description" content="Blogging for the future"/><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="preload" href="/_next/static/css/50853c3f2e0364c3.css" as="style"/><link rel="stylesheet" href="/_next/static/css/50853c3f2e0364c3.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-93aa87d657ed1852.js" defer=""></script><script src="/_next/static/chunks/framework-c0d8f0fd2eea5ac1.js" defer=""></script><script src="/_next/static/chunks/main-b12cd062888056b2.js" defer=""></script><script src="/_next/static/chunks/pages/_app-d9139de5c3de3b6b.js" defer=""></script><script src="/_next/static/chunks/996-3d2a4318c0ac6f1a.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bslug%5D-b6f09b4db8bfc341.js" defer=""></script><script src="/_next/static/U1O0VFr02s2obkmwwo8ro/_buildManifest.js" defer=""></script><script src="/_next/static/U1O0VFr02s2obkmwwo8ro/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div><main><div><div style="margin-bottom:100px"><a href="/">Misc scribbles</a></div><article><div><h1>On over-reproducibility</h1><h4>2016-03-05</h4></div><div><p>Recently, some posts were made by <a href="https://twitter.com/arjunrajlab">https://twitter.com/arjunrajlab</a> about how
perhaps we are aiming at "over-reproducibility". I think this is interesting,
and would generally agree that not everyone needs to achieve total automation
of their whole pipeline, but I think the post does a lot of "blaming your
tools" and disparaging good development practices with regards to version
control and figure generation.</p>
<p>I think that the complaint that version control and automated figures are not
for everyone is probably true, but it is overgeneralizing a different problem.
For example, students are not "trained" to work with Git, and they are not
"trained" to do software engineering. In fact, even computer science students
are not generally "trained" to do any of those things (computer science !=
software engineering). But that doesn't mean that your lab needs to forego
using all those tools. Software development can be incredibly complex and
sophisticated, but it's important to make sure things are "done right"!
High-quality and easy-to-reproduce software is really about process, and
engineering. But that is also why there is no one-true-way for
reproducibility. Maybe Arjun doesn't have a reproducible workflow right now,
but what about 5 years down the road, where he suddenly has a great framework
for such things? This happens all the time in software development (for
example, how long ago was it that "push to deploy" did not exist? how often
would you just edit your files live on your site? now that is seen as bad
practice!), but that said, processes for software quality can evolve pretty
organically, so even though some best practices exist, people can grow their
own quality environment.</p>
<p>Even if we agree that software development+version control=good, there are
still a lot of complaints about it in the blogpost. For example, the complaint
that git is too hard is pretty silly, and the xkcd comic about calling over
graph theorist doesn't really help. As a software developer at work, I think
that version control simply helps define a disciplined way of working. Version
control makes you analyze your progress, summarize it as a commit message,
format the code properly, make sure it passes tests, and then talk to your
collaborators about accepting it. Dropbox might accomplish some of those
things, but I would really doubt that it is covering that full scope. Arjun
seems to agree with using version control for some of his labs software
development, so again, there is a spectrum of needs being met. Nevertheless,
there are some weird comments about whether commit messages are like a "lab
notebook", but hint: they are not, write documentation for your project or keep
a separate journal or blog or wiki. Commit messages in my opinion should be
about one line, and the changes should be very self explanatory. But another
big argument in the blogpost is whether version control works for something
like paper writing, and I believe that this underscores something else: that
paper writing is really a pretty messy procedure.</p>
<p>I think that perhaps the "google docs" mode of writing is probably pretty ok
for many things, but it still needs a gatekeeper to incorporate the comments
from coauthors and reviewers into the document in an organized way. In my
experience as a "gatekeeper" with writing my senior thesis, I organized my
paper using knitr, and I automated figures being generated by R wherever
possible, and then I would convert the paper to .docx to share with my
advisors. Then I would take their comments on the .docx and incorporate it back
into my paper. This could be seen as burdensome ("why not just use google
docs"), but I felt that it was a good way to incorporate review into a
reproducible workflow.</p>
<p>Now, my pipeline precludes your PI from having to learn git to make a pull
request on your paper. That's a good thing... and we still have
reproducibility. But what about the figures themselves? I said I had knitr for
reproducible figures, but what about everyone else? I think figures have high
value, and so people might want to have more reproducibility invested in them.
In the blog post, it was claimed that making "complex" pub-quality figures was
difficult (i.e. the plea for Adobe Illustrator), but look at the annotation
functions from ggplot2, and multifaceted images. I found these annotation
functions to be very easy to pick up. There is also the on-going debate about
ggplot2 vs base graphics on the simplystatistics blog, which covers making
publication quality figures, and last I checked, I think the ggplot2â€²ers were
winning. I don't know how it works in high profile journals like Nature,
because it looks like they just re-do all the figures to make them have some
consistent style, but that doesn't mean your original figure should be
irreproducible.</p>
<p>The debate about reproducible figures is pretty tangible too in things like
microscopy images. Simply look at the large amount of discussion from pubpeer
about image fraud and possible duplications. The pubpeer community obviously
has some pretty sophisticated tools for hunting out possibly manipulated
microscopy images. These types of things also lead to investigations, and you
can see in the high-profile retraction case over STAP cells that it looks like
the investigating committee were simply asking how some figures were made, and
upon finding that lab members don't know, a paper was retracted. The
RetractionWatch blog covers these
investigations <a href="http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/">http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/</a></p>
<p>You can't depend on other people to back your figure up, so you need to take
responsibility for making sure your papers and your work are reproducible (and,
there is a spectrum for reproducibility, but I believe that version control is
a great example of highly disciplined work). I also think that just having
folders on some hard drive is not a good way to do things either. There is a
saying in software development that is "if it's not in version control, it
doesn't exist". That's not to say that version control is for everything, big
data obviously has trouble with being stored in git. But that shouldn't block
you from creating reproducible analyses.</p>
<p>Another example from the over-reproducibility blogpost says that if you have
"analysis1" and "analysis2", then version control advocates would tell you to
delete analysis1 and just remember that it is in your history. I think that
this is just a different issue. If you actually care about both analyses, just
make them separate repositories, with basic README.md files explaining each
them, and stop worrying about it. Having one repository containing too many
miscellaneous scripts is actually an anti-pattern. Stop making repositories
called "bioinfo-scripts" that just contain a mish-mash of analysis scripts!
Make your work purpose driven and do tasks. Also, this is an argument against
REPL tools: your R REPL history is not a reproducible script. Make your code
into a script that generates well defined outputs. Windows users: you might not
understand this because the command line on windows is crippled, but you have
to make things run on the command line.</p>
<p>Now I wish I could say that I live by my words, but having been involved in
coauthoring several papers, I will just have to admit that it is really a messy
procedure despite my best intentions as an editor and coauthor. I wish things
would be better!</p>
<p>On over-reproducibility: there is no such thing! There are pretty good
arguments to really automate most of a process, especially if it is done
repeatedly, to remove human errors, because meat-machines genuinely do things
wrong all the time.</p>
<p>And, as my parents would say around the dinner table: "you can always have
more, but you can never have less"...so, you're not going to get to a point of
over-reproducibility. We shouldn't cargo cult it as the only way to do science
but it's not a bad thing to have.</p></div><div style="margin-top:200px"></div></article></div></main></div><footer style="margin-top:100px"><a href="/">Home</a> <a href="/archive">Blog archive</a> <a href="https://github.com/cmdcolin/">Github</a> <a href="https://twitter.com/cmdcolin">Twitter</a> <a href="/projects">Projects</a> <a href="/photos">Photos</a> <a href="/rss.xml">RSS</a><a href="/about">About</a> </footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"On over-reproducibility","date":"2016-03-05","slug":"2016-03-05","html":"\u003cp\u003eRecently, some posts were made by \u003ca href=\"https://twitter.com/arjunrajlab\"\u003ehttps://twitter.com/arjunrajlab\u003c/a\u003e about how\nperhaps we are aiming at \"over-reproducibility\". I think this is interesting,\nand would generally agree that not everyone needs to achieve total automation\nof their whole pipeline, but I think the post does a lot of \"blaming your\ntools\" and disparaging good development practices with regards to version\ncontrol and figure generation.\u003c/p\u003e\n\u003cp\u003eI think that the complaint that version control and automated figures are not\nfor everyone is probably true, but it is overgeneralizing a different problem.\nFor example, students are not \"trained\" to work with Git, and they are not\n\"trained\" to do software engineering. In fact, even computer science students\nare not generally \"trained\" to do any of those things (computer science !=\nsoftware engineering). But that doesn't mean that your lab needs to forego\nusing all those tools. Software development can be incredibly complex and\nsophisticated, but it's important to make sure things are \"done right\"!\nHigh-quality and easy-to-reproduce software is really about process, and\nengineering. But that is also why there is no one-true-way for\nreproducibility. Maybe Arjun doesn't have a reproducible workflow right now,\nbut what about 5 years down the road, where he suddenly has a great framework\nfor such things? This happens all the time in software development (for\nexample, how long ago was it that \"push to deploy\" did not exist? how often\nwould you just edit your files live on your site? now that is seen as bad\npractice!), but that said, processes for software quality can evolve pretty\norganically, so even though some best practices exist, people can grow their\nown quality environment.\u003c/p\u003e\n\u003cp\u003eEven if we agree that software development+version control=good, there are\nstill a lot of complaints about it in the blogpost. For example, the complaint\nthat git is too hard is pretty silly, and the xkcd comic about calling over\ngraph theorist doesn't really help. As a software developer at work, I think\nthat version control simply helps define a disciplined way of working. Version\ncontrol makes you analyze your progress, summarize it as a commit message,\nformat the code properly, make sure it passes tests, and then talk to your\ncollaborators about accepting it. Dropbox might accomplish some of those\nthings, but I would really doubt that it is covering that full scope. Arjun\nseems to agree with using version control for some of his labs software\ndevelopment, so again, there is a spectrum of needs being met. Nevertheless,\nthere are some weird comments about whether commit messages are like a \"lab\nnotebook\", but hint: they are not, write documentation for your project or keep\na separate journal or blog or wiki. Commit messages in my opinion should be\nabout one line, and the changes should be very self explanatory. But another\nbig argument in the blogpost is whether version control works for something\nlike paper writing, and I believe that this underscores something else: that\npaper writing is really a pretty messy procedure.\u003c/p\u003e\n\u003cp\u003eI think that perhaps the \"google docs\" mode of writing is probably pretty ok\nfor many things, but it still needs a gatekeeper to incorporate the comments\nfrom coauthors and reviewers into the document in an organized way. In my\nexperience as a \"gatekeeper\" with writing my senior thesis, I organized my\npaper using knitr, and I automated figures being generated by R wherever\npossible, and then I would convert the paper to .docx to share with my\nadvisors. Then I would take their comments on the .docx and incorporate it back\ninto my paper. This could be seen as burdensome (\"why not just use google\ndocs\"), but I felt that it was a good way to incorporate review into a\nreproducible workflow.\u003c/p\u003e\n\u003cp\u003eNow, my pipeline precludes your PI from having to learn git to make a pull\nrequest on your paper. That's a good thing... and we still have\nreproducibility. But what about the figures themselves? I said I had knitr for\nreproducible figures, but what about everyone else? I think figures have high\nvalue, and so people might want to have more reproducibility invested in them.\nIn the blog post, it was claimed that making \"complex\" pub-quality figures was\ndifficult (i.e. the plea for Adobe Illustrator), but look at the annotation\nfunctions from ggplot2, and multifaceted images. I found these annotation\nfunctions to be very easy to pick up. There is also the on-going debate about\nggplot2 vs base graphics on the simplystatistics blog, which covers making\npublication quality figures, and last I checked, I think the ggplot2â€²ers were\nwinning. I don't know how it works in high profile journals like Nature,\nbecause it looks like they just re-do all the figures to make them have some\nconsistent style, but that doesn't mean your original figure should be\nirreproducible.\u003c/p\u003e\n\u003cp\u003eThe debate about reproducible figures is pretty tangible too in things like\nmicroscopy images. Simply look at the large amount of discussion from pubpeer\nabout image fraud and possible duplications. The pubpeer community obviously\nhas some pretty sophisticated tools for hunting out possibly manipulated\nmicroscopy images. These types of things also lead to investigations, and you\ncan see in the high-profile retraction case over STAP cells that it looks like\nthe investigating committee were simply asking how some figures were made, and\nupon finding that lab members don't know, a paper was retracted. The\nRetractionWatch blog covers these\ninvestigations \u003ca href=\"http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/\"\u003ehttp://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eYou can't depend on other people to back your figure up, so you need to take\nresponsibility for making sure your papers and your work are reproducible (and,\nthere is a spectrum for reproducibility, but I believe that version control is\na great example of highly disciplined work). I also think that just having\nfolders on some hard drive is not a good way to do things either. There is a\nsaying in software development that is \"if it's not in version control, it\ndoesn't exist\". That's not to say that version control is for everything, big\ndata obviously has trouble with being stored in git. But that shouldn't block\nyou from creating reproducible analyses.\u003c/p\u003e\n\u003cp\u003eAnother example from the over-reproducibility blogpost says that if you have\n\"analysis1\" and \"analysis2\", then version control advocates would tell you to\ndelete analysis1 and just remember that it is in your history. I think that\nthis is just a different issue. If you actually care about both analyses, just\nmake them separate repositories, with basic README.md files explaining each\nthem, and stop worrying about it. Having one repository containing too many\nmiscellaneous scripts is actually an anti-pattern. Stop making repositories\ncalled \"bioinfo-scripts\" that just contain a mish-mash of analysis scripts!\nMake your work purpose driven and do tasks. Also, this is an argument against\nREPL tools: your R REPL history is not a reproducible script. Make your code\ninto a script that generates well defined outputs. Windows users: you might not\nunderstand this because the command line on windows is crippled, but you have\nto make things run on the command line.\u003c/p\u003e\n\u003cp\u003eNow I wish I could say that I live by my words, but having been involved in\ncoauthoring several papers, I will just have to admit that it is really a messy\nprocedure despite my best intentions as an editor and coauthor. I wish things\nwould be better!\u003c/p\u003e\n\u003cp\u003eOn over-reproducibility: there is no such thing! There are pretty good\narguments to really automate most of a process, especially if it is done\nrepeatedly, to remove human errors, because meat-machines genuinely do things\nwrong all the time.\u003c/p\u003e\n\u003cp\u003eAnd, as my parents would say around the dinner table: \"you can always have\nmore, but you can never have less\"...so, you're not going to get to a point of\nover-reproducibility. We shouldn't cargo cult it as the only way to do science\nbut it's not a bad thing to have.\u003c/p\u003e"}},"__N_SSG":true},"page":"/posts/[slug]","query":{"slug":"2016-03-05"},"buildId":"U1O0VFr02s2obkmwwo8ro","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>