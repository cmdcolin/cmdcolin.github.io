<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/39537df1dfa69610d89e.css" as="style"/><link rel="stylesheet" href="/_next/static/css/39537df1dfa69610d89e.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-a40ef1678bae11e696dba45124eadd70.js"></script><script src="/_next/static/chunks/webpack-1a8a258926ecde76681b.js" defer=""></script><script src="/_next/static/chunks/framework-b97a0ed4f13ff8397343.js" defer=""></script><script src="/_next/static/chunks/main-1f2c591c5d3bfcfc95e6.js" defer=""></script><script src="/_next/static/chunks/pages/_app-72a03db9ecdc52193d45.js" defer=""></script><script src="/_next/static/chunks/pages/2016-03-05-276429d0e6cb88d12288.js" defer=""></script><script src="/_next/static/1dmMki36U_DdLh0c508pP/_buildManifest.js" defer=""></script><script src="/_next/static/1dmMki36U_DdLh0c508pP/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div><div><a href="/">Return home</a><img src="/avatar.png" style="height:2em;margin-left:1em"/></div><div class="blog"><h1>On over-reproducibility</h1><p>Recently, some posts were made by
<a href="https://twitter.com/arjunrajlab">https://twitter.com/arjunrajlab</a> about how perhaps we are aiming at
&quot;over-reproducibility&quot;. I think this is interesting, and would generally
agree that not everyone needs to achieve total automation of their whole
pipeline, but I think the post does a lot of &quot;blaming your tools&quot; and
disparaging good development practices with regards to version control
and figure generation. </p><p>I think that the complaint that version control and automated figures
are not for everyone is probably true, but it is overgeneralizing a
different problem. For example, students are not &quot;trained&quot; to work with
Git, and they are not \&quot;trained&quot; to do software engineering. In fact,
even computer science students are not generally &quot;trained&quot; to do any of
those things (computer science != software engineering). But that
doesn&#x27;t mean that your lab needs to forego using all those tools.
Software development can be incredibly complex and sophisticated, but
it&#x27;s important to make sure things are &quot;done right&quot;! High-quality and
easy-to-reproduce software is really about process, and engineering. But
that is also why there is no one-true-way for reproducibility. Maybe
Arjun doesn&#x27;t have a reproducible workflow right now, but what about 5
years down the road, where he suddenly has a great framework for such
things? This happens all the time in software development (for example,
how long ago was it that &quot;push to deploy&quot; did not exist? how often would
you just edit your files live on your site? now that is seen as bad
practice!), but that said, processes for software quality can evolve
pretty organically, so even though some best practices exist, people can
grow their own quality environment.</p><p>Even if we agree that software development+version control=good, there
are still a lot of complaints about it in the blogpost. For example, the
complaint that git is too hard is pretty silly, and the xkcd comic about
calling over graph theorist doesn&#x27;t really help. As a software developer
at work, I think that version control simply helps define a disciplined
way of working. Version control makes you analyze your progress,
summarize it as a commit message, format the code properly, make sure it
passes tests, and then talk to your collaborators about accepting it.
Dropbox might accomplish some of those things, but I would really doubt
that it is covering that full scope. Arjun seems to agree with using
version control for some of his labs software development, so again,
there is a spectrum of needs being met. Nevertheless, there are some
weird comments about whether commit messages are like a &quot;lab notebook&quot;,
but hint: they are not, write documentation for your project or keep a
separate journal or blog or wiki. Commit messages in my opinion should
be about one line, and the changes should be very self explanatory. But
another big argument in the blogpost is whether version control works
for something like paper writing, and I believe that this underscores
something else: that paper writing is really a pretty messy procedure.</p><p>I think that perhaps the &quot;google docs&quot; mode of writing is probably
pretty ok for many things, but it still needs a gatekeeper to
incorporate the comments from coauthors and reviewers into the document
in an organized way. In my experience as a &quot;gatekeeper&quot; with writing my
senior thesis, I organized my paper using knitr, and I automated figures
being generated by R wherever possible, and then I would convert the
paper to .docx to share with my advisors. Then I would take their
comments on the .docx and incorporate it back into my paper. This could
be seen as burdensome (&quot;why not just use google docs&quot;), but I felt that
it was a good way to incorporate review into a reproducible workflow.</p><p>Now, my pipeline precludes your PI from having to learn git to make a
pull request on your paper. That&#x27;s a good thing... and we still have
reproducibility.  But what about the figures themselves? I said I had
knitr for reproducible figures, but what about everyone else? I think
figures have high value, and so people might want to have more
reproducibility invested in them. In the blog post, it was claimed that
making &quot;complex&quot; pub-quality figures was difficult (i.e. the plea for
Adobe Illustrator), but look at the annotation functions from ggplot2,
and multifaceted images. I found these annotation functions to be very
easy to pick up. There is also the on-going debate about ggplot2 vs base
graphics on the simplystatistics blog, which covers making publication
quality figures, and last I checked, I think the ggplot2′ers were
winning. I don&#x27;t know how it works in high profile journals like Nature,
because it looks like they just re-do all the figures to make them have
some consistent style, but that doesn&#x27;t mean your original figure should
be irreproducible.</p><p>The debate about reproducible figures is pretty tangible too in things
like microscopy images. Simply look at the large amount of discussion
from pubpeer about image fraud and possible duplications. The pubpeer
community obviously has some pretty sophisticated tools for hunting out
possibly manipulated microscopy images. These types of things also lead
to investigations, and you can see in the high-profile retraction case
over STAP cells that it looks like the investigating committee were
simply asking how some figures were made, and upon finding that lab
members don&#x27;t know, a paper was retracted. The RetractionWatch blog
covers these
investigations <a href="http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/">http://retractionwatch.com/2016/02/26/stap-stem-cell-researcher-obokata-loses-another-paper/</a></p><p>You can&#x27;t depend on other people to back your figure up, so you need to
take responsibility for making sure your papers and your work are
reproducible (and, there is a spectrum for reproducibility, but I
believe that version control is a great example of highly disciplined
work). I also think that just having folders on some hard drive is not a
good way to do things either. There is a saying in software development
that is &quot;if it&#x27;s not in version control, it doesn&#x27;t exist&quot;. That&#x27;s not
to say that version control is for everything, big data obviously has
trouble with being stored in git. But that shouldn&#x27;t block you from
creating reproducible analyses.</p><p>Another example from the over-reproducibility blogpost says that if you
have &quot;analysis1″ and &quot;analysis2″, then version control advocates would
tell you to delete analysis1 and just remember that it is in your
history. I think that this is just a different issue. If you actually
care about both analyses, just make them separate repositories, with
basic README.md files explaining each them, and stop worrying about it.
Having one repository containing too many miscellaneous scripts is
actually an anti-pattern. Stop making repositories
called &quot;bioinfo-scripts&quot; that just contain a mish-mash of analysis
scripts! Make your work purpose driven and do tasks. Also, this is an
argument against REPL tools: your R REPL history is not a reproducible
script. Make your code into a script that generates well defined
outputs. Windows users: you might not understand this because the
command line on windows is crippled, but you have to make things run on
the command line.</p><p>Now I wish I could say that I live by my words, but having been involved
in coauthoring several papers, I will just have to admit that it is
really a messy procedure despite my best intentions as an editor and
coauthor. I wish things would be better! </p><p>\</p><p>On over-reproducibility: there is no such thing! There are pretty good
arguments to really automate most of a process, especially if it is done
repeatedly, to remove human errors, because meat-machines genuinely do
things wrong all the time.</p><p>And, as my parents would say around the dinner table: &quot;you can always
have more, but you can never have less&quot;...so, you&#x27;re not going to get to
a point of over-reproducibility. We shouldn&#x27;t cargo cult it as the only
way to do science but it&#x27;s not a bad thing to have.</p><p>::: {#footer}
<!-- -->[ March 5th, 2016 4:07pm ]<!-- -->{#timestamp} <!-- -->[reproducibility]<!-- -->{.tag}
<!-- -->[science]<!-- -->{.tag} <!-- -->[bioinformatics]<!-- -->{.tag}
:::</p></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{}},"page":"/2016-03-05","query":{},"buildId":"1dmMki36U_DdLh0c508pP","nextExport":true,"autoExport":true,"isFallback":false,"scriptLoader":[]}</script></body></html>