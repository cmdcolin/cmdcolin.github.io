<!DOCTYPE html><html lang="en"> <head><meta charset="UTF-8"><meta name="description" content="Astro description"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.16.19"><title>How I learned to hate ORM (especially for data import scripts)</title><style>body{font-family:Helvetica,Arial,sans-serif;background-color:Canvas;color:CanvasText;color-scheme:light dark}img{max-width:100%}pre{max-width:100%;overflow:auto}li+li{margin-top:10px}pre{padding:10px;border-radius:5px}
</style></head> <body> <div class="mb-8"> <a href="/">Misc scribbles</a> </div>  <h1>How I learned to hate ORM (especially for data import scripts)</h1> <p>2017-03-12</p> <p>When I was tasked with making a new application for our websites, I was given
several CSV files with some expectation that these files could basically be just
loaded into a database and jumped into production really quickly. If you are
using R and Shiny to make a data visualization dashboard, especially if it is
read only, this can actually be a reality for you: load those CSVs and just
pretend you’re a full featured database. I had to actually create some read
write functionality though. This was sort of experimental for me and I’m not
that well versed in databases, but I wanted to share my experience</p>
<p>When I started, I chose grails/groovy/hibernate/GORM as a platform to use. This
quickly turned into pain when I tried to make a data importer using grails also.</p>
<p>Each CSV row from the source file would have to be turned into many different
rows in the database because it represented multiple relationships, example:</p>
<p><img src="/media/158300473458_0.png" alt=""></p>
<p>Initially I made my data importer in grails, and was hardcoding column names
knowing full well this was really inflexible. At the same time I was also trying
to “iterate” on my database schema, and I’d want to re-import my data to test it
out, but it was really really slow. I tried many different approaches to try to
speed this up such as cleanUpGorm, StatelessSessions, and other tricks, but it
would take 10-20 minutes for imports on a 100KB input file.</p>
<p>What I basically realised is that for bulk data import</p>
<ol>
<li>
<p>Using the ORM is really painful for bulk import.</p>
</li>
<li>
<p>If you can pre-process your data so that it is already in the format the
database expects, then you can use the CSV COPY command which is very fast</p>
</li>
<li>
<p>If you can then abandon the ORM mentality and even ignore it as a convenience
factor, then you can embrace my database system itself</p>
</li>
</ol>
<p>Overall, after all this work, it just seemed like ORM treats the database as a
danger and something to be heavily abstracted over, but I actually found joy in
learning how to treat my database as a first class citizen. Soon I started
gaining appreciation of</p>
<ul>
<li>using plain SQL queries</li>
<li>learning about full text search in postgres with ts_query</li>
<li>learning about triggers to make a “last updated” field get updated
automatically</li>
</ul>
<p>I am pretty happy this way, and although I miss some things like criteria
queries which are very powerful, I am happy that I can interact with my database
as a friend</p>
<p>At the very least, due to the fact that I now pre-process the data before
database loading, I can now import large amounts of data super fast with the CSV
COPY command</p>  <footer class="mt-16"> <a class="m-2" href="/">Home</a> <a class="m-2" href="/archive">Blog archive</a> <a class="m-2" href="https://github.com/cmdcolin/">Github</a> <a class="m-2" href="/projects">Projects</a> <a class="m-2" href="/books">Books</a> <a class="m-2" href="/about">About</a> <a class="m-2" href="/rss.xml">RSS</a> </footer> </body></html>